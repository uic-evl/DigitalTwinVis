{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "import copy\n",
    "from Utils import *\n",
    "from SymptomPrediction import *\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False)\n",
    "data.processed_df.T\n",
    "data.get_input_state(1).shape\n",
    "# data.processed_df#.shape, len(data.processed_df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c676f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpv\n",
      "age\n",
      "packs_per_year\n",
      "gender\n",
      "Aspiration rate Pre-therapy\n",
      "total_dose\n",
      "dose_fraction\n",
      "OS (Calculated)\n",
      "Locoregional control (Time)\n",
      "FDM (months)\n",
      "time_to_event\n",
      "Overall Survival (1=alive, 0=dead)\n",
      "LRC\n",
      "DC\n",
      "bilateral\n",
      "White/Caucasion\n",
      "Hispanic/Latino\n",
      "African American/Black\n",
      "Asian\n",
      "cc_none\n",
      "cc_platinum\n",
      "cc_cetuximab\n",
      "cc_others\n",
      "no_dose_adjustment\n",
      "dose_modified\n",
      "dose_delayed\n",
      "dose_cancelled\n",
      "dose_delayed_&_modified\n",
      "regiment_modification\n",
      "T-category_1\n",
      "T-category_2\n",
      "T-category_3\n",
      "T-category_4\n",
      "N-category_0\n",
      "N-category_1\n",
      "N-category_2\n",
      "N-category_3\n",
      "AJCC_1\n",
      "AJCC_2\n",
      "AJCC_3\n",
      "AJCC_4\n",
      "Pathological Grade_0\n",
      "Pathological Grade_1\n",
      "Pathological Grade_2\n",
      "Pathological Grade_3\n",
      "Pathological Grade_4\n",
      "subsite_BOT\n",
      "subsite_GPS\n",
      "subsite_NOS\n",
      "subsite_Soft palate\n",
      "subsite_Tonsil\n",
      "treatment_CC\n",
      "treatment_IC+CC\n",
      "treatment_IC+Radiation alone\n",
      "treatment_Radiation alone\n",
      "DLT_Dermatological\n",
      "DLT_Neurological\n",
      "DLT_Gastrointestinal\n",
      "DLT_Hematological\n",
      "DLT_Nephrological\n",
      "DLT_Vascular\n",
      "DLT_Infection (Pneumonia)\n",
      "DLT_Other\n",
      "DLT_Dermatological 2\n",
      "DLT_Neurological 2\n",
      "DLT_Gastrointestinal 2\n",
      "DLT_Hematological 2\n",
      "DLT_Nephrological 2\n",
      "DLT_Vascular 2\n",
      "DLT_Infection (Pneumonia) 2\n",
      "DLT_Other 2\n",
      "CR Primary\n",
      "PR Primary\n",
      "SD Primary\n",
      "CR Nodal\n",
      "PR Nodal\n",
      "SD Nodal\n",
      "CR Primary 2\n",
      "PR Primary 2\n",
      "SD Primary 2\n",
      "CR Nodal 2\n",
      "PR Nodal 2\n",
      "SD Nodal 2\n",
      "Decision 1 (Induction Chemo) Y/N\n",
      "Decision 2 (CC / RT alone)\n",
      "Decision 3 Neck Dissection (Y/N)\n",
      "Overall Survival (4 Years)\n",
      "FT\n",
      "Aspiration rate Post-therapy\n",
      "1A_ipsi\n",
      "1A_contra\n",
      "1B_ipsi\n",
      "1B_contra\n",
      "2A_ipsi\n",
      "2A_contra\n",
      "2B_ipsi\n",
      "2B_contra\n",
      "3_ipsi\n",
      "3_contra\n",
      "4_ipsi\n",
      "4_contra\n",
      "5A_ipsi\n",
      "5A_contra\n",
      "5B_ipsi\n",
      "5B_contra\n",
      "6_ipsi\n",
      "6_contra\n",
      "RPLN_ipsi\n",
      "RPLN_contra\n"
     ]
    }
   ],
   "source": [
    "for c in data.processed_df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cbf89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((937, 234), (1192, 295))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mdasi_stuff():\n",
    "    model = torch.load('../resources/symptomImputer.pt')\n",
    "    mdasi_base = pd.read_excel('../data/mdasi_updated.xlsx').drop('Unnamed: 0',axis=1)\n",
    "    mdasi_imputed = pd.read_csv('../data/mdasi_imputed.csv').drop('Unnamed: 0',axis=1)\n",
    "    mdasi_base['id'] = mdasi_base['ID'].apply(lambda x: int(x.replace('STIEFEL_','')))\n",
    "    mdasi_imputed['id'] = mdasi_imputed['ID'].apply(lambda x: int(x.replace('STIEFEL_','')))\n",
    "    return model, mdasi_base, mdasi_imputed\n",
    "\n",
    "sp, mdasib, mdasi = load_mdasi_stuff()\n",
    "mdasi.shape, mdasib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79fb7fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                   60.514408\n",
       "gender                                 0.906083\n",
       "packs_per_year                         7.441222\n",
       "hpv                                    1.000000\n",
       "total_dose                          6838.928495\n",
       "dose_fraction                         32.559232\n",
       "White/Caucasion                        0.927428\n",
       "Hispanic/Latino                        0.067236\n",
       "African American/Black                 0.025614\n",
       "Asian                                  0.006403\n",
       "bilateral                              0.022412\n",
       "subsite_BOT                            0.465315\n",
       "subsite_GPS                            0.011740\n",
       "subsite_Tonsil                         0.454642\n",
       "subsite_Soft palate                    0.005336\n",
       "subsite_NOS                            0.059765\n",
       "T-category_1                           0.326574\n",
       "N-category_0                           0.073639\n",
       "T-category_2                           0.356457\n",
       "N-category_1                           0.671291\n",
       "T-category_3                           0.153682\n",
       "N-category_2                           0.208111\n",
       "T-category_4                           0.102455\n",
       "N-category_3                           0.046958\n",
       "Decision 1 (Induction Chemo) Y/N       0.193170\n",
       "Decision 2 (CC / RT alone)             0.722519\n",
       "Decision 3 Neck Dissection (Y/N)       0.165422\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_mdasi_input(mdasi).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3eab2e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mdasi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmdasi\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mdasi' is not defined"
     ]
    }
   ],
   "source": [
    "mdasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc1f869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_mse_loss(ypred, y):\n",
    "    #ignores loss in the autoencoder for missing values (-1 here)\n",
    "    y = torch.flatten(y)\n",
    "    ypred = torch.flatten(ypred)\n",
    "    mask = torch.lt(y,-.1)\n",
    "    out = (ypred[~mask] - y[~mask])**2\n",
    "    loss = out.mean()\n",
    "    return loss\n",
    "\n",
    "def train_symptom_model(mdasi,lr=.0001,patience=1000,epochs=1000000,symptoms = None,\n",
    "                        save_file='../resources/symptomImputerTemp.pt',verbose=True,**kwargs):\n",
    "\n",
    "    mdasi_input=  process_mdasi_input(mdasi)\n",
    "\n",
    "    train_ids = mdasi_input.reset_index().id.sample(frac=.66,replace=False).values\n",
    "    test_ids = mdasi_input.drop(train_ids).reset_index().id.values\n",
    "    \n",
    "    xtrain = df_to_torch(mdasi_input.loc[train_ids])\n",
    "    xtest = df_to_torch(mdasi_input.loc[test_ids])\n",
    "\n",
    "    sdf,_,symptoms = get_symptom_df(mdasi)\n",
    "\n",
    "    stopred= symptoms\n",
    "    if symptoms is None:\n",
    "        stopred = Const.prediction_symptoms\n",
    "\n",
    "    ytrain = torch.from_numpy(sdf_symptom_array( sdf.loc[train_ids], stopred))\n",
    "    ytest = torch.from_numpy(sdf_symptom_array( sdf.loc[test_ids], stopred))\n",
    "\n",
    "    sp = SymptomPredictor(xtrain.shape[1],ytrain.shape[1],max_rating=10,**kwargs)\n",
    "    sp.fit_normalizer(xtrain)\n",
    "    optimizer = torch.optim.Adam(sp.parameters(),lr=lr)\n",
    "\n",
    "    best_loss = 1000000000000000000000000\n",
    "    steps_since_improvement=0\n",
    "    patience=patience\n",
    "    sp.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        ypred = sp(xtrain)\n",
    "\n",
    "        loss = nan_mse_loss(ypred,ytrain)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ypred_test = sp(xtest)\n",
    "        val_loss = nan_mse_loss(ypred_test,ytest)\n",
    "        if verbose:\n",
    "            print(epoch,loss.item(),val_loss.item())\n",
    "        steps_since_improvement+=1\n",
    "        if val_loss.item() < best_loss:\n",
    "            best_loss = val_loss.item()\n",
    "            steps_since_improvement=0\n",
    "            torch.save(sp.state_dict(),save_file)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    sp.load_state_dict(torch.load(save_file))\n",
    "    sp.eval()\n",
    "    if verbose:\n",
    "        print('best loss',best_loss,epoch-patience)\n",
    "    return sp,best_loss\n",
    "\n",
    "# sp,sp_loss = train_symptom_model(mdasib,hidden_layers=[1000,100,10])\n",
    "# sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dedbfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 3.572778029530631, 'layers': [10], 'dropout': 0}\n",
      "+++++++++++++++++++++++++++\n",
      "new best loss 3.572778029530631\n",
      "[10]\n",
      "0\n",
      "_________++++++++++__________\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 5.310018261393623, 'layers': [10], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 3.775321466661291, 'layers': [10], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 5.109372702073977, 'layers': [10], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.694319483080253, 'layers': [100], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.231830178589532, 'layers': [100], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.32321058242886, 'layers': [100], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.172756442968619, 'layers': [100], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.449996373705416, 'layers': [1000, 100], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.040886425016643, 'layers': [1000, 100], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.610439358546581, 'layers': [1000, 100], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.188022830617731, 'layers': [1000, 100], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.519906799727679, 'layers': [5000, 100], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.3307078691091565, 'layers': [5000, 100], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.4025365067755, 'layers': [5000, 100], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 6.220357490261801, 'layers': [5000, 100], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 4.4056139325473795, 'layers': [10, 10], 'dropout': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 5.43094330054629, 'layers': [10, 10], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 4.9487019947473, 'layers': [10, 10], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
      "), 'loss': 4.80992937313374, 'layers': [10, 10], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 5.248269194145637, 'layers': [100, 100], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 5.915694309440531, 'layers': [100, 100], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.624135820531084, 'layers': [100, 100], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
      "), 'loss': 4.627791377684386, 'layers': [100, 100], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 5.902682946043526, 'layers': [1000, 50], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.182181750671457, 'layers': [1000, 50], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.132405125735925, 'layers': [1000, 50], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.110646353524963, 'layers': [1000, 50], 'dropout': 0.5}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.074429496810378, 'layers': [5000, 50], 'dropout': 0}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.281657256892816, 'layers': [5000, 50], 'dropout': 0.1}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.646910357124267, 'layers': [5000, 50], 'dropout': 0.2}\n",
      "\n",
      "{'model': SymptomPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=27, out_features=5000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5000, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (final_layer): Linear(in_features=50, out_features=112, bias=True)\n",
      "), 'loss': 6.444481564710038, 'layers': [5000, 50], 'dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "hidden_layersets = [\n",
    "    [10],[100],[1000,100],[5000,100],\n",
    "    [10,10],[100,100],\n",
    "    [1000,50],[5000,50]\n",
    "]\n",
    "dropouts = [0,.1,.2,.5]\n",
    "best_model = None\n",
    "best_mloss = 1000000000000000000\n",
    "results = []\n",
    "for hl in hidden_layersets:\n",
    "    for do in dropouts:\n",
    "        sptemp,sploss = train_symptom_model(mdasi,hidden_layers=hl,dropout=do,patience=100,verbose=False)\n",
    "        results.append({'model': sptemp, 'loss': sploss,'layers': hl[:],'dropout':do})\n",
    "        print()\n",
    "        print(results[-1])\n",
    "        if sploss < best_mloss:\n",
    "            best_model = sptemp\n",
    "            best_mloss = sploss\n",
    "            print('+++++++++++++++++++++++++++')\n",
    "            print('new best loss',sploss)\n",
    "            print(hl)\n",
    "            print(do)\n",
    "            print('_________++++++++++__________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12d0af8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymptomPredictor(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b02c039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'../resources/symptomImputer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "906035a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1445</td>\n",
       "      <td>0.500248</td>\n",
       "      <td>1.414331</td>\n",
       "      <td>0.547527</td>\n",
       "      <td>-0.238426</td>\n",
       "      <td>-1.361126</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>1.397747</td>\n",
       "      <td>0.993124</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>2.373032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1123</td>\n",
       "      <td>1.487083</td>\n",
       "      <td>1.007057</td>\n",
       "      <td>-0.035258</td>\n",
       "      <td>1.829207</td>\n",
       "      <td>-1.361126</td>\n",
       "      <td>-0.713692</td>\n",
       "      <td>-0.538427</td>\n",
       "      <td>-0.318023</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>0.779958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1446</td>\n",
       "      <td>0.812521</td>\n",
       "      <td>0.903847</td>\n",
       "      <td>2.806787</td>\n",
       "      <td>-0.877378</td>\n",
       "      <td>-1.361126</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>2.524730</td>\n",
       "      <td>1.340965</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>-0.422416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1448</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.387447</td>\n",
       "      <td>1.268020</td>\n",
       "      <td>1.322180</td>\n",
       "      <td>-1.361126</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>1.342638</td>\n",
       "      <td>-0.318023</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>1.311435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1449</td>\n",
       "      <td>1.225510</td>\n",
       "      <td>0.541784</td>\n",
       "      <td>0.852631</td>\n",
       "      <td>1.462089</td>\n",
       "      <td>-0.814546</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>0.769261</td>\n",
       "      <td>-0.318023</td>\n",
       "      <td>-0.824981</td>\n",
       "      <td>0.200049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>1707</td>\n",
       "      <td>1.103811</td>\n",
       "      <td>1.428927</td>\n",
       "      <td>0.264068</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>-0.168224</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>0.234492</td>\n",
       "      <td>2.886616</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>1.772260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>1708</td>\n",
       "      <td>1.696921</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.906366</td>\n",
       "      <td>1.670223</td>\n",
       "      <td>-0.942027</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>-0.243785</td>\n",
       "      <td>0.443138</td>\n",
       "      <td>-1.018400</td>\n",
       "      <td>-0.060345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>1709</td>\n",
       "      <td>1.878426</td>\n",
       "      <td>1.065306</td>\n",
       "      <td>-0.527575</td>\n",
       "      <td>1.261594</td>\n",
       "      <td>-1.361126</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>-1.135325</td>\n",
       "      <td>2.643781</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>0.380769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>1710</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.032895</td>\n",
       "      <td>0.962017</td>\n",
       "      <td>1.134421</td>\n",
       "      <td>-0.537424</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>0.238278</td>\n",
       "      <td>0.804344</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>0.421281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>1712</td>\n",
       "      <td>1.172816</td>\n",
       "      <td>0.590557</td>\n",
       "      <td>0.531357</td>\n",
       "      <td>1.665440</td>\n",
       "      <td>1.011139</td>\n",
       "      <td>-1.260582</td>\n",
       "      <td>0.688706</td>\n",
       "      <td>-0.318023</td>\n",
       "      <td>-1.137796</td>\n",
       "      <td>-0.422416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         0         1         2         3         4         5  \\\n",
       "0    1445  0.500248  1.414331  0.547527 -0.238426 -1.361126 -1.260582   \n",
       "1    1123  1.487083  1.007057 -0.035258  1.829207 -1.361126 -0.713692   \n",
       "2    1446  0.812521  0.903847  2.806787 -0.877378 -1.361126 -1.260582   \n",
       "3    1448  0.806867  0.387447  1.268020  1.322180 -1.361126 -1.260582   \n",
       "4    1449  1.225510  0.541784  0.852631  1.462089 -0.814546 -1.260582   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "932  1707  1.103811  1.428927  0.264068  0.756452 -0.168224 -1.260582   \n",
       "933  1708  1.696921  0.924384  0.906366  1.670223 -0.942027 -1.260582   \n",
       "934  1709  1.878426  1.065306 -0.527575  1.261594 -1.361126 -1.260582   \n",
       "935  1710  1.450276  1.032895  0.962017  1.134421 -0.537424 -1.260582   \n",
       "936  1712  1.172816  0.590557  0.531357  1.665440  1.011139 -1.260582   \n",
       "\n",
       "            6         7         8         9  \n",
       "0    1.397747  0.993124 -1.137796  2.373032  \n",
       "1   -0.538427 -0.318023 -1.137796  0.779958  \n",
       "2    2.524730  1.340965 -1.137796 -0.422416  \n",
       "3    1.342638 -0.318023 -1.137796  1.311435  \n",
       "4    0.769261 -0.318023 -0.824981  0.200049  \n",
       "..        ...       ...       ...       ...  \n",
       "932  0.234492  2.886616 -1.137796  1.772260  \n",
       "933 -0.243785  0.443138 -1.018400 -0.060345  \n",
       "934 -1.135325  2.643781 -1.137796  0.380769  \n",
       "935  0.238278  0.804344 -1.137796  0.421281  \n",
       "936  0.688706 -0.318023 -1.137796 -0.422416  \n",
       "\n",
       "[937 rows x 11 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdasi_embeddings = best_model.get_embedding(df_to_torch(process_mdasi_input(mdasi))).cpu().detach()\n",
    "pd.DataFrame(mdasi_embeddings.cpu().detach().numpy(),index=mdasi.id).to_csv('../resources/mdasi_embeddings.csv')\n",
    "pd.read_csv('../resources/mdasi_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c140c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision 1 (Induction Chemo) Y/N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'treated': {'ids': [1069, 118, 225, 1368, 1605, 164, 1342, 1015, 1542, 1532],\n",
       "  'dists': [40.595754742170485,\n",
       "   40.99183677704289,\n",
       "   41.256458873501465,\n",
       "   41.35526375542134,\n",
       "   41.452049965318615,\n",
       "   41.52398205700639,\n",
       "   41.564073532250795,\n",
       "   41.78066071929792,\n",
       "   41.78761053841052,\n",
       "   41.8526227330986],\n",
       "  'symptoms': {'choke': {'ratings': [[0.0, 0.0, 1.0, 0.0],\n",
       "     [0.0, 2.0, 0.758286357, 2.0],\n",
       "     [0.0, 1.0, 0.0, 0.0],\n",
       "     [0.641221374, 2.0, 0.0, 0.0],\n",
       "     [1.0, 0.0, 0.453594029, 0.0],\n",
       "     [0.0, 2.142912626, 1.0, 3.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.376850367, 0.0],\n",
       "     [0.0, 2.0, 0.766977549, 1.115396976],\n",
       "     [0.641221374, 0.0, 0.450264215, 0.536481261]],\n",
       "    'means': [0.22824427480000004,\n",
       "     0.9142912626000002,\n",
       "     0.4805972517,\n",
       "     0.6651878237]},\n",
       "   'drymouth': {'ratings': [[0.0, 0.0, 1.0, 4.0],\n",
       "     [0.0, 1.0, 1.703879237, 6.0],\n",
       "     [0.0, 1.0, 5.0, 6.0],\n",
       "     [0.945638432, 4.0, 3.0, 2.0],\n",
       "     [0.0, 6.0, 4.932738304, 5.0],\n",
       "     [4.0, 6.488459587, 3.0, 6.0],\n",
       "     [0.0, 7.0, 6.0, 5.0],\n",
       "     [0.0, 0.0, 1.760259986, 0.0],\n",
       "     [1.0, 3.0, 3.263810873, 4.019793034],\n",
       "     [0.945638432, 3.0, 3.254362583, 4.000380993]],\n",
       "    'means': [0.6891276864, 3.1488459587, 3.2915050983, 4.2020174027]}}},\n",
       " 'untreated': {'ids': [1517, 1461, 1257, 912, 1394, 110, 905, 1220, 1641, 274],\n",
       "  'dists': [40.78775051293201,\n",
       "   41.04087367642968,\n",
       "   41.64022951940358,\n",
       "   41.672210341462254,\n",
       "   41.79856490521784,\n",
       "   41.81341334076366,\n",
       "   42.00314682278176,\n",
       "   42.13572691534008,\n",
       "   42.174952352684464,\n",
       "   42.196100801178055],\n",
       "  'symptoms': {'choke': {'ratings': [[1.0, 9.0, 1.594100952, 1.932183027],\n",
       "     [0.0, 0.0, 2.0, 0.896200657],\n",
       "     [0.0, 2.180908442, 0.826929212, 1.194316268],\n",
       "     [4.0, 4.886623859, 1.765619516, 2.443482161],\n",
       "     [0.641221374, 0.0, 1.0, 1.0],\n",
       "     [0.0, 6.0, 2.0, 1.0],\n",
       "     [0.641221374, 0.0, 0.450264215, 0.536481261],\n",
       "     [0.641221374, 2.916265249, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, 7.0, 1.341926575, 1.482010603]],\n",
       "    'means': [0.6923664122, 3.198379755, 1.097884047, 1.0484673977]},\n",
       "   'drymouth': {'ratings': [[8.0, 10.0, 7.496423244, 8.314195633],\n",
       "     [0.0, 3.0, 6.0, 5.970096588],\n",
       "     [1.0, 8.0, 6.04564476, 5.933849335],\n",
       "     [0.0, 5.0, 4.44291544, 4.766464233],\n",
       "     [0.945638432, 8.0, 5.0, 9.0],\n",
       "     [0.0, 3.0, 3.0, 5.0],\n",
       "     [0.945638432, 8.0, 6.154408455, 6.043144226],\n",
       "     [0.945638432, 5.381517887, 5.0, 4.0],\n",
       "     [3.0, 3.0, 0.0, 1.0],\n",
       "     [1.0, 6.0, 4.779668808, 6.383118629]],\n",
       "    'means': [1.5836915296, 5.9381517887, 4.7919060707, 5.6410868644]}}},\n",
       " 'dates': [0, 7, 12, 27]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_patient(d,pid=7,clear_transitions=True):\n",
    "    tp = d.processed_df.loc[pid].to_dict()\n",
    "    if clear_transitions:\n",
    "        for v in Const.primary_disease_states + Const.nodal_disease_states:\n",
    "            tp[v] = 0\n",
    "            tp[v + ' 2'] = 0\n",
    "    return tp \n",
    "\n",
    "def get_knn(model,xin,mdf,sdf,symptom_subset=None,k=10,dates=[0,7,12,27]):\n",
    "    xalt = df_to_torch(mdf)\n",
    "    embeddings = model.get_embedding(xin).cpu().detach().numpy()\n",
    "    base_embeddings = model.get_embedding(xalt).cpu().detach().numpy()\n",
    "    dists = cdist(embeddings,base_embeddings)[0]\n",
    "    order = np.argsort(dists)[:k]\n",
    "    dists = dists[order]\n",
    "    \n",
    "    mdasi_ids= mdf.index\n",
    "    ids = mdasi_ids[order]\n",
    "    symptoms = sdf.loc[ids]\n",
    "    \n",
    "    if symptom_subset is None:\n",
    "        symptom_subset = Const.prediction_symptoms\n",
    "    res = {'ids': ids.tolist(),'dists': dists.tolist()}\n",
    "    sentries = {}\n",
    "    for sym in symptom_subset:\n",
    "        if sym == 'core':\n",
    "            continue\n",
    "        cols = [c for c in symptoms.columns if sym+'_' in c]\n",
    "        values = symptoms[cols].values\n",
    "        entry = {'ratings': values.tolist()}\n",
    "        means = []\n",
    "        for cidx in range(values.shape[1]):\n",
    "            subvals = values[:,cidx]\n",
    "            subvals = [v for v in subvals if v >= 0]\n",
    "            means.append(np.mean(subvals))\n",
    "        entry['means'] = means\n",
    "        sentries[sym] = entry\n",
    "    return {'ids': ids.tolist(),'dists':dists.tolist(),'symptoms':sentries}\n",
    "\n",
    "def get_knn_predictions(fdict,\n",
    "                        model,\n",
    "                        mdasi,\n",
    "                        mdasi_embeddings=None,\n",
    "                        k=10,\n",
    "                        ttype=torch.FloatTensor,\n",
    "                        dates=[0,7,12,27],\n",
    "                        symptom_subset = None,\n",
    "                        decision_state=0,#0 is default, 1,2,3 are ic,cc,nd?\n",
    "                       ):\n",
    "    \n",
    "\n",
    "    mdasi_df = process_mdasi_input(mdasi)\n",
    "    sdf,output_dates,output_symptoms = get_symptom_df(mdasi)\n",
    "    \n",
    "    \n",
    "    order = mdasi_df.columns\n",
    "    xin = torch.tensor([fdict[k] for k in order]).type(ttype).view(1,-1) \n",
    "\n",
    "    if decision_state == 0:\n",
    "        se = get_knn(model,xin,mdasi_df,sdf,k=k,symptom_subset=symptom_subset,dates=dates)\n",
    "        se['dates'] = dates\n",
    "        res = se\n",
    "    \n",
    "    else:\n",
    "        dcol = Const.decisions[decision_state-1]\n",
    "        print(dcol)\n",
    "        mdasi_df_treated = mdasi_df[mdasi_df[dcol].astype(float) > .5]\n",
    "        mdasi_df_untreated = mdasi_df[mdasi_df[dcol].astype(float) < .5]\n",
    "        se_treated = get_knn(model,xin,mdasi_df_treated,sdf,k=k,symptom_subset=symptom_subset,dates=dates)\n",
    "        se_untreated = get_knn(model,xin,mdasi_df_untreated,sdf,k=k,symptom_subset=symptom_subset,dates=dates)\n",
    "        res = {'treated': se_treated,'untreated': se_untreated,'dates': dates}\n",
    "    return res\n",
    "\n",
    "test_patient = get_test_patient(data,7)\n",
    "get_knn_predictions(test_patient,sp2,mdasi,symptom_subset=['choke','drymouth'],decision_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c986c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dates': [0, 7, 12, 27],\n",
       " 'symptoms': {'choke': {'means': [6.100060939788818, 10.0, 10.0, 10.0],\n",
       "   'ratings': [[8.176459312438965, 10.0, 10.0, 10.0],\n",
       "    [2.87192702293396, 10.0, 10.0, 10.0],\n",
       "    [2.1255526542663574,\n",
       "     4.624366283416748,\n",
       "     1.6369287967681885,\n",
       "     1.4604820013046265],\n",
       "    [8.405499458312988, 10.0, 10.0, 10.0],\n",
       "    [2.015972375869751,\n",
       "     5.311256408691406,\n",
       "     2.0509910583496094,\n",
       "     1.7925984859466553],\n",
       "    [1.6517019271850586,\n",
       "     4.735230922698975,\n",
       "     2.233750104904175,\n",
       "     2.3451006412506104],\n",
       "    [8.31027889251709,\n",
       "     9.208638191223145,\n",
       "     6.922463417053223,\n",
       "     9.567170143127441],\n",
       "    [2.952191114425659, 10.0, 10.0, 10.0],\n",
       "    [8.343428611755371, 10.0, 10.0, 10.0],\n",
       "    [9.011286735534668, 10.0, 10.0, 10.0]]},\n",
       "  'drymouth': {'means': [4.6650214195251465,\n",
       "    7.582496166229248,\n",
       "    5.747006416320801,\n",
       "    8.741512298583984],\n",
       "   'ratings': [[5.53472375869751, 10.0, 8.317580223083496, 10.0],\n",
       "    [2.568161964416504,\n",
       "     4.523853778839111,\n",
       "     4.533323287963867,\n",
       "     6.291259288787842],\n",
       "    [2.3225622177124023,\n",
       "     2.5512807369232178,\n",
       "     1.3353896141052246,\n",
       "     0.9036229848861694],\n",
       "    [5.3419880867004395, 10.0, 7.953537464141846, 10.0],\n",
       "    [2.2206315994262695,\n",
       "     2.9599428176879883,\n",
       "     1.4725122451782227,\n",
       "     0.9622749090194702],\n",
       "    [1.8177798986434937,\n",
       "     3.1599514484405518,\n",
       "     1.714538335800171,\n",
       "     1.4044437408447266],\n",
       "    [7.301510810852051, 10.0, 6.769355773925781, 9.908489227294922],\n",
       "    [2.303697109222412,\n",
       "     4.189084053039551,\n",
       "     4.57016134262085,\n",
       "     6.390407085418701],\n",
       "    [5.25469446182251, 10.0, 8.118497848510742, 10.0],\n",
       "    [5.817529678344727, 10.0, 7.874978065490723, 10.0]]}}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_symptom_predictions(fdict,\n",
    "                        model,\n",
    "                        order=None,\n",
    "                        k=10,\n",
    "                        ttype=torch.FloatTensor,\n",
    "                        dates=[0,7,12,27],\n",
    "                        symptom_subset = None,\n",
    "                        decision_state=0,#0 is default, 1,2,3 are ic,cc,nd?\n",
    "                       ):\n",
    "\n",
    "    \n",
    "    if order is None:\n",
    "        order = Const.mdasi_input_cols\n",
    "\n",
    "    xin = torch.tensor([fdict[k] for k in order]).type(ttype).view(1,-1) \n",
    "\n",
    "    model.eval()\n",
    "    model.disable_dropout()\n",
    "    ypred = model(xin).cpu().detach().numpy()\n",
    "\n",
    "    symptoms = Const.prediction_symptoms\n",
    "    if symptom_subset is None:\n",
    "        symptom_subset = Const.prediction_symptoms\n",
    "    curpos = 0\n",
    "    results = {s: {'means':[],'ratings': []} for s in symptom_subset}\n",
    "    \n",
    "    for sym in symptoms:\n",
    "        if sym not in symptom_subset:\n",
    "            curpos += len(dates)\n",
    "            continue\n",
    "        values = ypred[:,curpos:curpos+len(dates)].tolist()[0]\n",
    "        curpos += len(dates)\n",
    "        results[sym]['means'] = values\n",
    "        \n",
    "    for i in range(k):\n",
    "        model.enable_dropout()\n",
    "        ypred = model(xin).cpu().detach().numpy()\n",
    "        curpos = 0\n",
    "        for sym in symptoms:\n",
    "            if sym not in symptom_subset:\n",
    "                curpos += len(dates)\n",
    "                continue\n",
    "            values = ypred[:,curpos:curpos+len(dates)].tolist()[0]\n",
    "            curpos += len(dates)\n",
    "            cur_res = results[sym]['ratings']\n",
    "            cur_res.append(values)\n",
    "            results[sym]['ratings'] = cur_res\n",
    "    model.disable_dropout()\n",
    "    return {'dates': dates,'symptoms': results}\n",
    "\n",
    "test_patient = get_test_patient(data,5)\n",
    "get_symptom_predictions(test_patient,sp,symptom_subset=['choke','drymouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd90d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "D10\n",
      "D15\n",
      "D2\n",
      "D20\n",
      "D25\n",
      "D30\n",
      "D35\n",
      "D40\n",
      "D45\n",
      "D5\n",
      "D50\n",
      "D55\n",
      "D60\n",
      "D65\n",
      "D70\n",
      "D75\n",
      "D80\n",
      "D85\n",
      "D90\n",
      "D95\n",
      "D97\n",
      "D98\n",
      "D99\n",
      "V10\n",
      "V15\n",
      "V20\n",
      "V25\n",
      "V30\n",
      "V35\n",
      "V40\n",
      "V45\n",
      "V5\n",
      "V50\n",
      "V55\n",
      "V60\n",
      "V65\n",
      "V70\n",
      "V75\n",
      "V80\n",
      "level_0\n",
      "max_dose\n",
      "mean_dose\n",
      "min_dose\n",
      "volume\n",
      "chemotherapy\n",
      "baseline_height\n",
      "sx_prior_to_enrollment\n",
      "ic_prior_to_enrollment\n",
      "status_at_enrollememt\n",
      "end_of_treatment_weight\n",
      "rt\n",
      "baseline_weight\n",
      "is_ajcc_8th_edition\n",
      "is_male\n",
      "age\n",
      "n_stage\n",
      "performance_score\n",
      "concurrent_prior_to_enrollment\n",
      "ic\n",
      "concurrent\n",
      "sxprimary\n",
      "t_stage\n",
      "os\n",
      "subsite\n",
      "M6_mbs_digest\n",
      "Local_control\n",
      "wk6_weight\n",
      "hpv\n",
      "Technique\n",
      "Regional_control\n",
      "dates\n",
      "symptoms_pain_original\n",
      "symptoms_fatigue_original\n",
      "symptoms_nausea_original\n",
      "symptoms_sleep_original\n",
      "symptoms_distress_original\n",
      "symptoms_sob_original\n",
      "symptoms_memory_original\n",
      "symptoms_appetite_original\n",
      "symptoms_drowsy_original\n",
      "symptoms_drymouth_original\n",
      "symptoms_sad_original\n",
      "symptoms_vomit_original\n",
      "symptoms_numb_original\n",
      "symptoms_mucus_original\n",
      "symptoms_swallow_original\n",
      "symptoms_choke_original\n",
      "symptoms_voice_original\n",
      "symptoms_skin_original\n",
      "symptoms_constipation_original\n",
      "symptoms_taste_original\n",
      "symptoms_mucositis_original\n",
      "symptoms_teeth_original\n",
      "symptoms_activity_original\n",
      "symptoms_mood_original\n",
      "symptoms_work_original\n",
      "symptoms_relations_original\n",
      "symptoms_walking_original\n",
      "symptoms_enjoy_original\n",
      "baseline_bmi\n",
      "wk6_bmi\n",
      "end_of_treatment_bmi\n",
      "bmi_change\n",
      "weight_loss_5kg\n",
      "longterm_bmi_change\n",
      "t4\n",
      "n3\n",
      "t3\n",
      "n2\n",
      "BOT\n",
      "t_severe\n",
      "n_severe\n",
      "Tonsil\n",
      "age>median\n",
      "age_65\n",
      "digest_increase\n",
      "performance_1\n",
      "performance_2\n",
      "performance_high\n",
      "previously_treated\n",
      "IMRT\n",
      "IMPT\n",
      "VMAT\n",
      "symptoms_activity\n",
      "symptoms_appetite\n",
      "symptoms_choke\n",
      "symptoms_constipation\n",
      "symptoms_distress\n",
      "symptoms_drowsy\n",
      "symptoms_drymouth\n",
      "symptoms_enjoy\n",
      "symptoms_fatigue\n",
      "symptoms_memory\n",
      "symptoms_mood\n",
      "symptoms_mucositis\n",
      "symptoms_mucus\n",
      "symptoms_nausea\n",
      "symptoms_numb\n",
      "symptoms_pain\n",
      "symptoms_relations\n",
      "symptoms_sad\n",
      "symptoms_skin\n",
      "symptoms_sleep\n",
      "symptoms_sob\n",
      "symptoms_swallow\n",
      "symptoms_taste\n",
      "symptoms_teeth\n",
      "symptoms_voice\n",
      "symptoms_vomit\n",
      "symptoms_walking\n",
      "symptoms_work\n"
     ]
    }
   ],
   "source": [
    "DOSE_ORDER = ['Esophagus', 'Spinal_Cord', 'Lt_Brachial_Plexus', 'Rt_Brachial_Plexus', 'Cricopharyngeal_Muscle', 'Cricoid_cartilage', 'IPC', 'MPC', 'Brainstem', 'Larynx', 'Thyroid_cartilage', 'Rt_Sternocleidomastoid_M', 'Rt_Mastoid', 'Rt_Parotid_Gland', 'Rt_Medial_Pterygoid_M', 'Rt_Lateral_Pterygoid_M', 'Rt_Masseter_M', 'Lt_Sternocleidomastoid_M', 'Lt_Mastoid', 'Lt_Parotid_Gland', 'Lt_Submandibular_Gland', 'Lt_Medial_Pterygoid_M', 'Lt_Lateral_Pterygoid_M', 'Lt_Masseter_M', 'Supraglottic_Larynx', 'SPC', 'Rt_Submandibular_Gland', 'Hyoid_bone', 'Soft_Palate', 'Genioglossus_M', 'Tongue', 'Rt_Ant_Digastric_M', 'Lt_Ant_Digastric_M', 'Mylogeniohyoid_M', 'Extended_Oral_Cavity', 'Mandible', 'Hard_Palate', 'Lower_Lip', 'Upper_Lip', 'Glottic_Area']\n",
    "dosedf = pd.read_csv('../data/minimal_dose_cluster_dataset.csv')\n",
    "for c in dosedf.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4da8742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bilateral</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>hpv</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>T-category_1</th>\n",
       "      <th>N-category_0</th>\n",
       "      <th>AJCC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <th>subsite_BOT</th>\n",
       "      <th>subsite_GPS</th>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <th>subsite_NOS</th>\n",
       "      <th>White/Caucasion</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>African American/Black</th>\n",
       "      <th>Asian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.930556</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.319444</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59.730556</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>49.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>48.705556</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>77.116667</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>45.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>49.733333</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  gender  bilateral  total_dose  dose_fraction  hpv  \\\n",
       "id                                                                    \n",
       "3      55.969444       1      False       66.00       2.200000    1   \n",
       "5      20.950000       1      False       72.00       1.800000    0   \n",
       "6      69.930556       0       True       70.00       2.121212    1   \n",
       "7      72.319444       1      False       70.00       2.121212    1   \n",
       "8      59.730556       1      False       66.00       2.200000    1   \n",
       "...          ...     ...        ...         ...            ...  ...   \n",
       "10201  49.566667       1      False       70.00       2.121212    1   \n",
       "10202  48.705556       1      False       72.00       1.714286    0   \n",
       "10203  77.116667       1      False       70.00       2.333333    1   \n",
       "10204  45.950000       1       True       69.96       2.120000    0   \n",
       "10205  49.733333       1      False       69.96       2.120000    1   \n",
       "\n",
       "       packs_per_year  T-category_1  N-category_0  AJCC_1  ...  \\\n",
       "id                                                         ...   \n",
       "3                 0.0             0             0       1  ...   \n",
       "5                38.0             0             0       0  ...   \n",
       "6                35.0             0             0       0  ...   \n",
       "7                 0.0             1             0       0  ...   \n",
       "8                 0.0             1             0       1  ...   \n",
       "...               ...           ...           ...     ...  ...   \n",
       "10201            30.0             0             0       0  ...   \n",
       "10202            30.0             0             0       0  ...   \n",
       "10203             0.0             1             0       1  ...   \n",
       "10204             5.0             0             0       0  ...   \n",
       "10205             0.0             0             0       0  ...   \n",
       "\n",
       "       Pathological Grade_4  subsite_BOT  subsite_GPS  subsite_Tonsil  \\\n",
       "id                                                                      \n",
       "3                         0            1            0               0   \n",
       "5                         0            1            0               0   \n",
       "6                         0            1            0               0   \n",
       "7                         0            0            0               0   \n",
       "8                         0            0            0               1   \n",
       "...                     ...          ...          ...             ...   \n",
       "10201                     0            1            0               0   \n",
       "10202                     0            0            0               0   \n",
       "10203                     0            0            0               1   \n",
       "10204                     0            0            0               1   \n",
       "10205                     0            1            0               0   \n",
       "\n",
       "       subsite_Soft palate  subsite_NOS  White/Caucasion  Hispanic/Latino  \\\n",
       "id                                                                          \n",
       "3                        0            0             True            False   \n",
       "5                        0            0             True            False   \n",
       "6                        0            0             True            False   \n",
       "7                        0            1             True            False   \n",
       "8                        0            0            False            False   \n",
       "...                    ...          ...              ...              ...   \n",
       "10201                    0            0             True            False   \n",
       "10202                    0            1            False             True   \n",
       "10203                    0            0             True            False   \n",
       "10204                    0            0             True            False   \n",
       "10205                    0            0             True            False   \n",
       "\n",
       "       African American/Black  Asian  \n",
       "id                                    \n",
       "3                       False  False  \n",
       "5                       False  False  \n",
       "6                       False  False  \n",
       "7                       False  False  \n",
       "8                       False  False  \n",
       "...                       ...    ...  \n",
       "10201                   False  False  \n",
       "10202                   False  False  \n",
       "10203                   False  False  \n",
       "10204                   False  False  \n",
       "10205                   False  False  \n",
       "\n",
       "[536 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_camprt_data():\n",
    "    pdata = pd.read_csv('../data/camprt_pdata.csv')\n",
    "#     for col in pdata.columns:\n",
    "#         print(col)\n",
    "#         if len(pdata[col].unique()) < 10:\n",
    "#             print(pdata[col].unique())\n",
    "#         print('___')\n",
    "\n",
    "    to_keep = ['id','age','gender','bilateral','total_dose','dose_fraction','hpv','packs_per_year']\n",
    "    cdf = pdata.copy()\n",
    "    cdf['id'] = pdata['Dummy ID']\n",
    "    cdf['age'] = pdata['Age at Diagnosis (Calculated)']\n",
    "    cdf['gender'] = pdata['Gender'].apply(lambda x: x=='Male')\n",
    "    cdf['bilateral'] = pdata['Tm Laterality (R/L)'].apply(lambda x: x.lower() == 'bilateral')\n",
    "    cdf['total_dose'] = pdata['Total dose']\n",
    "    cdf['dose_fraction'] = pdata['Dose/fraction (Gy)']\n",
    "    cdf['packs_per_year'] = pdata['Smoking status (Packs/Year)']\n",
    "    \n",
    "    cdf[Const.decisions[0]] = pdata['Therapeutic combination'].apply(lambda x: 'IC' in x)\n",
    "    cdf[Const.decisions[1]] = pdata['Therapeutic combination'].apply(lambda x: 'CC' in x)\n",
    "    smoking_map = {\n",
    "        \n",
    "    }\n",
    "    hpv_map = {\n",
    "        'Unknown': -1,\n",
    "        'Negative': 0,\n",
    "        'Positive': 1\n",
    "    }\n",
    "    cdf['hpv'] = pdata['HPV/P16 status'].apply(lambda x: hpv_map.get(x,-1))\n",
    "    \n",
    "    tstages = [1,2,3,4]\n",
    "\n",
    "    ajcc_map = {\n",
    "        'II': 2,\n",
    "        'I': 1,\n",
    "        'III': 3,\n",
    "        'IV': 4,\n",
    "    }\n",
    "    \n",
    "    path_grade_map = {\n",
    "        'I': 1,\n",
    "        'II': 2,\n",
    "        'III': 3,\n",
    "        'IV': 4\n",
    "    }\n",
    "    for ts in tstages:\n",
    "        cdf['T-category_'+ str(ts)] = pdata['T-category'].apply(lambda x: int(x[1]) == ts if x.lower() not in ['tx','tis'] else False)\n",
    "        to_keep.append('T-category_'+str(ts))\n",
    "\n",
    "        ns = ts-1\n",
    "        cdf['N-category_'+ str(ns)] = pdata['N-category_8th_edition'].apply(lambda x: int(x[1]) == ns)\n",
    "        to_keep.append('N-category_'+str(ns))\n",
    "\n",
    "        cdf['AJCC_' + str(ts)] = pdata['AJCC 8th edition'].apply(lambda x: ajcc_map.get(x,0) == ts)\n",
    "        to_keep.append('AJCC_'+str(ts))\n",
    "    \n",
    "        cdf['Pathological Grade_' + str(ts)] = pdata['Pathological Grade'].apply(lambda x: path_grade_map.get(x,0) == ts)\n",
    "        to_keep.append('Pathological Grade_'+str(ts))\n",
    "    subsites = [\n",
    "            'BOT','GPS','Tonsil','Soft palate','NOS'\n",
    "        #     'Pharyngeal wall'\n",
    "    ]\n",
    "    for subsite in subsites:\n",
    "        cdf['subsite_'+subsite] = pdata['Tumor subsite (BOT/Tonsil/Soft Palate/Pharyngeal wall/GPS/NOS)'].apply(lambda x: x == subsite.replace(' ','_'))\n",
    "        to_keep.append('subsite_'+subsite)\n",
    "        \n",
    "    for race in ['White/Caucasion', 'Hispanic/Latino', 'African American/Black', 'Asian']:\n",
    "        cdf[race] = pdata['Race'].apply(lambda x: x==race)\n",
    "        to_keep.append(race)\n",
    "    return cdf[to_keep].set_index('id')\n",
    "\n",
    "data.processed_df[get_camprt_data().columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c16470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1A_ipsi</th>\n",
       "      <th>1B_ipsi</th>\n",
       "      <th>2A_ipsi</th>\n",
       "      <th>2B_ipsi</th>\n",
       "      <th>3_ipsi</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>1A_contra</th>\n",
       "      <th>1B_contra</th>\n",
       "      <th>2A_contra</th>\n",
       "      <th>2B_contra</th>\n",
       "      <th>3_contra</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_contra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>10200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>10202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>10203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>10204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  1A_ipsi  1B_ipsi  2A_ipsi  2B_ipsi  3_ipsi  4_ipsi  5A_ipsi  \\\n",
       "0        1      0.0      0.0      1.0      1.0     1.0     0.0      0.0   \n",
       "1        2      0.0      0.0      1.0      1.0     0.0     0.0      0.0   \n",
       "2        3      0.0      0.0      1.0      1.0     1.0     0.0      0.0   \n",
       "3        4      0.0      0.0      1.0      1.0     0.0     0.0      0.0   \n",
       "4        5      0.0      0.0      0.0      0.0     1.0     0.0      0.0   \n",
       "..     ...      ...      ...      ...      ...     ...     ...      ...   \n",
       "588  10200      0.0      0.0      1.0      1.0     0.0     0.0      0.0   \n",
       "589  10202      0.0      0.0      1.0      1.0     1.0     0.0      0.0   \n",
       "590  10203      0.0      0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "591  10204      0.0      0.0      1.0      1.0     0.0     0.0      0.0   \n",
       "592  10205      0.0      0.0      1.0      1.0     0.0     0.0      0.0   \n",
       "\n",
       "     5B_ipsi  6_ipsi  1A_contra  1B_contra  2A_contra  2B_contra  3_contra  \\\n",
       "0        0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1        0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "2        0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "3        0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4        0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "..       ...     ...        ...        ...        ...        ...       ...   \n",
       "588      0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "589      0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "590      0.0     0.0        0.0        0.0        1.0        1.0       0.0   \n",
       "591      0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "592      0.0     0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "     4_contra  5A_contra  5B_contra  6_contra  \n",
       "0         0.0        0.0        0.0       0.0  \n",
       "1         0.0        0.0        0.0       0.0  \n",
       "2         0.0        0.0        0.0       0.0  \n",
       "3         0.0        0.0        0.0       0.0  \n",
       "4         0.0        0.0        0.0       0.0  \n",
       "..        ...        ...        ...       ...  \n",
       "588       0.0        0.0        0.0       0.0  \n",
       "589       0.0        0.0        0.0       0.0  \n",
       "590       0.0        0.0        0.0       0.0  \n",
       "591       0.0        0.0        0.0       0.0  \n",
       "592       0.0        0.0        0.0       0.0  \n",
       "\n",
       "[593 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lns = pd.read_csv('../data/monograms_clean.csv').drop(['RPLN_contra','RPLN_ipsi','id.1'],axis=1)\n",
    "lns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8c7293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad value 90.02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Spinal_Cord</th>\n",
       "      <th>Lt_Brachial_Plexus</th>\n",
       "      <th>Rt_Brachial_Plexus</th>\n",
       "      <th>Cricopharyngeal_Muscle</th>\n",
       "      <th>Lt_thyroid_lobe</th>\n",
       "      <th>Rt_thyroid_lobe</th>\n",
       "      <th>Cricoid_cartilage</th>\n",
       "      <th>IPC</th>\n",
       "      <th>MPC</th>\n",
       "      <th>...</th>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <th>subsite_BOT</th>\n",
       "      <th>subsite_GPS</th>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <th>subsite_NOS</th>\n",
       "      <th>White/Caucasion</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>African American/Black</th>\n",
       "      <th>Asian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.64</td>\n",
       "      <td>31.63</td>\n",
       "      <td>48.80</td>\n",
       "      <td>69.54</td>\n",
       "      <td>8.46</td>\n",
       "      <td>48.10</td>\n",
       "      <td>57.91</td>\n",
       "      <td>7.92</td>\n",
       "      <td>51.68</td>\n",
       "      <td>63.35</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.22</td>\n",
       "      <td>31.94</td>\n",
       "      <td>56.92</td>\n",
       "      <td>48.21</td>\n",
       "      <td>29.38</td>\n",
       "      <td>57.14</td>\n",
       "      <td>51.76</td>\n",
       "      <td>34.06</td>\n",
       "      <td>51.92</td>\n",
       "      <td>71.09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.17</td>\n",
       "      <td>14.50</td>\n",
       "      <td>1.36</td>\n",
       "      <td>45.87</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>44.56</td>\n",
       "      <td>6.76</td>\n",
       "      <td>6.91</td>\n",
       "      <td>26.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.73</td>\n",
       "      <td>26.28</td>\n",
       "      <td>44.65</td>\n",
       "      <td>52.98</td>\n",
       "      <td>27.08</td>\n",
       "      <td>49.57</td>\n",
       "      <td>55.30</td>\n",
       "      <td>27.40</td>\n",
       "      <td>19.49</td>\n",
       "      <td>57.43</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32.89</td>\n",
       "      <td>25.98</td>\n",
       "      <td>55.89</td>\n",
       "      <td>53.36</td>\n",
       "      <td>41.72</td>\n",
       "      <td>61.80</td>\n",
       "      <td>54.90</td>\n",
       "      <td>45.25</td>\n",
       "      <td>44.32</td>\n",
       "      <td>46.52</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>44.37</td>\n",
       "      <td>53.07</td>\n",
       "      <td>25.86</td>\n",
       "      <td>50.42</td>\n",
       "      <td>56.14</td>\n",
       "      <td>25.85</td>\n",
       "      <td>13.76</td>\n",
       "      <td>46.39</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25.54</td>\n",
       "      <td>26.51</td>\n",
       "      <td>49.40</td>\n",
       "      <td>46.52</td>\n",
       "      <td>13.07</td>\n",
       "      <td>44.35</td>\n",
       "      <td>50.04</td>\n",
       "      <td>17.47</td>\n",
       "      <td>20.97</td>\n",
       "      <td>63.86</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30.80</td>\n",
       "      <td>28.35</td>\n",
       "      <td>51.05</td>\n",
       "      <td>48.22</td>\n",
       "      <td>9.26</td>\n",
       "      <td>46.78</td>\n",
       "      <td>50.68</td>\n",
       "      <td>15.14</td>\n",
       "      <td>41.35</td>\n",
       "      <td>58.76</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32.43</td>\n",
       "      <td>26.50</td>\n",
       "      <td>42.35</td>\n",
       "      <td>55.48</td>\n",
       "      <td>14.13</td>\n",
       "      <td>47.02</td>\n",
       "      <td>54.45</td>\n",
       "      <td>20.40</td>\n",
       "      <td>56.38</td>\n",
       "      <td>65.58</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>38.44</td>\n",
       "      <td>24.75</td>\n",
       "      <td>54.04</td>\n",
       "      <td>48.58</td>\n",
       "      <td>22.87</td>\n",
       "      <td>53.91</td>\n",
       "      <td>51.93</td>\n",
       "      <td>28.64</td>\n",
       "      <td>19.46</td>\n",
       "      <td>58.14</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>32.22</td>\n",
       "      <td>35.54</td>\n",
       "      <td>54.69</td>\n",
       "      <td>57.24</td>\n",
       "      <td>47.42</td>\n",
       "      <td>56.11</td>\n",
       "      <td>56.79</td>\n",
       "      <td>53.20</td>\n",
       "      <td>58.94</td>\n",
       "      <td>68.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>26.34</td>\n",
       "      <td>20.78</td>\n",
       "      <td>56.83</td>\n",
       "      <td>54.49</td>\n",
       "      <td>11.03</td>\n",
       "      <td>54.95</td>\n",
       "      <td>47.92</td>\n",
       "      <td>12.75</td>\n",
       "      <td>35.02</td>\n",
       "      <td>62.83</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>34.34</td>\n",
       "      <td>25.82</td>\n",
       "      <td>48.61</td>\n",
       "      <td>57.31</td>\n",
       "      <td>15.91</td>\n",
       "      <td>50.22</td>\n",
       "      <td>57.28</td>\n",
       "      <td>22.80</td>\n",
       "      <td>29.11</td>\n",
       "      <td>62.24</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>30.60</td>\n",
       "      <td>22.94</td>\n",
       "      <td>46.22</td>\n",
       "      <td>44.92</td>\n",
       "      <td>14.38</td>\n",
       "      <td>47.34</td>\n",
       "      <td>47.91</td>\n",
       "      <td>21.43</td>\n",
       "      <td>15.18</td>\n",
       "      <td>61.64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>29.86</td>\n",
       "      <td>28.56</td>\n",
       "      <td>59.48</td>\n",
       "      <td>58.56</td>\n",
       "      <td>14.29</td>\n",
       "      <td>56.97</td>\n",
       "      <td>52.03</td>\n",
       "      <td>17.63</td>\n",
       "      <td>53.72</td>\n",
       "      <td>56.14</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>29.26</td>\n",
       "      <td>26.16</td>\n",
       "      <td>46.06</td>\n",
       "      <td>45.64</td>\n",
       "      <td>20.87</td>\n",
       "      <td>50.24</td>\n",
       "      <td>39.01</td>\n",
       "      <td>25.57</td>\n",
       "      <td>28.60</td>\n",
       "      <td>55.91</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>41.51</td>\n",
       "      <td>29.14</td>\n",
       "      <td>45.63</td>\n",
       "      <td>46.62</td>\n",
       "      <td>16.93</td>\n",
       "      <td>49.74</td>\n",
       "      <td>51.24</td>\n",
       "      <td>25.81</td>\n",
       "      <td>21.72</td>\n",
       "      <td>47.34</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.22</td>\n",
       "      <td>14.51</td>\n",
       "      <td>49.72</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.79</td>\n",
       "      <td>48.17</td>\n",
       "      <td>1.24</td>\n",
       "      <td>8.38</td>\n",
       "      <td>13.40</td>\n",
       "      <td>35.66</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>36.45</td>\n",
       "      <td>24.27</td>\n",
       "      <td>46.37</td>\n",
       "      <td>60.35</td>\n",
       "      <td>11.38</td>\n",
       "      <td>47.80</td>\n",
       "      <td>57.13</td>\n",
       "      <td>16.85</td>\n",
       "      <td>66.69</td>\n",
       "      <td>60.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.03</td>\n",
       "      <td>14.26</td>\n",
       "      <td>1.66</td>\n",
       "      <td>52.11</td>\n",
       "      <td>5.69</td>\n",
       "      <td>1.61</td>\n",
       "      <td>51.96</td>\n",
       "      <td>6.81</td>\n",
       "      <td>9.20</td>\n",
       "      <td>44.15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>29.61</td>\n",
       "      <td>25.66</td>\n",
       "      <td>59.36</td>\n",
       "      <td>49.35</td>\n",
       "      <td>17.67</td>\n",
       "      <td>51.10</td>\n",
       "      <td>49.16</td>\n",
       "      <td>24.53</td>\n",
       "      <td>33.01</td>\n",
       "      <td>57.32</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>36.98</td>\n",
       "      <td>27.01</td>\n",
       "      <td>54.56</td>\n",
       "      <td>47.33</td>\n",
       "      <td>26.50</td>\n",
       "      <td>53.72</td>\n",
       "      <td>51.50</td>\n",
       "      <td>27.21</td>\n",
       "      <td>22.90</td>\n",
       "      <td>54.08</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>27.43</td>\n",
       "      <td>25.81</td>\n",
       "      <td>45.32</td>\n",
       "      <td>46.34</td>\n",
       "      <td>8.51</td>\n",
       "      <td>45.74</td>\n",
       "      <td>41.95</td>\n",
       "      <td>11.30</td>\n",
       "      <td>52.29</td>\n",
       "      <td>63.28</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>28.21</td>\n",
       "      <td>19.20</td>\n",
       "      <td>50.27</td>\n",
       "      <td>54.66</td>\n",
       "      <td>17.94</td>\n",
       "      <td>54.61</td>\n",
       "      <td>52.66</td>\n",
       "      <td>27.57</td>\n",
       "      <td>37.77</td>\n",
       "      <td>66.68</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>29.31</td>\n",
       "      <td>28.83</td>\n",
       "      <td>55.24</td>\n",
       "      <td>52.38</td>\n",
       "      <td>39.43</td>\n",
       "      <td>52.85</td>\n",
       "      <td>51.60</td>\n",
       "      <td>36.56</td>\n",
       "      <td>17.78</td>\n",
       "      <td>56.43</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>29.26</td>\n",
       "      <td>18.32</td>\n",
       "      <td>44.86</td>\n",
       "      <td>49.31</td>\n",
       "      <td>10.56</td>\n",
       "      <td>49.55</td>\n",
       "      <td>48.17</td>\n",
       "      <td>11.81</td>\n",
       "      <td>46.90</td>\n",
       "      <td>57.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>37.18</td>\n",
       "      <td>24.65</td>\n",
       "      <td>54.99</td>\n",
       "      <td>48.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>53.33</td>\n",
       "      <td>49.67</td>\n",
       "      <td>20.43</td>\n",
       "      <td>29.66</td>\n",
       "      <td>60.12</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>25.69</td>\n",
       "      <td>23.23</td>\n",
       "      <td>49.99</td>\n",
       "      <td>46.71</td>\n",
       "      <td>6.95</td>\n",
       "      <td>51.02</td>\n",
       "      <td>47.60</td>\n",
       "      <td>13.85</td>\n",
       "      <td>54.62</td>\n",
       "      <td>68.11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>21.73</td>\n",
       "      <td>21.43</td>\n",
       "      <td>53.02</td>\n",
       "      <td>48.30</td>\n",
       "      <td>15.92</td>\n",
       "      <td>51.84</td>\n",
       "      <td>37.54</td>\n",
       "      <td>15.64</td>\n",
       "      <td>47.77</td>\n",
       "      <td>57.26</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>33.73</td>\n",
       "      <td>25.73</td>\n",
       "      <td>57.00</td>\n",
       "      <td>10.05</td>\n",
       "      <td>35.32</td>\n",
       "      <td>55.75</td>\n",
       "      <td>17.54</td>\n",
       "      <td>37.09</td>\n",
       "      <td>40.18</td>\n",
       "      <td>41.72</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2.85</td>\n",
       "      <td>18.12</td>\n",
       "      <td>48.91</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8.60</td>\n",
       "      <td>52.46</td>\n",
       "      <td>1.51</td>\n",
       "      <td>11.34</td>\n",
       "      <td>17.64</td>\n",
       "      <td>46.17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>37.67</td>\n",
       "      <td>27.80</td>\n",
       "      <td>51.27</td>\n",
       "      <td>44.96</td>\n",
       "      <td>19.72</td>\n",
       "      <td>54.57</td>\n",
       "      <td>50.62</td>\n",
       "      <td>27.19</td>\n",
       "      <td>24.03</td>\n",
       "      <td>60.46</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>35.88</td>\n",
       "      <td>29.96</td>\n",
       "      <td>49.62</td>\n",
       "      <td>60.03</td>\n",
       "      <td>14.85</td>\n",
       "      <td>50.62</td>\n",
       "      <td>52.73</td>\n",
       "      <td>20.11</td>\n",
       "      <td>28.00</td>\n",
       "      <td>71.43</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.71</td>\n",
       "      <td>12.73</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.97</td>\n",
       "      <td>37.83</td>\n",
       "      <td>1.10</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.58</td>\n",
       "      <td>36.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>29.75</td>\n",
       "      <td>23.17</td>\n",
       "      <td>49.18</td>\n",
       "      <td>45.25</td>\n",
       "      <td>9.56</td>\n",
       "      <td>46.36</td>\n",
       "      <td>47.73</td>\n",
       "      <td>12.88</td>\n",
       "      <td>34.61</td>\n",
       "      <td>65.81</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>25.31</td>\n",
       "      <td>24.52</td>\n",
       "      <td>45.97</td>\n",
       "      <td>55.23</td>\n",
       "      <td>8.49</td>\n",
       "      <td>45.74</td>\n",
       "      <td>51.96</td>\n",
       "      <td>15.35</td>\n",
       "      <td>44.60</td>\n",
       "      <td>68.07</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>37.19</td>\n",
       "      <td>27.91</td>\n",
       "      <td>50.64</td>\n",
       "      <td>38.73</td>\n",
       "      <td>24.74</td>\n",
       "      <td>46.74</td>\n",
       "      <td>42.88</td>\n",
       "      <td>29.11</td>\n",
       "      <td>21.34</td>\n",
       "      <td>59.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>35.04</td>\n",
       "      <td>26.43</td>\n",
       "      <td>45.03</td>\n",
       "      <td>58.99</td>\n",
       "      <td>13.25</td>\n",
       "      <td>39.89</td>\n",
       "      <td>62.04</td>\n",
       "      <td>22.09</td>\n",
       "      <td>53.16</td>\n",
       "      <td>70.62</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>24.94</td>\n",
       "      <td>26.91</td>\n",
       "      <td>47.93</td>\n",
       "      <td>56.15</td>\n",
       "      <td>13.58</td>\n",
       "      <td>42.50</td>\n",
       "      <td>55.08</td>\n",
       "      <td>20.69</td>\n",
       "      <td>16.15</td>\n",
       "      <td>59.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>35.54</td>\n",
       "      <td>24.55</td>\n",
       "      <td>45.75</td>\n",
       "      <td>54.52</td>\n",
       "      <td>11.84</td>\n",
       "      <td>47.93</td>\n",
       "      <td>54.38</td>\n",
       "      <td>18.16</td>\n",
       "      <td>26.36</td>\n",
       "      <td>55.56</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>34.79</td>\n",
       "      <td>28.13</td>\n",
       "      <td>44.62</td>\n",
       "      <td>46.29</td>\n",
       "      <td>24.83</td>\n",
       "      <td>46.52</td>\n",
       "      <td>48.75</td>\n",
       "      <td>26.63</td>\n",
       "      <td>10.02</td>\n",
       "      <td>65.88</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.45</td>\n",
       "      <td>13.57</td>\n",
       "      <td>2.05</td>\n",
       "      <td>51.26</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>44.99</td>\n",
       "      <td>7.01</td>\n",
       "      <td>18.70</td>\n",
       "      <td>35.59</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>37.95</td>\n",
       "      <td>28.65</td>\n",
       "      <td>57.92</td>\n",
       "      <td>47.19</td>\n",
       "      <td>22.56</td>\n",
       "      <td>56.18</td>\n",
       "      <td>49.08</td>\n",
       "      <td>27.78</td>\n",
       "      <td>22.35</td>\n",
       "      <td>67.94</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>38.28</td>\n",
       "      <td>29.69</td>\n",
       "      <td>59.22</td>\n",
       "      <td>57.15</td>\n",
       "      <td>21.84</td>\n",
       "      <td>58.27</td>\n",
       "      <td>51.25</td>\n",
       "      <td>27.83</td>\n",
       "      <td>36.17</td>\n",
       "      <td>72.95</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>35.04</td>\n",
       "      <td>29.76</td>\n",
       "      <td>48.62</td>\n",
       "      <td>57.26</td>\n",
       "      <td>17.17</td>\n",
       "      <td>46.14</td>\n",
       "      <td>52.77</td>\n",
       "      <td>24.47</td>\n",
       "      <td>22.27</td>\n",
       "      <td>58.11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>14.08</td>\n",
       "      <td>20.80</td>\n",
       "      <td>51.32</td>\n",
       "      <td>57.58</td>\n",
       "      <td>25.86</td>\n",
       "      <td>40.24</td>\n",
       "      <td>44.77</td>\n",
       "      <td>24.09</td>\n",
       "      <td>55.60</td>\n",
       "      <td>66.12</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>28.83</td>\n",
       "      <td>24.59</td>\n",
       "      <td>56.18</td>\n",
       "      <td>54.15</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.94</td>\n",
       "      <td>62.27</td>\n",
       "      <td>66.41</td>\n",
       "      <td>69.57</td>\n",
       "      <td>69.64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>39.72</td>\n",
       "      <td>28.44</td>\n",
       "      <td>55.96</td>\n",
       "      <td>48.65</td>\n",
       "      <td>21.24</td>\n",
       "      <td>50.23</td>\n",
       "      <td>53.11</td>\n",
       "      <td>33.11</td>\n",
       "      <td>26.49</td>\n",
       "      <td>57.75</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>31.93</td>\n",
       "      <td>25.73</td>\n",
       "      <td>37.53</td>\n",
       "      <td>43.63</td>\n",
       "      <td>25.74</td>\n",
       "      <td>41.34</td>\n",
       "      <td>44.61</td>\n",
       "      <td>29.30</td>\n",
       "      <td>13.82</td>\n",
       "      <td>64.44</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>34.84</td>\n",
       "      <td>28.75</td>\n",
       "      <td>54.31</td>\n",
       "      <td>47.26</td>\n",
       "      <td>14.89</td>\n",
       "      <td>52.46</td>\n",
       "      <td>50.78</td>\n",
       "      <td>19.98</td>\n",
       "      <td>47.45</td>\n",
       "      <td>66.86</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>37.84</td>\n",
       "      <td>25.54</td>\n",
       "      <td>55.10</td>\n",
       "      <td>68.88</td>\n",
       "      <td>61.53</td>\n",
       "      <td>58.39</td>\n",
       "      <td>67.31</td>\n",
       "      <td>63.11</td>\n",
       "      <td>63.29</td>\n",
       "      <td>63.83</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>27.60</td>\n",
       "      <td>23.35</td>\n",
       "      <td>36.65</td>\n",
       "      <td>48.64</td>\n",
       "      <td>10.33</td>\n",
       "      <td>39.48</td>\n",
       "      <td>50.15</td>\n",
       "      <td>16.34</td>\n",
       "      <td>35.06</td>\n",
       "      <td>61.52</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.42</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>47.15</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>43.55</td>\n",
       "      <td>6.89</td>\n",
       "      <td>11.85</td>\n",
       "      <td>39.54</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>30.98</td>\n",
       "      <td>24.54</td>\n",
       "      <td>45.71</td>\n",
       "      <td>49.63</td>\n",
       "      <td>11.58</td>\n",
       "      <td>48.29</td>\n",
       "      <td>51.31</td>\n",
       "      <td>18.56</td>\n",
       "      <td>27.17</td>\n",
       "      <td>53.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>9.49</td>\n",
       "      <td>18.71</td>\n",
       "      <td>3.07</td>\n",
       "      <td>51.81</td>\n",
       "      <td>7.08</td>\n",
       "      <td>2.13</td>\n",
       "      <td>54.92</td>\n",
       "      <td>13.09</td>\n",
       "      <td>24.05</td>\n",
       "      <td>45.47</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.52</td>\n",
       "      <td>21.42</td>\n",
       "      <td>15.44</td>\n",
       "      <td>16.40</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.84</td>\n",
       "      <td>23.22</td>\n",
       "      <td>56.94</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>31.53</td>\n",
       "      <td>24.61</td>\n",
       "      <td>45.35</td>\n",
       "      <td>55.39</td>\n",
       "      <td>5.83</td>\n",
       "      <td>37.76</td>\n",
       "      <td>38.63</td>\n",
       "      <td>6.98</td>\n",
       "      <td>59.37</td>\n",
       "      <td>67.44</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>34.90</td>\n",
       "      <td>25.99</td>\n",
       "      <td>38.66</td>\n",
       "      <td>55.49</td>\n",
       "      <td>18.21</td>\n",
       "      <td>44.27</td>\n",
       "      <td>57.59</td>\n",
       "      <td>26.18</td>\n",
       "      <td>33.45</td>\n",
       "      <td>68.90</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>30.40</td>\n",
       "      <td>26.71</td>\n",
       "      <td>45.77</td>\n",
       "      <td>54.58</td>\n",
       "      <td>13.88</td>\n",
       "      <td>48.96</td>\n",
       "      <td>54.71</td>\n",
       "      <td>22.65</td>\n",
       "      <td>40.84</td>\n",
       "      <td>58.34</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1.84</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.64</td>\n",
       "      <td>49.17</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>54.51</td>\n",
       "      <td>15.13</td>\n",
       "      <td>9.05</td>\n",
       "      <td>34.68</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>30.61</td>\n",
       "      <td>28.10</td>\n",
       "      <td>53.16</td>\n",
       "      <td>55.88</td>\n",
       "      <td>10.16</td>\n",
       "      <td>54.49</td>\n",
       "      <td>42.83</td>\n",
       "      <td>12.13</td>\n",
       "      <td>53.25</td>\n",
       "      <td>63.37</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>19.17</td>\n",
       "      <td>28.10</td>\n",
       "      <td>57.33</td>\n",
       "      <td>47.82</td>\n",
       "      <td>17.27</td>\n",
       "      <td>56.03</td>\n",
       "      <td>49.34</td>\n",
       "      <td>22.73</td>\n",
       "      <td>59.95</td>\n",
       "      <td>65.46</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>39.04</td>\n",
       "      <td>26.78</td>\n",
       "      <td>57.92</td>\n",
       "      <td>48.35</td>\n",
       "      <td>10.96</td>\n",
       "      <td>49.48</td>\n",
       "      <td>47.85</td>\n",
       "      <td>21.32</td>\n",
       "      <td>43.49</td>\n",
       "      <td>61.35</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>23.14</td>\n",
       "      <td>23.70</td>\n",
       "      <td>45.68</td>\n",
       "      <td>51.89</td>\n",
       "      <td>28.45</td>\n",
       "      <td>52.98</td>\n",
       "      <td>50.74</td>\n",
       "      <td>31.77</td>\n",
       "      <td>25.13</td>\n",
       "      <td>52.80</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>28.43</td>\n",
       "      <td>30.63</td>\n",
       "      <td>54.62</td>\n",
       "      <td>48.51</td>\n",
       "      <td>21.68</td>\n",
       "      <td>52.13</td>\n",
       "      <td>49.17</td>\n",
       "      <td>29.72</td>\n",
       "      <td>30.06</td>\n",
       "      <td>63.58</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>30.55</td>\n",
       "      <td>28.48</td>\n",
       "      <td>47.51</td>\n",
       "      <td>57.97</td>\n",
       "      <td>21.83</td>\n",
       "      <td>50.21</td>\n",
       "      <td>56.71</td>\n",
       "      <td>25.26</td>\n",
       "      <td>17.57</td>\n",
       "      <td>59.46</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3.33</td>\n",
       "      <td>13.73</td>\n",
       "      <td>47.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>6.10</td>\n",
       "      <td>51.27</td>\n",
       "      <td>1.13</td>\n",
       "      <td>11.94</td>\n",
       "      <td>10.10</td>\n",
       "      <td>65.54</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>32.16</td>\n",
       "      <td>29.25</td>\n",
       "      <td>57.27</td>\n",
       "      <td>55.82</td>\n",
       "      <td>13.14</td>\n",
       "      <td>56.87</td>\n",
       "      <td>53.09</td>\n",
       "      <td>20.48</td>\n",
       "      <td>30.51</td>\n",
       "      <td>59.31</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>35.76</td>\n",
       "      <td>30.13</td>\n",
       "      <td>49.03</td>\n",
       "      <td>43.71</td>\n",
       "      <td>25.85</td>\n",
       "      <td>53.41</td>\n",
       "      <td>48.99</td>\n",
       "      <td>28.67</td>\n",
       "      <td>31.25</td>\n",
       "      <td>65.91</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>35.04</td>\n",
       "      <td>29.91</td>\n",
       "      <td>53.67</td>\n",
       "      <td>47.77</td>\n",
       "      <td>34.81</td>\n",
       "      <td>54.53</td>\n",
       "      <td>48.38</td>\n",
       "      <td>37.06</td>\n",
       "      <td>34.28</td>\n",
       "      <td>66.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>26.71</td>\n",
       "      <td>24.05</td>\n",
       "      <td>46.84</td>\n",
       "      <td>45.34</td>\n",
       "      <td>14.45</td>\n",
       "      <td>48.68</td>\n",
       "      <td>50.47</td>\n",
       "      <td>20.34</td>\n",
       "      <td>37.47</td>\n",
       "      <td>60.72</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>40.03</td>\n",
       "      <td>30.92</td>\n",
       "      <td>61.74</td>\n",
       "      <td>55.55</td>\n",
       "      <td>52.94</td>\n",
       "      <td>65.42</td>\n",
       "      <td>57.83</td>\n",
       "      <td>55.94</td>\n",
       "      <td>54.99</td>\n",
       "      <td>68.94</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>15.26</td>\n",
       "      <td>20.12</td>\n",
       "      <td>47.02</td>\n",
       "      <td>47.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>40.91</td>\n",
       "      <td>41.31</td>\n",
       "      <td>9.25</td>\n",
       "      <td>52.21</td>\n",
       "      <td>65.57</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>23.98</td>\n",
       "      <td>25.94</td>\n",
       "      <td>53.00</td>\n",
       "      <td>48.86</td>\n",
       "      <td>6.70</td>\n",
       "      <td>44.39</td>\n",
       "      <td>47.73</td>\n",
       "      <td>14.62</td>\n",
       "      <td>35.28</td>\n",
       "      <td>61.09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.96</td>\n",
       "      <td>20.90</td>\n",
       "      <td>47.55</td>\n",
       "      <td>1.14</td>\n",
       "      <td>3.66</td>\n",
       "      <td>41.70</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8.16</td>\n",
       "      <td>12.83</td>\n",
       "      <td>40.56</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>29.28</td>\n",
       "      <td>21.91</td>\n",
       "      <td>45.54</td>\n",
       "      <td>47.03</td>\n",
       "      <td>10.08</td>\n",
       "      <td>49.58</td>\n",
       "      <td>33.80</td>\n",
       "      <td>11.18</td>\n",
       "      <td>33.77</td>\n",
       "      <td>59.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>34.45</td>\n",
       "      <td>30.07</td>\n",
       "      <td>47.34</td>\n",
       "      <td>55.37</td>\n",
       "      <td>19.76</td>\n",
       "      <td>50.37</td>\n",
       "      <td>54.27</td>\n",
       "      <td>24.49</td>\n",
       "      <td>26.71</td>\n",
       "      <td>60.62</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>25.39</td>\n",
       "      <td>22.50</td>\n",
       "      <td>52.61</td>\n",
       "      <td>46.40</td>\n",
       "      <td>16.22</td>\n",
       "      <td>53.95</td>\n",
       "      <td>52.29</td>\n",
       "      <td>28.75</td>\n",
       "      <td>22.51</td>\n",
       "      <td>60.76</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>37.68</td>\n",
       "      <td>24.28</td>\n",
       "      <td>60.10</td>\n",
       "      <td>47.93</td>\n",
       "      <td>12.49</td>\n",
       "      <td>58.08</td>\n",
       "      <td>41.40</td>\n",
       "      <td>21.14</td>\n",
       "      <td>28.10</td>\n",
       "      <td>51.87</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>25.15</td>\n",
       "      <td>19.94</td>\n",
       "      <td>43.81</td>\n",
       "      <td>53.58</td>\n",
       "      <td>12.91</td>\n",
       "      <td>44.36</td>\n",
       "      <td>56.41</td>\n",
       "      <td>20.99</td>\n",
       "      <td>33.84</td>\n",
       "      <td>52.97</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>25.29</td>\n",
       "      <td>27.84</td>\n",
       "      <td>49.70</td>\n",
       "      <td>60.86</td>\n",
       "      <td>6.61</td>\n",
       "      <td>44.16</td>\n",
       "      <td>55.82</td>\n",
       "      <td>13.58</td>\n",
       "      <td>37.71</td>\n",
       "      <td>65.37</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>37.30</td>\n",
       "      <td>26.91</td>\n",
       "      <td>54.89</td>\n",
       "      <td>47.83</td>\n",
       "      <td>14.89</td>\n",
       "      <td>54.20</td>\n",
       "      <td>51.88</td>\n",
       "      <td>22.91</td>\n",
       "      <td>30.99</td>\n",
       "      <td>60.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>31.07</td>\n",
       "      <td>33.75</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.66</td>\n",
       "      <td>48.27</td>\n",
       "      <td>58.04</td>\n",
       "      <td>58.39</td>\n",
       "      <td>48.23</td>\n",
       "      <td>49.16</td>\n",
       "      <td>60.90</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>29.90</td>\n",
       "      <td>22.72</td>\n",
       "      <td>46.63</td>\n",
       "      <td>53.84</td>\n",
       "      <td>12.90</td>\n",
       "      <td>50.56</td>\n",
       "      <td>55.44</td>\n",
       "      <td>22.40</td>\n",
       "      <td>25.11</td>\n",
       "      <td>52.83</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>33.94</td>\n",
       "      <td>27.70</td>\n",
       "      <td>48.51</td>\n",
       "      <td>55.06</td>\n",
       "      <td>14.65</td>\n",
       "      <td>48.11</td>\n",
       "      <td>52.34</td>\n",
       "      <td>19.89</td>\n",
       "      <td>16.83</td>\n",
       "      <td>65.74</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>34.36</td>\n",
       "      <td>25.51</td>\n",
       "      <td>50.08</td>\n",
       "      <td>45.44</td>\n",
       "      <td>9.45</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.23</td>\n",
       "      <td>15.59</td>\n",
       "      <td>43.67</td>\n",
       "      <td>65.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>37.95</td>\n",
       "      <td>28.83</td>\n",
       "      <td>45.08</td>\n",
       "      <td>54.46</td>\n",
       "      <td>12.01</td>\n",
       "      <td>45.53</td>\n",
       "      <td>58.38</td>\n",
       "      <td>25.61</td>\n",
       "      <td>32.97</td>\n",
       "      <td>61.84</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>48.41</td>\n",
       "      <td>35.71</td>\n",
       "      <td>58.54</td>\n",
       "      <td>64.45</td>\n",
       "      <td>53.42</td>\n",
       "      <td>56.81</td>\n",
       "      <td>66.67</td>\n",
       "      <td>58.86</td>\n",
       "      <td>60.25</td>\n",
       "      <td>71.33</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>38.48</td>\n",
       "      <td>28.76</td>\n",
       "      <td>53.47</td>\n",
       "      <td>46.37</td>\n",
       "      <td>30.65</td>\n",
       "      <td>52.11</td>\n",
       "      <td>49.32</td>\n",
       "      <td>32.83</td>\n",
       "      <td>11.33</td>\n",
       "      <td>58.06</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>35.54</td>\n",
       "      <td>33.44</td>\n",
       "      <td>53.97</td>\n",
       "      <td>47.31</td>\n",
       "      <td>12.15</td>\n",
       "      <td>45.59</td>\n",
       "      <td>47.82</td>\n",
       "      <td>22.05</td>\n",
       "      <td>31.41</td>\n",
       "      <td>63.03</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>27.08</td>\n",
       "      <td>25.79</td>\n",
       "      <td>47.22</td>\n",
       "      <td>47.04</td>\n",
       "      <td>14.03</td>\n",
       "      <td>48.44</td>\n",
       "      <td>49.24</td>\n",
       "      <td>20.27</td>\n",
       "      <td>41.68</td>\n",
       "      <td>61.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>38.78</td>\n",
       "      <td>28.75</td>\n",
       "      <td>63.37</td>\n",
       "      <td>67.40</td>\n",
       "      <td>70.63</td>\n",
       "      <td>61.97</td>\n",
       "      <td>65.55</td>\n",
       "      <td>69.45</td>\n",
       "      <td>71.17</td>\n",
       "      <td>70.83</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>36.90</td>\n",
       "      <td>27.06</td>\n",
       "      <td>51.92</td>\n",
       "      <td>56.41</td>\n",
       "      <td>42.40</td>\n",
       "      <td>48.90</td>\n",
       "      <td>53.19</td>\n",
       "      <td>38.23</td>\n",
       "      <td>13.40</td>\n",
       "      <td>16.09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>29.49</td>\n",
       "      <td>30.68</td>\n",
       "      <td>56.14</td>\n",
       "      <td>48.64</td>\n",
       "      <td>24.46</td>\n",
       "      <td>48.76</td>\n",
       "      <td>46.82</td>\n",
       "      <td>29.92</td>\n",
       "      <td>15.99</td>\n",
       "      <td>63.23</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>24.34</td>\n",
       "      <td>23.16</td>\n",
       "      <td>47.48</td>\n",
       "      <td>52.84</td>\n",
       "      <td>19.40</td>\n",
       "      <td>47.74</td>\n",
       "      <td>46.08</td>\n",
       "      <td>24.76</td>\n",
       "      <td>13.66</td>\n",
       "      <td>49.42</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>31.85</td>\n",
       "      <td>25.88</td>\n",
       "      <td>58.96</td>\n",
       "      <td>57.55</td>\n",
       "      <td>48.63</td>\n",
       "      <td>65.07</td>\n",
       "      <td>63.12</td>\n",
       "      <td>57.34</td>\n",
       "      <td>71.85</td>\n",
       "      <td>72.56</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>4.50</td>\n",
       "      <td>14.55</td>\n",
       "      <td>53.65</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>5.29</td>\n",
       "      <td>15.41</td>\n",
       "      <td>48.86</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>36.02</td>\n",
       "      <td>27.56</td>\n",
       "      <td>45.74</td>\n",
       "      <td>56.22</td>\n",
       "      <td>12.33</td>\n",
       "      <td>47.04</td>\n",
       "      <td>52.86</td>\n",
       "      <td>18.00</td>\n",
       "      <td>23.02</td>\n",
       "      <td>57.47</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>27.70</td>\n",
       "      <td>24.59</td>\n",
       "      <td>46.03</td>\n",
       "      <td>60.21</td>\n",
       "      <td>17.16</td>\n",
       "      <td>51.36</td>\n",
       "      <td>60.72</td>\n",
       "      <td>25.04</td>\n",
       "      <td>32.92</td>\n",
       "      <td>59.17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>25.17</td>\n",
       "      <td>22.46</td>\n",
       "      <td>46.13</td>\n",
       "      <td>51.21</td>\n",
       "      <td>14.61</td>\n",
       "      <td>48.54</td>\n",
       "      <td>50.64</td>\n",
       "      <td>23.28</td>\n",
       "      <td>33.09</td>\n",
       "      <td>58.21</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>25.69</td>\n",
       "      <td>24.58</td>\n",
       "      <td>46.96</td>\n",
       "      <td>53.11</td>\n",
       "      <td>9.10</td>\n",
       "      <td>43.84</td>\n",
       "      <td>56.54</td>\n",
       "      <td>19.97</td>\n",
       "      <td>35.74</td>\n",
       "      <td>57.51</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>31.65</td>\n",
       "      <td>30.18</td>\n",
       "      <td>47.18</td>\n",
       "      <td>48.92</td>\n",
       "      <td>23.16</td>\n",
       "      <td>48.68</td>\n",
       "      <td>51.27</td>\n",
       "      <td>25.66</td>\n",
       "      <td>14.31</td>\n",
       "      <td>56.32</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>31.42</td>\n",
       "      <td>28.65</td>\n",
       "      <td>46.03</td>\n",
       "      <td>54.35</td>\n",
       "      <td>16.82</td>\n",
       "      <td>47.22</td>\n",
       "      <td>55.54</td>\n",
       "      <td>27.80</td>\n",
       "      <td>36.73</td>\n",
       "      <td>59.90</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>1.46</td>\n",
       "      <td>18.22</td>\n",
       "      <td>3.79</td>\n",
       "      <td>49.67</td>\n",
       "      <td>4.27</td>\n",
       "      <td>1.62</td>\n",
       "      <td>48.14</td>\n",
       "      <td>10.56</td>\n",
       "      <td>18.87</td>\n",
       "      <td>30.03</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>35.15</td>\n",
       "      <td>30.65</td>\n",
       "      <td>45.79</td>\n",
       "      <td>45.05</td>\n",
       "      <td>38.94</td>\n",
       "      <td>47.14</td>\n",
       "      <td>49.71</td>\n",
       "      <td>37.80</td>\n",
       "      <td>11.21</td>\n",
       "      <td>54.09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>3.74</td>\n",
       "      <td>15.16</td>\n",
       "      <td>45.80</td>\n",
       "      <td>45.74</td>\n",
       "      <td>8.88</td>\n",
       "      <td>49.55</td>\n",
       "      <td>27.05</td>\n",
       "      <td>12.76</td>\n",
       "      <td>16.29</td>\n",
       "      <td>54.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>24.87</td>\n",
       "      <td>29.07</td>\n",
       "      <td>60.30</td>\n",
       "      <td>60.53</td>\n",
       "      <td>42.23</td>\n",
       "      <td>60.24</td>\n",
       "      <td>64.85</td>\n",
       "      <td>46.07</td>\n",
       "      <td>57.63</td>\n",
       "      <td>64.76</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>29.98</td>\n",
       "      <td>29.02</td>\n",
       "      <td>45.25</td>\n",
       "      <td>53.71</td>\n",
       "      <td>24.45</td>\n",
       "      <td>48.42</td>\n",
       "      <td>56.35</td>\n",
       "      <td>32.90</td>\n",
       "      <td>22.40</td>\n",
       "      <td>56.45</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>27.50</td>\n",
       "      <td>29.74</td>\n",
       "      <td>57.80</td>\n",
       "      <td>48.52</td>\n",
       "      <td>23.91</td>\n",
       "      <td>51.22</td>\n",
       "      <td>48.92</td>\n",
       "      <td>29.68</td>\n",
       "      <td>37.23</td>\n",
       "      <td>63.84</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>17.59</td>\n",
       "      <td>27.69</td>\n",
       "      <td>59.87</td>\n",
       "      <td>47.98</td>\n",
       "      <td>23.93</td>\n",
       "      <td>54.86</td>\n",
       "      <td>44.12</td>\n",
       "      <td>16.18</td>\n",
       "      <td>67.53</td>\n",
       "      <td>72.67</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>2.05</td>\n",
       "      <td>18.25</td>\n",
       "      <td>2.37</td>\n",
       "      <td>49.98</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.12</td>\n",
       "      <td>54.25</td>\n",
       "      <td>11.48</td>\n",
       "      <td>9.56</td>\n",
       "      <td>40.33</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>34.52</td>\n",
       "      <td>27.88</td>\n",
       "      <td>51.37</td>\n",
       "      <td>48.14</td>\n",
       "      <td>27.56</td>\n",
       "      <td>53.74</td>\n",
       "      <td>47.57</td>\n",
       "      <td>31.64</td>\n",
       "      <td>22.49</td>\n",
       "      <td>50.67</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>13.45</td>\n",
       "      <td>17.35</td>\n",
       "      <td>39.06</td>\n",
       "      <td>45.56</td>\n",
       "      <td>22.78</td>\n",
       "      <td>53.00</td>\n",
       "      <td>57.77</td>\n",
       "      <td>29.21</td>\n",
       "      <td>20.51</td>\n",
       "      <td>30.50</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>27.66</td>\n",
       "      <td>25.27</td>\n",
       "      <td>43.52</td>\n",
       "      <td>58.18</td>\n",
       "      <td>17.44</td>\n",
       "      <td>48.18</td>\n",
       "      <td>56.82</td>\n",
       "      <td>23.53</td>\n",
       "      <td>56.75</td>\n",
       "      <td>67.94</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>33.50</td>\n",
       "      <td>26.14</td>\n",
       "      <td>46.48</td>\n",
       "      <td>47.19</td>\n",
       "      <td>19.52</td>\n",
       "      <td>50.82</td>\n",
       "      <td>49.90</td>\n",
       "      <td>28.65</td>\n",
       "      <td>24.71</td>\n",
       "      <td>62.45</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>2.17</td>\n",
       "      <td>15.73</td>\n",
       "      <td>3.85</td>\n",
       "      <td>50.95</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.06</td>\n",
       "      <td>50.68</td>\n",
       "      <td>6.97</td>\n",
       "      <td>25.56</td>\n",
       "      <td>36.81</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>27.68</td>\n",
       "      <td>33.41</td>\n",
       "      <td>47.80</td>\n",
       "      <td>55.29</td>\n",
       "      <td>25.42</td>\n",
       "      <td>52.54</td>\n",
       "      <td>51.44</td>\n",
       "      <td>28.40</td>\n",
       "      <td>41.24</td>\n",
       "      <td>61.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>27.93</td>\n",
       "      <td>29.13</td>\n",
       "      <td>54.74</td>\n",
       "      <td>56.16</td>\n",
       "      <td>32.24</td>\n",
       "      <td>49.32</td>\n",
       "      <td>54.11</td>\n",
       "      <td>35.27</td>\n",
       "      <td>30.74</td>\n",
       "      <td>71.66</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>33.61</td>\n",
       "      <td>31.97</td>\n",
       "      <td>57.72</td>\n",
       "      <td>56.27</td>\n",
       "      <td>65.35</td>\n",
       "      <td>60.52</td>\n",
       "      <td>61.75</td>\n",
       "      <td>66.10</td>\n",
       "      <td>69.05</td>\n",
       "      <td>71.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>27.61</td>\n",
       "      <td>22.09</td>\n",
       "      <td>58.05</td>\n",
       "      <td>47.31</td>\n",
       "      <td>10.68</td>\n",
       "      <td>55.15</td>\n",
       "      <td>44.96</td>\n",
       "      <td>16.06</td>\n",
       "      <td>41.84</td>\n",
       "      <td>64.65</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>34.07</td>\n",
       "      <td>31.59</td>\n",
       "      <td>56.00</td>\n",
       "      <td>48.19</td>\n",
       "      <td>13.09</td>\n",
       "      <td>51.79</td>\n",
       "      <td>48.67</td>\n",
       "      <td>18.25</td>\n",
       "      <td>40.17</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>26.02</td>\n",
       "      <td>24.21</td>\n",
       "      <td>48.87</td>\n",
       "      <td>55.51</td>\n",
       "      <td>15.78</td>\n",
       "      <td>47.51</td>\n",
       "      <td>61.37</td>\n",
       "      <td>22.13</td>\n",
       "      <td>61.12</td>\n",
       "      <td>71.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>32.89</td>\n",
       "      <td>31.47</td>\n",
       "      <td>54.29</td>\n",
       "      <td>48.84</td>\n",
       "      <td>26.07</td>\n",
       "      <td>48.86</td>\n",
       "      <td>47.91</td>\n",
       "      <td>26.54</td>\n",
       "      <td>17.74</td>\n",
       "      <td>50.86</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>34.72</td>\n",
       "      <td>27.04</td>\n",
       "      <td>51.71</td>\n",
       "      <td>49.39</td>\n",
       "      <td>12.54</td>\n",
       "      <td>52.16</td>\n",
       "      <td>53.15</td>\n",
       "      <td>20.51</td>\n",
       "      <td>19.32</td>\n",
       "      <td>51.18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>32.64</td>\n",
       "      <td>27.44</td>\n",
       "      <td>48.41</td>\n",
       "      <td>57.11</td>\n",
       "      <td>17.06</td>\n",
       "      <td>46.85</td>\n",
       "      <td>60.19</td>\n",
       "      <td>23.67</td>\n",
       "      <td>38.08</td>\n",
       "      <td>67.02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>22.79</td>\n",
       "      <td>21.20</td>\n",
       "      <td>59.09</td>\n",
       "      <td>47.64</td>\n",
       "      <td>9.54</td>\n",
       "      <td>41.07</td>\n",
       "      <td>44.98</td>\n",
       "      <td>12.27</td>\n",
       "      <td>48.23</td>\n",
       "      <td>60.53</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>31.22</td>\n",
       "      <td>25.82</td>\n",
       "      <td>45.99</td>\n",
       "      <td>56.76</td>\n",
       "      <td>10.54</td>\n",
       "      <td>44.66</td>\n",
       "      <td>59.04</td>\n",
       "      <td>22.11</td>\n",
       "      <td>35.84</td>\n",
       "      <td>59.34</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>35.22</td>\n",
       "      <td>28.91</td>\n",
       "      <td>43.45</td>\n",
       "      <td>55.41</td>\n",
       "      <td>22.26</td>\n",
       "      <td>47.11</td>\n",
       "      <td>59.72</td>\n",
       "      <td>31.01</td>\n",
       "      <td>15.06</td>\n",
       "      <td>53.63</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10065</th>\n",
       "      <td>30.02</td>\n",
       "      <td>27.35</td>\n",
       "      <td>44.90</td>\n",
       "      <td>51.06</td>\n",
       "      <td>24.03</td>\n",
       "      <td>46.99</td>\n",
       "      <td>56.15</td>\n",
       "      <td>28.57</td>\n",
       "      <td>14.31</td>\n",
       "      <td>50.54</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>35.94</td>\n",
       "      <td>27.17</td>\n",
       "      <td>54.71</td>\n",
       "      <td>48.92</td>\n",
       "      <td>12.63</td>\n",
       "      <td>46.39</td>\n",
       "      <td>49.26</td>\n",
       "      <td>17.62</td>\n",
       "      <td>28.80</td>\n",
       "      <td>52.20</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>2.36</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.51</td>\n",
       "      <td>35.52</td>\n",
       "      <td>10.09</td>\n",
       "      <td>2.16</td>\n",
       "      <td>52.91</td>\n",
       "      <td>15.82</td>\n",
       "      <td>13.06</td>\n",
       "      <td>35.39</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10083</th>\n",
       "      <td>28.55</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.66</td>\n",
       "      <td>57.31</td>\n",
       "      <td>14.19</td>\n",
       "      <td>54.86</td>\n",
       "      <td>58.99</td>\n",
       "      <td>22.21</td>\n",
       "      <td>32.55</td>\n",
       "      <td>54.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10085</th>\n",
       "      <td>31.00</td>\n",
       "      <td>26.41</td>\n",
       "      <td>46.35</td>\n",
       "      <td>47.83</td>\n",
       "      <td>9.76</td>\n",
       "      <td>44.90</td>\n",
       "      <td>48.68</td>\n",
       "      <td>18.08</td>\n",
       "      <td>43.94</td>\n",
       "      <td>64.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10092</th>\n",
       "      <td>33.97</td>\n",
       "      <td>24.31</td>\n",
       "      <td>46.64</td>\n",
       "      <td>54.90</td>\n",
       "      <td>10.53</td>\n",
       "      <td>41.75</td>\n",
       "      <td>55.01</td>\n",
       "      <td>14.09</td>\n",
       "      <td>50.01</td>\n",
       "      <td>70.15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>38.13</td>\n",
       "      <td>27.43</td>\n",
       "      <td>53.46</td>\n",
       "      <td>50.28</td>\n",
       "      <td>18.35</td>\n",
       "      <td>53.62</td>\n",
       "      <td>49.15</td>\n",
       "      <td>25.50</td>\n",
       "      <td>27.96</td>\n",
       "      <td>64.90</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>34.13</td>\n",
       "      <td>21.59</td>\n",
       "      <td>43.12</td>\n",
       "      <td>49.79</td>\n",
       "      <td>12.22</td>\n",
       "      <td>44.07</td>\n",
       "      <td>51.60</td>\n",
       "      <td>17.39</td>\n",
       "      <td>18.07</td>\n",
       "      <td>62.47</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>34.40</td>\n",
       "      <td>24.53</td>\n",
       "      <td>47.61</td>\n",
       "      <td>55.69</td>\n",
       "      <td>16.75</td>\n",
       "      <td>50.56</td>\n",
       "      <td>55.18</td>\n",
       "      <td>21.71</td>\n",
       "      <td>39.32</td>\n",
       "      <td>67.37</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10129</th>\n",
       "      <td>35.05</td>\n",
       "      <td>31.63</td>\n",
       "      <td>54.08</td>\n",
       "      <td>46.31</td>\n",
       "      <td>19.89</td>\n",
       "      <td>54.84</td>\n",
       "      <td>50.90</td>\n",
       "      <td>28.20</td>\n",
       "      <td>25.69</td>\n",
       "      <td>39.13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>37.58</td>\n",
       "      <td>29.37</td>\n",
       "      <td>46.94</td>\n",
       "      <td>59.77</td>\n",
       "      <td>15.53</td>\n",
       "      <td>44.75</td>\n",
       "      <td>58.00</td>\n",
       "      <td>24.51</td>\n",
       "      <td>29.53</td>\n",
       "      <td>59.07</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>33.36</td>\n",
       "      <td>27.49</td>\n",
       "      <td>48.94</td>\n",
       "      <td>58.28</td>\n",
       "      <td>14.70</td>\n",
       "      <td>51.77</td>\n",
       "      <td>51.25</td>\n",
       "      <td>19.73</td>\n",
       "      <td>40.51</td>\n",
       "      <td>65.33</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>37.26</td>\n",
       "      <td>25.21</td>\n",
       "      <td>51.05</td>\n",
       "      <td>45.71</td>\n",
       "      <td>26.66</td>\n",
       "      <td>55.92</td>\n",
       "      <td>49.11</td>\n",
       "      <td>36.09</td>\n",
       "      <td>23.90</td>\n",
       "      <td>54.09</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>35.31</td>\n",
       "      <td>27.42</td>\n",
       "      <td>53.97</td>\n",
       "      <td>57.47</td>\n",
       "      <td>14.28</td>\n",
       "      <td>58.39</td>\n",
       "      <td>56.71</td>\n",
       "      <td>18.32</td>\n",
       "      <td>40.55</td>\n",
       "      <td>60.49</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10153</th>\n",
       "      <td>36.98</td>\n",
       "      <td>25.06</td>\n",
       "      <td>55.39</td>\n",
       "      <td>49.84</td>\n",
       "      <td>21.12</td>\n",
       "      <td>48.72</td>\n",
       "      <td>57.03</td>\n",
       "      <td>28.73</td>\n",
       "      <td>20.14</td>\n",
       "      <td>58.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10163</th>\n",
       "      <td>23.35</td>\n",
       "      <td>38.95</td>\n",
       "      <td>48.95</td>\n",
       "      <td>67.65</td>\n",
       "      <td>13.36</td>\n",
       "      <td>66.14</td>\n",
       "      <td>58.18</td>\n",
       "      <td>23.34</td>\n",
       "      <td>47.61</td>\n",
       "      <td>71.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>34.98</td>\n",
       "      <td>35.52</td>\n",
       "      <td>49.16</td>\n",
       "      <td>58.78</td>\n",
       "      <td>35.96</td>\n",
       "      <td>49.30</td>\n",
       "      <td>55.84</td>\n",
       "      <td>35.84</td>\n",
       "      <td>12.51</td>\n",
       "      <td>49.35</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>33.92</td>\n",
       "      <td>28.58</td>\n",
       "      <td>44.67</td>\n",
       "      <td>54.53</td>\n",
       "      <td>16.01</td>\n",
       "      <td>48.69</td>\n",
       "      <td>54.14</td>\n",
       "      <td>19.24</td>\n",
       "      <td>29.35</td>\n",
       "      <td>58.62</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>28.04</td>\n",
       "      <td>23.27</td>\n",
       "      <td>45.78</td>\n",
       "      <td>52.95</td>\n",
       "      <td>9.47</td>\n",
       "      <td>45.52</td>\n",
       "      <td>53.08</td>\n",
       "      <td>14.38</td>\n",
       "      <td>36.17</td>\n",
       "      <td>69.30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>30.50</td>\n",
       "      <td>26.49</td>\n",
       "      <td>45.25</td>\n",
       "      <td>48.79</td>\n",
       "      <td>9.87</td>\n",
       "      <td>46.27</td>\n",
       "      <td>45.98</td>\n",
       "      <td>12.18</td>\n",
       "      <td>42.96</td>\n",
       "      <td>66.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Esophagus  Spinal_Cord  Lt_Brachial_Plexus  Rt_Brachial_Plexus  \\\n",
       "id                                                                      \n",
       "4          40.64        31.63               48.80               69.54   \n",
       "11         39.22        31.94               56.92               48.21   \n",
       "27          1.17        14.50                1.36               45.87   \n",
       "29         30.73        26.28               44.65               52.98   \n",
       "33         32.89        25.98               55.89               53.36   \n",
       "34         36.35        27.25               44.37               53.07   \n",
       "35         25.54        26.51               49.40               46.52   \n",
       "36         30.80        28.35               51.05               48.22   \n",
       "41         32.43        26.50               42.35               55.48   \n",
       "49         38.44        24.75               54.04               48.58   \n",
       "100        32.22        35.54               54.69               57.24   \n",
       "102        26.34        20.78               56.83               54.49   \n",
       "104        34.34        25.82               48.61               57.31   \n",
       "109        30.60        22.94               46.22               44.92   \n",
       "110        29.86        28.56               59.48               58.56   \n",
       "114        29.26        26.16               46.06               45.64   \n",
       "118        41.51        29.14               45.63               46.62   \n",
       "119         5.22        14.51               49.72                2.82   \n",
       "120        36.45        24.27               46.37               60.35   \n",
       "125         2.03        14.26                1.66               52.11   \n",
       "126        29.61        25.66               59.36               49.35   \n",
       "128        36.98        27.01               54.56               47.33   \n",
       "134        27.43        25.81               45.32               46.34   \n",
       "136        28.21        19.20               50.27               54.66   \n",
       "147        29.31        28.83               55.24               52.38   \n",
       "149        29.26        18.32               44.86               49.31   \n",
       "150        37.18        24.65               54.99               48.13   \n",
       "152        25.69        23.23               49.99               46.71   \n",
       "153        21.73        21.43               53.02               48.30   \n",
       "154        33.73        25.73               57.00               10.05   \n",
       "155         2.85        18.12               48.91                1.50   \n",
       "156        37.67        27.80               51.27               44.96   \n",
       "158        35.88        29.96               49.62               60.03   \n",
       "160         1.71        12.73               49.12                1.33   \n",
       "164        29.75        23.17               49.18               45.25   \n",
       "169        25.31        24.52               45.97               55.23   \n",
       "171        37.19        27.91               50.64               38.73   \n",
       "172        35.04        26.43               45.03               58.99   \n",
       "173        24.94        26.91               47.93               56.15   \n",
       "176        35.54        24.55               45.75               54.52   \n",
       "177        34.79        28.13               44.62               46.29   \n",
       "178         1.45        13.57                2.05               51.26   \n",
       "179        37.95        28.65               57.92               47.19   \n",
       "180        38.28        29.69               59.22               57.15   \n",
       "181        35.04        29.76               48.62               57.26   \n",
       "183        14.08        20.80               51.32               57.58   \n",
       "184        28.83        24.59               56.18               54.15   \n",
       "185        39.72        28.44               55.96               48.65   \n",
       "188        31.93        25.73               37.53               43.63   \n",
       "194        34.84        28.75               54.31               47.26   \n",
       "197        37.84        25.54               55.10               68.88   \n",
       "200        27.60        23.35               36.65               48.64   \n",
       "202         1.42        16.01                0.81               47.15   \n",
       "209        30.98        24.54               45.71               49.63   \n",
       "212         9.49        18.71                3.07               51.81   \n",
       "213         0.52        21.42               15.44               16.40   \n",
       "215        31.53        24.61               45.35               55.39   \n",
       "218        34.90        25.99               38.66               55.49   \n",
       "220        30.40        26.71               45.77               54.58   \n",
       "221         1.84        13.65                1.64               49.17   \n",
       "223        30.61        28.10               53.16               55.88   \n",
       "225        19.17        28.10               57.33               47.82   \n",
       "226        39.04        26.78               57.92               48.35   \n",
       "228        23.14        23.70               45.68               51.89   \n",
       "229        28.43        30.63               54.62               48.51   \n",
       "232        30.55        28.48               47.51               57.97   \n",
       "234         3.33        13.73               47.71                2.43   \n",
       "236        32.16        29.25               57.27               55.82   \n",
       "237        35.76        30.13               49.03               43.71   \n",
       "242        35.04        29.91               53.67               47.77   \n",
       "244        26.71        24.05               46.84               45.34   \n",
       "246        40.03        30.92               61.74               55.55   \n",
       "247        15.26        20.12               47.02               47.72   \n",
       "248        23.98        25.94               53.00               48.86   \n",
       "251         2.96        20.90               47.55                1.14   \n",
       "252        29.28        21.91               45.54               47.03   \n",
       "256        34.45        30.07               47.34               55.37   \n",
       "257        25.39        22.50               52.61               46.40   \n",
       "260        37.68        24.28               60.10               47.93   \n",
       "261        25.15        19.94               43.81               53.58   \n",
       "262        25.29        27.84               49.70               60.86   \n",
       "263        37.30        26.91               54.89               47.83   \n",
       "265        31.07        33.75               53.06               55.66   \n",
       "267        29.90        22.72               46.63               53.84   \n",
       "268        33.94        27.70               48.51               55.06   \n",
       "271        34.36        25.51               50.08               45.44   \n",
       "274        37.95        28.83               45.08               54.46   \n",
       "276        48.41        35.71               58.54               64.45   \n",
       "278        38.48        28.76               53.47               46.37   \n",
       "280        35.54        33.44               53.97               47.31   \n",
       "281        27.08        25.79               47.22               47.04   \n",
       "283        38.78        28.75               63.37               67.40   \n",
       "285        36.90        27.06               51.92               56.41   \n",
       "286        29.49        30.68               56.14               48.64   \n",
       "287        24.34        23.16               47.48               52.84   \n",
       "289        31.85        25.88               58.96               57.55   \n",
       "2007        4.50        14.55               53.65                3.94   \n",
       "2011       36.02        27.56               45.74               56.22   \n",
       "2012       27.70        24.59               46.03               60.21   \n",
       "2023       25.17        22.46               46.13               51.21   \n",
       "2024       25.69        24.58               46.96               53.11   \n",
       "2026       31.65        30.18               47.18               48.92   \n",
       "2027       31.42        28.65               46.03               54.35   \n",
       "2028        1.46        18.22                3.79               49.67   \n",
       "2030       35.15        30.65               45.79               45.05   \n",
       "5004        3.74        15.16               45.80               45.74   \n",
       "5007       24.87        29.07               60.30               60.53   \n",
       "5008       29.98        29.02               45.25               53.71   \n",
       "5009       27.50        29.74               57.80               48.52   \n",
       "5011       17.59        27.69               59.87               47.98   \n",
       "5031        2.05        18.25                2.37               49.98   \n",
       "5034       34.52        27.88               51.37               48.14   \n",
       "5056       13.45        17.35               39.06               45.56   \n",
       "5067       27.66        25.27               43.52               58.18   \n",
       "5071       33.50        26.14               46.48               47.19   \n",
       "5077        2.17        15.73                3.85               50.95   \n",
       "5078       27.68        33.41               47.80               55.29   \n",
       "5081       27.93        29.13               54.74               56.16   \n",
       "5084       33.61        31.97               57.72               56.27   \n",
       "5090       27.61        22.09               58.05               47.31   \n",
       "5092       34.07        31.59               56.00               48.19   \n",
       "5100       26.02        24.21               48.87               55.51   \n",
       "10014      32.89        31.47               54.29               48.84   \n",
       "10036      34.72        27.04               51.71               49.39   \n",
       "10044      32.64        27.44               48.41               57.11   \n",
       "10061      22.79        21.20               59.09               47.64   \n",
       "10062      31.22        25.82               45.99               56.76   \n",
       "10063      35.22        28.91               43.45               55.41   \n",
       "10065      30.02        27.35               44.90               51.06   \n",
       "10071      35.94        27.17               54.71               48.92   \n",
       "10080       2.36        16.25                1.51               35.52   \n",
       "10083      28.55        31.21               58.66               57.31   \n",
       "10085      31.00        26.41               46.35               47.83   \n",
       "10092      33.97        24.31               46.64               54.90   \n",
       "10103      38.13        27.43               53.46               50.28   \n",
       "10113      34.13        21.59               43.12               49.79   \n",
       "10124      34.40        24.53               47.61               55.69   \n",
       "10129      35.05        31.63               54.08               46.31   \n",
       "10134      37.58        29.37               46.94               59.77   \n",
       "10135      33.36        27.49               48.94               58.28   \n",
       "10138      37.26        25.21               51.05               45.71   \n",
       "10147      35.31        27.42               53.97               57.47   \n",
       "10153      36.98        25.06               55.39               49.84   \n",
       "10163      23.35        38.95               48.95               67.65   \n",
       "10164      34.98        35.52               49.16               58.78   \n",
       "10174      33.92        28.58               44.67               54.53   \n",
       "10184      28.04        23.27               45.78               52.95   \n",
       "10191      30.50        26.49               45.25               48.79   \n",
       "\n",
       "       Cricopharyngeal_Muscle  Lt_thyroid_lobe  Rt_thyroid_lobe  \\\n",
       "id                                                                \n",
       "4                        8.46            48.10            57.91   \n",
       "11                      29.38            57.14            51.76   \n",
       "27                       4.01             1.02            44.56   \n",
       "29                      27.08            49.57            55.30   \n",
       "33                      41.72            61.80            54.90   \n",
       "34                      25.86            50.42            56.14   \n",
       "35                      13.07            44.35            50.04   \n",
       "36                       9.26            46.78            50.68   \n",
       "41                      14.13            47.02            54.45   \n",
       "49                      22.87            53.91            51.93   \n",
       "100                     47.42            56.11            56.79   \n",
       "102                     11.03            54.95            47.92   \n",
       "104                     15.91            50.22            57.28   \n",
       "109                     14.38            47.34            47.91   \n",
       "110                     14.29            56.97            52.03   \n",
       "114                     20.87            50.24            39.01   \n",
       "118                     16.93            49.74            51.24   \n",
       "119                      7.79            48.17             1.24   \n",
       "120                     11.38            47.80            57.13   \n",
       "125                      5.69             1.61            51.96   \n",
       "126                     17.67            51.10            49.16   \n",
       "128                     26.50            53.72            51.50   \n",
       "134                      8.51            45.74            41.95   \n",
       "136                     17.94            54.61            52.66   \n",
       "147                     39.43            52.85            51.60   \n",
       "149                     10.56            49.55            48.17   \n",
       "150                     14.62            53.33            49.67   \n",
       "152                      6.95            51.02            47.60   \n",
       "153                     15.92            51.84            37.54   \n",
       "154                     35.32            55.75            17.54   \n",
       "155                      8.60            52.46             1.51   \n",
       "156                     19.72            54.57            50.62   \n",
       "158                     14.85            50.62            52.73   \n",
       "160                      4.97            37.83             1.10   \n",
       "164                      9.56            46.36            47.73   \n",
       "169                      8.49            45.74            51.96   \n",
       "171                     24.74            46.74            42.88   \n",
       "172                     13.25            39.89            62.04   \n",
       "173                     13.58            42.50            55.08   \n",
       "176                     11.84            47.93            54.38   \n",
       "177                     24.83            46.52            48.75   \n",
       "178                      3.51             0.96            44.99   \n",
       "179                     22.56            56.18            49.08   \n",
       "180                     21.84            58.27            51.25   \n",
       "181                     17.17            46.14            52.77   \n",
       "183                     25.86            40.24            44.77   \n",
       "184                     66.74            59.94            62.27   \n",
       "185                     21.24            50.23            53.11   \n",
       "188                     25.74            41.34            44.61   \n",
       "194                     14.89            52.46            50.78   \n",
       "197                     61.53            58.39            67.31   \n",
       "200                     10.33            39.48            50.15   \n",
       "202                      2.73             0.77            43.55   \n",
       "209                     11.58            48.29            51.31   \n",
       "212                      7.08             2.13            54.92   \n",
       "213                      1.82             0.73             1.05   \n",
       "215                      5.83            37.76            38.63   \n",
       "218                     18.21            44.27            57.59   \n",
       "220                     13.88            48.96            54.71   \n",
       "221                      3.40             0.87            54.51   \n",
       "223                     10.16            54.49            42.83   \n",
       "225                     17.27            56.03            49.34   \n",
       "226                     10.96            49.48            47.85   \n",
       "228                     28.45            52.98            50.74   \n",
       "229                     21.68            52.13            49.17   \n",
       "232                     21.83            50.21            56.71   \n",
       "234                      6.10            51.27             1.13   \n",
       "236                     13.14            56.87            53.09   \n",
       "237                     25.85            53.41            48.99   \n",
       "242                     34.81            54.53            48.38   \n",
       "244                     14.45            48.68            50.47   \n",
       "246                     52.94            65.42            57.83   \n",
       "247                      8.53            40.91            41.31   \n",
       "248                      6.70            44.39            47.73   \n",
       "251                      3.66            41.70             0.99   \n",
       "252                     10.08            49.58            33.80   \n",
       "256                     19.76            50.37            54.27   \n",
       "257                     16.22            53.95            52.29   \n",
       "260                     12.49            58.08            41.40   \n",
       "261                     12.91            44.36            56.41   \n",
       "262                      6.61            44.16            55.82   \n",
       "263                     14.89            54.20            51.88   \n",
       "265                     48.27            58.04            58.39   \n",
       "267                     12.90            50.56            55.44   \n",
       "268                     14.65            48.11            52.34   \n",
       "271                      9.45            49.00            49.23   \n",
       "274                     12.01            45.53            58.38   \n",
       "276                     53.42            56.81            66.67   \n",
       "278                     30.65            52.11            49.32   \n",
       "280                     12.15            45.59            47.82   \n",
       "281                     14.03            48.44            49.24   \n",
       "283                     70.63            61.97            65.55   \n",
       "285                     42.40            48.90            53.19   \n",
       "286                     24.46            48.76            46.82   \n",
       "287                     19.40            47.74            46.08   \n",
       "289                     48.63            65.07            63.12   \n",
       "2007                     4.59            37.76             1.27   \n",
       "2011                    12.33            47.04            52.86   \n",
       "2012                    17.16            51.36            60.72   \n",
       "2023                    14.61            48.54            50.64   \n",
       "2024                     9.10            43.84            56.54   \n",
       "2026                    23.16            48.68            51.27   \n",
       "2027                    16.82            47.22            55.54   \n",
       "2028                     4.27             1.62            48.14   \n",
       "2030                    38.94            47.14            49.71   \n",
       "5004                     8.88            49.55            27.05   \n",
       "5007                    42.23            60.24            64.85   \n",
       "5008                    24.45            48.42            56.35   \n",
       "5009                    23.91            51.22            48.92   \n",
       "5011                    23.93            54.86            44.12   \n",
       "5031                     4.15             1.12            54.25   \n",
       "5034                    27.56            53.74            47.57   \n",
       "5056                    22.78            53.00            57.77   \n",
       "5067                    17.44            48.18            56.82   \n",
       "5071                    19.52            50.82            49.90   \n",
       "5077                     3.65             1.06            50.68   \n",
       "5078                    25.42            52.54            51.44   \n",
       "5081                    32.24            49.32            54.11   \n",
       "5084                    65.35            60.52            61.75   \n",
       "5090                    10.68            55.15            44.96   \n",
       "5092                    13.09            51.79            48.67   \n",
       "5100                    15.78            47.51            61.37   \n",
       "10014                   26.07            48.86            47.91   \n",
       "10036                   12.54            52.16            53.15   \n",
       "10044                   17.06            46.85            60.19   \n",
       "10061                    9.54            41.07            44.98   \n",
       "10062                   10.54            44.66            59.04   \n",
       "10063                   22.26            47.11            59.72   \n",
       "10065                   24.03            46.99            56.15   \n",
       "10071                   12.63            46.39            49.26   \n",
       "10080                   10.09             2.16            52.91   \n",
       "10083                   14.19            54.86            58.99   \n",
       "10085                    9.76            44.90            48.68   \n",
       "10092                   10.53            41.75            55.01   \n",
       "10103                   18.35            53.62            49.15   \n",
       "10113                   12.22            44.07            51.60   \n",
       "10124                   16.75            50.56            55.18   \n",
       "10129                   19.89            54.84            50.90   \n",
       "10134                   15.53            44.75            58.00   \n",
       "10135                   14.70            51.77            51.25   \n",
       "10138                   26.66            55.92            49.11   \n",
       "10147                   14.28            58.39            56.71   \n",
       "10153                   21.12            48.72            57.03   \n",
       "10163                   13.36            66.14            58.18   \n",
       "10164                   35.96            49.30            55.84   \n",
       "10174                   16.01            48.69            54.14   \n",
       "10184                    9.47            45.52            53.08   \n",
       "10191                    9.87            46.27            45.98   \n",
       "\n",
       "       Cricoid_cartilage    IPC    MPC  ...  Pathological Grade_4  \\\n",
       "id                                      ...                         \n",
       "4                   7.92  51.68  63.35  ...                 False   \n",
       "11                 34.06  51.92  71.09  ...                 False   \n",
       "27                  6.76   6.91  26.24  ...                 False   \n",
       "29                 27.40  19.49  57.43  ...                 False   \n",
       "33                 45.25  44.32  46.52  ...                 False   \n",
       "34                 25.85  13.76  46.39  ...                 False   \n",
       "35                 17.47  20.97  63.86  ...                 False   \n",
       "36                 15.14  41.35  58.76  ...                 False   \n",
       "41                 20.40  56.38  65.58  ...                 False   \n",
       "49                 28.64  19.46  58.14  ...                 False   \n",
       "100                53.20  58.94  68.48  ...                 False   \n",
       "102                12.75  35.02  62.83  ...                 False   \n",
       "104                22.80  29.11  62.24  ...                 False   \n",
       "109                21.43  15.18  61.64  ...                 False   \n",
       "110                17.63  53.72  56.14  ...                 False   \n",
       "114                25.57  28.60  55.91  ...                 False   \n",
       "118                25.81  21.72  47.34  ...                 False   \n",
       "119                 8.38  13.40  35.66  ...                 False   \n",
       "120                16.85  66.69  60.99  ...                 False   \n",
       "125                 6.81   9.20  44.15  ...                 False   \n",
       "126                24.53  33.01  57.32  ...                 False   \n",
       "128                27.21  22.90  54.08  ...                 False   \n",
       "134                11.30  52.29  63.28  ...                  True   \n",
       "136                27.57  37.77  66.68  ...                 False   \n",
       "147                36.56  17.78  56.43  ...                 False   \n",
       "149                11.81  46.90  57.78  ...                 False   \n",
       "150                20.43  29.66  60.12  ...                 False   \n",
       "152                13.85  54.62  68.11  ...                 False   \n",
       "153                15.64  47.77  57.26  ...                 False   \n",
       "154                37.09  40.18  41.72  ...                 False   \n",
       "155                11.34  17.64  46.17  ...                 False   \n",
       "156                27.19  24.03  60.46  ...                 False   \n",
       "158                20.11  28.00  71.43  ...                 False   \n",
       "160                 7.77   7.58  36.25  ...                 False   \n",
       "164                12.88  34.61  65.81  ...                 False   \n",
       "169                15.35  44.60  68.07  ...                 False   \n",
       "171                29.11  21.34  59.61  ...                 False   \n",
       "172                22.09  53.16  70.62  ...                 False   \n",
       "173                20.69  16.15  59.01  ...                 False   \n",
       "176                18.16  26.36  55.56  ...                 False   \n",
       "177                26.63  10.02  65.88  ...                 False   \n",
       "178                 7.01  18.70  35.59  ...                 False   \n",
       "179                27.78  22.35  67.94  ...                 False   \n",
       "180                27.83  36.17  72.95  ...                 False   \n",
       "181                24.47  22.27  58.11  ...                 False   \n",
       "183                24.09  55.60  66.12  ...                 False   \n",
       "184                66.41  69.57  69.64  ...                 False   \n",
       "185                33.11  26.49  57.75  ...                 False   \n",
       "188                29.30  13.82  64.44  ...                 False   \n",
       "194                19.98  47.45  66.86  ...                 False   \n",
       "197                63.11  63.29  63.83  ...                 False   \n",
       "200                16.34  35.06  61.52  ...                 False   \n",
       "202                 6.89  11.85  39.54  ...                 False   \n",
       "209                18.56  27.17  53.00  ...                 False   \n",
       "212                13.09  24.05  45.47  ...                 False   \n",
       "213                 1.84  23.22  56.94  ...                 False   \n",
       "215                 6.98  59.37  67.44  ...                 False   \n",
       "218                26.18  33.45  68.90  ...                 False   \n",
       "220                22.65  40.84  58.34  ...                 False   \n",
       "221                15.13   9.05  34.68  ...                 False   \n",
       "223                12.13  53.25  63.37  ...                 False   \n",
       "225                22.73  59.95  65.46  ...                 False   \n",
       "226                21.32  43.49  61.35  ...                 False   \n",
       "228                31.77  25.13  52.80  ...                 False   \n",
       "229                29.72  30.06  63.58  ...                 False   \n",
       "232                25.26  17.57  59.46  ...                 False   \n",
       "234                11.94  10.10  65.54  ...                 False   \n",
       "236                20.48  30.51  59.31  ...                 False   \n",
       "237                28.67  31.25  65.91  ...                 False   \n",
       "242                37.06  34.28  66.99  ...                 False   \n",
       "244                20.34  37.47  60.72  ...                 False   \n",
       "246                55.94  54.99  68.94  ...                 False   \n",
       "247                 9.25  52.21  65.57  ...                 False   \n",
       "248                14.62  35.28  61.09  ...                 False   \n",
       "251                 8.16  12.83  40.56  ...                 False   \n",
       "252                11.18  33.77  59.48  ...                 False   \n",
       "256                24.49  26.71  60.62  ...                 False   \n",
       "257                28.75  22.51  60.76  ...                 False   \n",
       "260                21.14  28.10  51.87  ...                 False   \n",
       "261                20.99  33.84  52.97  ...                 False   \n",
       "262                13.58  37.71  65.37  ...                 False   \n",
       "263                22.91  30.99  60.71  ...                 False   \n",
       "265                48.23  49.16  60.90  ...                 False   \n",
       "267                22.40  25.11  52.83  ...                 False   \n",
       "268                19.89  16.83  65.74  ...                 False   \n",
       "271                15.59  43.67  65.61  ...                 False   \n",
       "274                25.61  32.97  61.84  ...                 False   \n",
       "276                58.86  60.25  71.33  ...                 False   \n",
       "278                32.83  11.33  58.06  ...                 False   \n",
       "280                22.05  31.41  63.03  ...                 False   \n",
       "281                20.27  41.68  61.78  ...                 False   \n",
       "283                69.45  71.17  70.83  ...                 False   \n",
       "285                38.23  13.40  16.09  ...                 False   \n",
       "286                29.92  15.99  63.23  ...                 False   \n",
       "287                24.76  13.66  49.42  ...                 False   \n",
       "289                57.34  71.85  72.56  ...                 False   \n",
       "2007                5.29  15.41  48.86  ...                 False   \n",
       "2011               18.00  23.02  57.47  ...                 False   \n",
       "2012               25.04  32.92  59.17  ...                 False   \n",
       "2023               23.28  33.09  58.21  ...                 False   \n",
       "2024               19.97  35.74  57.51  ...                 False   \n",
       "2026               25.66  14.31  56.32  ...                 False   \n",
       "2027               27.80  36.73  59.90  ...                 False   \n",
       "2028               10.56  18.87  30.03  ...                 False   \n",
       "2030               37.80  11.21  54.09  ...                 False   \n",
       "5004               12.76  16.29  54.16  ...                 False   \n",
       "5007               46.07  57.63  64.76  ...                 False   \n",
       "5008               32.90  22.40  56.45  ...                  True   \n",
       "5009               29.68  37.23  63.84  ...                 False   \n",
       "5011               16.18  67.53  72.67  ...                 False   \n",
       "5031               11.48   9.56  40.33  ...                 False   \n",
       "5034               31.64  22.49  50.67  ...                 False   \n",
       "5056               29.21  20.51  30.50  ...                 False   \n",
       "5067               23.53  56.75  67.94  ...                 False   \n",
       "5071               28.65  24.71  62.45  ...                 False   \n",
       "5077                6.97  25.56  36.81  ...                 False   \n",
       "5078               28.40  41.24  61.99  ...                 False   \n",
       "5081               35.27  30.74  71.66  ...                 False   \n",
       "5084               66.10  69.05  71.78  ...                 False   \n",
       "5090               16.06  41.84  64.65  ...                 False   \n",
       "5092               18.25  40.17  68.04  ...                 False   \n",
       "5100               22.13  61.12  71.48  ...                 False   \n",
       "10014              26.54  17.74  50.86  ...                 False   \n",
       "10036              20.51  19.32  51.18  ...                 False   \n",
       "10044              23.67  38.08  67.02  ...                 False   \n",
       "10061              12.27  48.23  60.53  ...                 False   \n",
       "10062              22.11  35.84  59.34  ...                 False   \n",
       "10063              31.01  15.06  53.63  ...                 False   \n",
       "10065              28.57  14.31  50.54  ...                 False   \n",
       "10071              17.62  28.80  52.20  ...                 False   \n",
       "10080              15.82  13.06  35.39  ...                 False   \n",
       "10083              22.21  32.55  54.16  ...                 False   \n",
       "10085              18.08  43.94  64.48  ...                 False   \n",
       "10092              14.09  50.01  70.15  ...                 False   \n",
       "10103              25.50  27.96  64.90  ...                 False   \n",
       "10113              17.39  18.07  62.47  ...                 False   \n",
       "10124              21.71  39.32  67.37  ...                 False   \n",
       "10129              28.20  25.69  39.13  ...                 False   \n",
       "10134              24.51  29.53  59.07  ...                 False   \n",
       "10135              19.73  40.51  65.33  ...                 False   \n",
       "10138              36.09  23.90  54.09  ...                 False   \n",
       "10147              18.32  40.55  60.49  ...                 False   \n",
       "10153              28.73  20.14  58.61  ...                 False   \n",
       "10163              23.34  47.61  71.16  ...                 False   \n",
       "10164              35.84  12.51  49.35  ...                 False   \n",
       "10174              19.24  29.35  58.62  ...                 False   \n",
       "10184              14.38  36.17  69.30  ...                 False   \n",
       "10191              12.18  42.96  66.99  ...                 False   \n",
       "\n",
       "       subsite_BOT  subsite_GPS  subsite_Tonsil  subsite_Soft palate  \\\n",
       "id                                                                     \n",
       "4             True        False           False                False   \n",
       "11            True        False           False                False   \n",
       "27           False        False            True                False   \n",
       "29            True        False           False                False   \n",
       "33           False        False            True                False   \n",
       "34           False        False            True                False   \n",
       "35            True        False           False                False   \n",
       "36            True        False           False                False   \n",
       "41            True        False           False                False   \n",
       "49            True        False           False                False   \n",
       "100           True        False           False                False   \n",
       "102           True        False           False                False   \n",
       "104          False        False           False                False   \n",
       "109          False        False           False                False   \n",
       "110          False         True           False                False   \n",
       "114           True        False           False                False   \n",
       "118          False        False            True                False   \n",
       "119          False        False            True                False   \n",
       "120          False        False           False                False   \n",
       "125          False        False            True                False   \n",
       "126           True        False           False                False   \n",
       "128          False        False            True                False   \n",
       "134           True        False           False                False   \n",
       "136           True        False           False                False   \n",
       "147           True        False           False                False   \n",
       "149           True        False           False                False   \n",
       "150          False        False            True                False   \n",
       "152          False        False           False                False   \n",
       "153           True        False           False                False   \n",
       "154          False        False            True                False   \n",
       "155          False        False            True                False   \n",
       "156          False        False            True                False   \n",
       "158           True        False           False                False   \n",
       "160          False        False            True                False   \n",
       "164          False        False            True                False   \n",
       "169           True        False           False                False   \n",
       "171          False        False            True                False   \n",
       "172           True        False           False                False   \n",
       "173          False        False            True                False   \n",
       "176          False        False            True                False   \n",
       "177          False        False           False                False   \n",
       "178          False        False            True                False   \n",
       "179          False        False            True                False   \n",
       "180          False        False           False                False   \n",
       "181           True        False           False                False   \n",
       "183           True        False           False                False   \n",
       "184           True        False           False                False   \n",
       "185          False        False            True                False   \n",
       "188          False        False            True                False   \n",
       "194           True        False           False                False   \n",
       "197          False        False            True                False   \n",
       "200           True        False           False                False   \n",
       "202          False        False            True                False   \n",
       "209          False        False            True                False   \n",
       "212          False        False            True                False   \n",
       "213           True        False           False                False   \n",
       "215           True        False           False                False   \n",
       "218          False        False            True                False   \n",
       "220           True        False           False                False   \n",
       "221          False        False            True                False   \n",
       "223           True        False           False                False   \n",
       "225           True        False           False                False   \n",
       "226          False        False            True                False   \n",
       "228          False        False            True                False   \n",
       "229          False        False            True                False   \n",
       "232           True        False           False                False   \n",
       "234          False        False            True                False   \n",
       "236           True        False           False                False   \n",
       "237          False        False            True                False   \n",
       "242           True        False           False                False   \n",
       "244           True        False           False                False   \n",
       "246          False        False            True                False   \n",
       "247           True        False           False                False   \n",
       "248           True        False           False                False   \n",
       "251          False        False            True                False   \n",
       "252          False         True           False                False   \n",
       "256          False        False            True                False   \n",
       "257           True        False           False                False   \n",
       "260          False        False            True                False   \n",
       "261          False         True           False                False   \n",
       "262          False        False            True                False   \n",
       "263           True        False           False                False   \n",
       "265          False        False            True                False   \n",
       "267           True        False           False                False   \n",
       "268           True        False           False                False   \n",
       "271           True        False           False                False   \n",
       "274           True        False           False                False   \n",
       "276           True        False           False                False   \n",
       "278           True        False           False                False   \n",
       "280           True        False           False                False   \n",
       "281           True        False           False                False   \n",
       "283          False        False           False                False   \n",
       "285          False        False            True                False   \n",
       "286           True        False           False                False   \n",
       "287           True        False           False                False   \n",
       "289           True        False           False                False   \n",
       "2007         False        False            True                False   \n",
       "2011         False        False            True                False   \n",
       "2012          True        False           False                False   \n",
       "2023          True        False           False                False   \n",
       "2024         False        False            True                False   \n",
       "2026         False        False            True                False   \n",
       "2027         False        False            True                False   \n",
       "2028         False        False            True                False   \n",
       "2030         False        False           False                False   \n",
       "5004         False        False            True                False   \n",
       "5007          True        False           False                False   \n",
       "5008         False        False           False                False   \n",
       "5009          True        False           False                False   \n",
       "5011          True        False           False                False   \n",
       "5031         False        False            True                False   \n",
       "5034         False        False            True                False   \n",
       "5056         False        False            True                False   \n",
       "5067          True        False           False                False   \n",
       "5071          True        False           False                False   \n",
       "5077         False        False            True                False   \n",
       "5078          True        False           False                False   \n",
       "5081          True        False           False                False   \n",
       "5084          True        False           False                False   \n",
       "5090          True        False           False                False   \n",
       "5092         False        False            True                False   \n",
       "5100          True        False           False                False   \n",
       "10014        False        False            True                False   \n",
       "10036        False        False            True                False   \n",
       "10044        False        False            True                False   \n",
       "10061        False        False            True                False   \n",
       "10062         True        False           False                False   \n",
       "10063        False        False            True                False   \n",
       "10065         True        False           False                False   \n",
       "10071         True        False           False                False   \n",
       "10080        False        False            True                False   \n",
       "10083         True        False           False                False   \n",
       "10085         True        False           False                False   \n",
       "10092         True        False           False                False   \n",
       "10103         True        False           False                False   \n",
       "10113         True        False           False                False   \n",
       "10124        False        False            True                False   \n",
       "10129        False        False            True                False   \n",
       "10134         True        False           False                False   \n",
       "10135         True        False           False                False   \n",
       "10138         True        False           False                False   \n",
       "10147         True        False           False                False   \n",
       "10153        False        False            True                False   \n",
       "10163         True        False           False                False   \n",
       "10164         True        False           False                False   \n",
       "10174         True        False           False                False   \n",
       "10184        False        False            True                False   \n",
       "10191         True        False           False                False   \n",
       "\n",
       "       subsite_NOS  White/Caucasion  Hispanic/Latino  African American/Black  \\\n",
       "id                                                                             \n",
       "4            False             True            False                   False   \n",
       "11           False             True            False                   False   \n",
       "27           False             True            False                   False   \n",
       "29           False            False             True                   False   \n",
       "33           False             True            False                   False   \n",
       "34           False             True            False                   False   \n",
       "35           False             True            False                   False   \n",
       "36           False             True            False                   False   \n",
       "41           False             True            False                   False   \n",
       "49           False             True            False                   False   \n",
       "100          False             True            False                   False   \n",
       "102          False             True            False                   False   \n",
       "104           True             True            False                   False   \n",
       "109           True             True            False                   False   \n",
       "110          False             True            False                   False   \n",
       "114          False             True            False                   False   \n",
       "118          False             True            False                   False   \n",
       "119          False             True            False                   False   \n",
       "120           True             True            False                   False   \n",
       "125          False             True            False                   False   \n",
       "126          False             True            False                   False   \n",
       "128          False             True            False                   False   \n",
       "134          False             True            False                   False   \n",
       "136          False             True            False                   False   \n",
       "147          False             True            False                   False   \n",
       "149          False             True            False                   False   \n",
       "150          False             True            False                   False   \n",
       "152           True             True            False                   False   \n",
       "153          False             True            False                   False   \n",
       "154          False             True            False                   False   \n",
       "155          False             True            False                   False   \n",
       "156          False             True            False                   False   \n",
       "158          False             True            False                   False   \n",
       "160          False             True            False                   False   \n",
       "164          False             True            False                   False   \n",
       "169          False             True            False                   False   \n",
       "171          False             True            False                   False   \n",
       "172          False             True            False                   False   \n",
       "173          False             True            False                   False   \n",
       "176          False            False            False                    True   \n",
       "177           True             True            False                   False   \n",
       "178          False             True            False                   False   \n",
       "179          False             True            False                   False   \n",
       "180           True             True            False                   False   \n",
       "181          False             True            False                   False   \n",
       "183          False             True            False                   False   \n",
       "184          False             True            False                   False   \n",
       "185          False             True            False                   False   \n",
       "188          False             True            False                   False   \n",
       "194          False            False            False                   False   \n",
       "197          False             True            False                   False   \n",
       "200          False             True            False                   False   \n",
       "202          False             True            False                   False   \n",
       "209          False            False            False                   False   \n",
       "212          False             True            False                   False   \n",
       "213          False             True            False                   False   \n",
       "215          False             True            False                   False   \n",
       "218          False             True            False                   False   \n",
       "220          False             True            False                   False   \n",
       "221          False             True            False                   False   \n",
       "223          False             True            False                   False   \n",
       "225          False            False             True                   False   \n",
       "226          False             True            False                   False   \n",
       "228          False             True            False                   False   \n",
       "229          False             True            False                   False   \n",
       "232          False             True            False                   False   \n",
       "234          False             True            False                   False   \n",
       "236          False             True            False                   False   \n",
       "237          False             True            False                   False   \n",
       "242          False             True            False                   False   \n",
       "244          False             True            False                   False   \n",
       "246          False             True            False                   False   \n",
       "247          False             True            False                   False   \n",
       "248          False             True            False                   False   \n",
       "251          False             True            False                   False   \n",
       "252          False             True            False                   False   \n",
       "256          False             True            False                   False   \n",
       "257          False             True            False                   False   \n",
       "260          False             True            False                   False   \n",
       "261          False             True            False                   False   \n",
       "262          False             True            False                   False   \n",
       "263          False             True            False                   False   \n",
       "265          False             True            False                   False   \n",
       "267          False             True            False                   False   \n",
       "268          False             True            False                   False   \n",
       "271          False             True            False                   False   \n",
       "274          False             True            False                   False   \n",
       "276          False             True            False                   False   \n",
       "278          False             True            False                   False   \n",
       "280          False             True            False                   False   \n",
       "281          False             True            False                   False   \n",
       "283           True            False            False                    True   \n",
       "285          False             True            False                   False   \n",
       "286          False             True            False                   False   \n",
       "287          False             True            False                   False   \n",
       "289          False             True            False                   False   \n",
       "2007         False             True            False                   False   \n",
       "2011         False             True            False                   False   \n",
       "2012         False             True            False                   False   \n",
       "2023         False             True            False                   False   \n",
       "2024         False             True            False                   False   \n",
       "2026         False             True            False                   False   \n",
       "2027         False             True            False                   False   \n",
       "2028         False             True            False                   False   \n",
       "2030         False             True            False                   False   \n",
       "5004         False             True            False                   False   \n",
       "5007         False             True            False                   False   \n",
       "5008          True             True            False                   False   \n",
       "5009         False             True            False                   False   \n",
       "5011         False             True            False                   False   \n",
       "5031         False             True            False                   False   \n",
       "5034         False             True            False                   False   \n",
       "5056         False             True            False                   False   \n",
       "5067         False             True            False                   False   \n",
       "5071         False             True            False                   False   \n",
       "5077         False             True            False                   False   \n",
       "5078         False             True            False                   False   \n",
       "5081         False             True            False                   False   \n",
       "5084         False             True            False                   False   \n",
       "5090         False             True            False                   False   \n",
       "5092         False             True            False                   False   \n",
       "5100         False             True            False                   False   \n",
       "10014        False             True            False                   False   \n",
       "10036        False             True            False                   False   \n",
       "10044        False             True            False                   False   \n",
       "10061        False             True            False                   False   \n",
       "10062        False             True            False                   False   \n",
       "10063        False            False            False                    True   \n",
       "10065        False             True            False                   False   \n",
       "10071        False             True            False                   False   \n",
       "10080        False             True            False                   False   \n",
       "10083        False             True            False                   False   \n",
       "10085        False             True            False                   False   \n",
       "10092        False             True            False                   False   \n",
       "10103        False             True            False                   False   \n",
       "10113        False             True            False                   False   \n",
       "10124        False             True            False                   False   \n",
       "10129        False             True            False                   False   \n",
       "10134        False             True            False                   False   \n",
       "10135        False             True            False                   False   \n",
       "10138        False             True            False                   False   \n",
       "10147        False             True            False                   False   \n",
       "10153        False             True            False                   False   \n",
       "10163        False             True            False                   False   \n",
       "10164        False             True            False                   False   \n",
       "10174        False             True            False                   False   \n",
       "10184        False             True            False                   False   \n",
       "10191        False             True            False                   False   \n",
       "\n",
       "       Asian  \n",
       "id            \n",
       "4      False  \n",
       "11     False  \n",
       "27     False  \n",
       "29     False  \n",
       "33     False  \n",
       "34     False  \n",
       "35     False  \n",
       "36     False  \n",
       "41     False  \n",
       "49     False  \n",
       "100    False  \n",
       "102    False  \n",
       "104    False  \n",
       "109    False  \n",
       "110    False  \n",
       "114    False  \n",
       "118    False  \n",
       "119    False  \n",
       "120    False  \n",
       "125    False  \n",
       "126    False  \n",
       "128    False  \n",
       "134    False  \n",
       "136    False  \n",
       "147    False  \n",
       "149    False  \n",
       "150    False  \n",
       "152    False  \n",
       "153    False  \n",
       "154    False  \n",
       "155    False  \n",
       "156    False  \n",
       "158    False  \n",
       "160    False  \n",
       "164    False  \n",
       "169    False  \n",
       "171    False  \n",
       "172    False  \n",
       "173    False  \n",
       "176    False  \n",
       "177    False  \n",
       "178    False  \n",
       "179    False  \n",
       "180    False  \n",
       "181    False  \n",
       "183    False  \n",
       "184    False  \n",
       "185    False  \n",
       "188    False  \n",
       "194    False  \n",
       "197    False  \n",
       "200    False  \n",
       "202    False  \n",
       "209     True  \n",
       "212    False  \n",
       "213    False  \n",
       "215    False  \n",
       "218    False  \n",
       "220    False  \n",
       "221    False  \n",
       "223    False  \n",
       "225    False  \n",
       "226    False  \n",
       "228    False  \n",
       "229    False  \n",
       "232    False  \n",
       "234    False  \n",
       "236    False  \n",
       "237    False  \n",
       "242    False  \n",
       "244    False  \n",
       "246    False  \n",
       "247    False  \n",
       "248    False  \n",
       "251    False  \n",
       "252    False  \n",
       "256    False  \n",
       "257    False  \n",
       "260    False  \n",
       "261    False  \n",
       "262    False  \n",
       "263    False  \n",
       "265    False  \n",
       "267    False  \n",
       "268    False  \n",
       "271    False  \n",
       "274    False  \n",
       "276    False  \n",
       "278    False  \n",
       "280    False  \n",
       "281    False  \n",
       "283    False  \n",
       "285    False  \n",
       "286    False  \n",
       "287    False  \n",
       "289    False  \n",
       "2007   False  \n",
       "2011   False  \n",
       "2012   False  \n",
       "2023   False  \n",
       "2024   False  \n",
       "2026   False  \n",
       "2027   False  \n",
       "2028   False  \n",
       "2030   False  \n",
       "5004   False  \n",
       "5007   False  \n",
       "5008   False  \n",
       "5009   False  \n",
       "5011   False  \n",
       "5031   False  \n",
       "5034   False  \n",
       "5056   False  \n",
       "5067   False  \n",
       "5071   False  \n",
       "5077   False  \n",
       "5078   False  \n",
       "5081   False  \n",
       "5084   False  \n",
       "5090   False  \n",
       "5092   False  \n",
       "5100   False  \n",
       "10014  False  \n",
       "10036  False  \n",
       "10044  False  \n",
       "10061  False  \n",
       "10062  False  \n",
       "10063  False  \n",
       "10065  False  \n",
       "10071  False  \n",
       "10080  False  \n",
       "10083  False  \n",
       "10085  False  \n",
       "10092  False  \n",
       "10103  False  \n",
       "10113  False  \n",
       "10124  False  \n",
       "10129  False  \n",
       "10134  False  \n",
       "10135  False  \n",
       "10138  False  \n",
       "10147  False  \n",
       "10153  False  \n",
       "10163  False  \n",
       "10164  False  \n",
       "10174  False  \n",
       "10184  False  \n",
       "10191  False  \n",
       "\n",
       "[148 rows x 97 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('../data/camprt_datajson.json','r') as f:\n",
    "    camprtjson = json.load(f)\n",
    "camprtjson\n",
    "camprtdata = []\n",
    "organs = set()\n",
    "for item in camprtjson:\n",
    "    entry = {'id': item['ID_int']}\n",
    "    for organ, values in item['organData'].items():\n",
    "        v = float(values['meanDose'])\n",
    "        if np.isnan(v) or v == np.inf or v < 0 or v > 90:\n",
    "            print('bad value',v)\n",
    "            v = 0\n",
    "        entry[organ] = v\n",
    "        organs.add(organ)\n",
    "    camprtdata.append(entry)\n",
    "camprtdf = pd.DataFrame(camprtdata).set_index('id')\n",
    "merged_camprt = camprtdf.merge(lns,on='id',how='inner').merge(get_camprt_data(),on='id').set_index('id')\n",
    "organs = sorted(organs)\n",
    "merged_camprt.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58ee3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43.059837341308594 42.487918853759766\n",
      "1 41.928707122802734 38.931026458740234\n",
      "2 38.32482147216797 34.30946731567383\n",
      "3 33.42279815673828 30.164064407348633\n",
      "4 28.985782623291016 27.12162971496582\n",
      "5 25.46324348449707 25.67548942565918\n",
      "6 23.962848663330078 25.157995223999023\n",
      "7 23.93639373779297 24.741668701171875\n",
      "8 24.153457641601562 24.48395347595215\n",
      "9 23.970123291015625 23.863065719604492\n",
      "10 23.16248893737793 23.440305709838867\n",
      "11 22.474008560180664 22.895872116088867\n",
      "12 22.15484046936035 22.608478546142578\n",
      "13 21.907764434814453 22.235374450683594\n",
      "14 21.63998031616211 21.859718322753906\n",
      "15 21.364011764526367 21.50958824157715\n",
      "16 21.08566665649414 21.299558639526367\n",
      "17 20.83793830871582 20.97184944152832\n",
      "18 20.414793014526367 20.58218002319336\n",
      "19 19.981769561767578 20.08932113647461\n",
      "20 19.486967086791992 19.554922103881836\n",
      "21 18.928707122802734 18.62929344177246\n",
      "22 18.151662826538086 18.198280334472656\n",
      "23 17.443147659301758 17.380544662475586\n",
      "24 16.74286460876465 16.464487075805664\n",
      "25 15.931344985961914 15.668822288513184\n",
      "26 15.329158782958984 14.805291175842285\n",
      "27 14.656466484069824 13.97754955291748\n",
      "28 13.68547534942627 12.955242156982422\n",
      "29 12.805435180664062 11.700862884521484\n",
      "30 11.649497032165527 10.50694465637207\n",
      "31 10.470032691955566 9.210077285766602\n",
      "32 9.070372581481934 7.574252605438232\n",
      "33 7.544774532318115 6.441939830780029\n",
      "34 6.33382511138916 5.202669143676758\n",
      "35 5.21384859085083 4.322292327880859\n",
      "36 4.108932971954346 4.038602352142334\n",
      "37 3.5571017265319824 3.9121696949005127\n",
      "38 3.3463969230651855 4.030881404876709\n",
      "39 3.4906156063079834 4.257594585418701\n",
      "40 3.5272533893585205 4.295333385467529\n",
      "41 3.6109018325805664 4.349320888519287\n",
      "42 3.5910096168518066 4.216897010803223\n",
      "43 3.494434356689453 3.973782777786255\n",
      "44 3.2532994747161865 3.8100576400756836\n",
      "45 3.1771483421325684 3.681069850921631\n",
      "46 2.997530937194824 3.5117368698120117\n",
      "47 2.806776762008667 3.4051969051361084\n",
      "48 2.7487592697143555 3.5554800033569336\n",
      "49 2.749055862426758 3.430278778076172\n",
      "50 2.7285361289978027 3.2425777912139893\n",
      "51 2.6725306510925293 3.3165066242218018\n",
      "52 2.5632779598236084 3.2017617225646973\n",
      "53 2.5220947265625 3.241475820541382\n",
      "54 2.5560622215270996 3.111874580383301\n",
      "55 2.461668014526367 3.3571038246154785\n",
      "56 2.3899924755096436 3.37666392326355\n",
      "57 2.3865654468536377 3.2902157306671143\n",
      "58 2.3530046939849854 3.2364137172698975\n",
      "59 2.290773868560791 3.35477876663208\n",
      "60 2.249572515487671 3.1325433254241943\n",
      "61 2.2543811798095703 3.055294990539551\n",
      "62 2.1756303310394287 3.13311505317688\n",
      "63 2.1553525924682617 3.2155921459198\n",
      "64 2.185331106185913 3.1412911415100098\n",
      "65 2.167757511138916 3.163482666015625\n",
      "66 2.0837903022766113 3.235579490661621\n",
      "67 2.1111340522766113 3.2039365768432617\n",
      "68 2.0989580154418945 3.231388807296753\n",
      "69 2.04646897315979 3.378509759902954\n",
      "70 2.035977602005005 3.258620500564575\n",
      "71 2.0669121742248535 3.1846702098846436\n",
      "72 2.001206159591675 3.172278881072998\n",
      "73 1.9963243007659912 3.1157138347625732\n",
      "74 1.9936670064926147 3.2743053436279297\n",
      "75 1.9443408250808716 3.184868574142456\n",
      "76 2.0063459873199463 3.1526410579681396\n",
      "77 1.9635484218597412 3.338918924331665\n",
      "78 1.9217780828475952 3.2635326385498047\n",
      "79 1.892841100692749 3.2408790588378906\n",
      "80 1.8678396940231323 3.2753477096557617\n",
      "81 1.8767950534820557 3.390587329864502\n",
      "82 1.8612667322158813 3.344409942626953\n",
      "83 1.8361008167266846 3.5304670333862305\n",
      "84 1.8167178630828857 3.434046983718872\n",
      "85 1.8442001342773438 3.407043218612671\n",
      "86 1.775945782661438 3.4963371753692627\n",
      "87 1.8224581480026245 3.4681551456451416\n",
      "88 1.7767162322998047 3.4542951583862305\n",
      "89 1.788460373878479 3.4914793968200684\n",
      "90 1.8041175603866577 3.407764196395874\n",
      "91 1.802187442779541 3.288766622543335\n",
      "92 1.762613296508789 3.5279171466827393\n",
      "93 1.7702964544296265 3.2812609672546387\n",
      "94 1.73220956325531 3.4391729831695557\n",
      "95 1.7663509845733643 3.444014310836792\n",
      "96 1.6670809984207153 3.306990623474121\n",
      "97 1.6681880950927734 3.5014028549194336\n",
      "98 1.6914269924163818 3.54573655128479\n",
      "99 1.6833038330078125 3.677100419998169\n",
      "100 1.6019946336746216 3.544248104095459\n",
      "101 1.6821552515029907 3.7585339546203613\n",
      "102 1.6503701210021973 3.7600247859954834\n",
      "103 1.5540027618408203 3.933338165283203\n",
      "104 1.5734686851501465 3.8943698406219482\n",
      "105 1.5607572793960571 3.8263118267059326\n",
      "106 1.5547592639923096 3.8803346157073975\n",
      "107 1.5292528867721558 3.7529752254486084\n",
      "108 1.562394618988037 3.8379101753234863\n",
      "109 1.5551998615264893 3.8299875259399414\n",
      "110 1.5674505233764648 3.966453790664673\n",
      "111 1.4309455156326294 3.6596851348876953\n",
      "112 1.436618447303772 3.8828864097595215\n",
      "113 1.463962435722351 4.106396675109863\n",
      "114 1.4849472045898438 3.84889554977417\n",
      "115 1.4251344203948975 3.951988697052002\n",
      "116 1.3812726736068726 4.259631156921387\n",
      "117 1.2701691389083862 4.227697372436523\n",
      "118 1.317376971244812 4.315565586090088\n",
      "119 1.2838871479034424 4.316661834716797\n",
      "120 1.3374483585357666 4.336331367492676\n",
      "121 1.2457475662231445 4.443406581878662\n",
      "122 1.3789623975753784 4.398275375366211\n",
      "123 1.147695541381836 4.126383304595947\n",
      "124 1.15518057346344 4.097699165344238\n",
      "125 1.2107235193252563 4.449732780456543\n",
      "126 1.2385714054107666 4.4614129066467285\n",
      "127 1.1637287139892578 4.7380266189575195\n",
      "128 1.1714187860488892 4.812313079833984\n",
      "129 1.205641746520996 4.527214050292969\n",
      "130 1.1805543899536133 4.707040786743164\n",
      "131 1.1260911226272583 4.57926607131958\n",
      "132 1.1664299964904785 4.4570088386535645\n",
      "133 0.9994803071022034 4.545095920562744\n",
      "134 1.014385461807251 4.4572906494140625\n",
      "135 1.0207114219665527 4.596251010894775\n",
      "136 1.038490653038025 4.556636333465576\n",
      "137 1.0149340629577637 4.554295539855957\n",
      "138 0.9845500588417053 4.730224132537842\n",
      "139 0.9646022319793701 4.669842720031738\n",
      "140 0.9247973561286926 4.356832504272461\n",
      "141 0.9745187759399414 4.663944244384766\n",
      "142 0.932931125164032 4.593439102172852\n",
      "143 0.9387467503547668 4.3904547691345215\n",
      "144 1.0021116733551025 4.283681392669678\n",
      "145 0.8703933954238892 4.341609954833984\n",
      "146 0.9270483255386353 4.581656455993652\n",
      "147 0.9252471923828125 4.759748935699463\n",
      "148 0.9502893090248108 4.926430702209473\n",
      "149 0.8876978158950806 4.515044212341309\n",
      "150 0.8742227554321289 4.676330089569092\n",
      "151 0.868707537651062 4.801356792449951\n",
      "152 0.9658640027046204 4.66193962097168\n",
      "153 0.8456839919090271 4.403162956237793\n",
      "154 0.8491520285606384 4.459670066833496\n",
      "155 0.899077296257019 4.252761363983154\n",
      "156 0.9140081405639648 4.5309648513793945\n",
      "157 0.8116481304168701 4.340949535369873\n",
      "158 0.8385984301567078 4.53318452835083\n",
      "159 0.846284806728363 4.371974945068359\n",
      "160 0.8061832785606384 4.627530574798584\n",
      "161 0.8306758999824524 4.539916515350342\n",
      "162 0.8138943314552307 4.701446056365967\n",
      "best loss 3.055294990539551 62\n"
     ]
    }
   ],
   "source": [
    "def dose_mse_loss(ypred, y):\n",
    "    #ignores loss in the autoencoder for missing values (-1 here)\n",
    "    scale=y.shape[1]\n",
    "    y = torch.flatten(y)\n",
    "    y = y\n",
    "    ypred = torch.flatten(ypred)\n",
    "    out = ((ypred - y))**2\n",
    "    loss = out.mean()/scale\n",
    "    return loss\n",
    "\n",
    "patience=100\n",
    "epochs=10000\n",
    "dose_save_file = '../resources/doseImputerTemp.pt'\n",
    "lr = .1\n",
    "\n",
    "ydf = merged_camprt[organs].fillna(0)\n",
    "xdf = merged_camprt.drop(ydf.columns,axis=1).fillna(0)\n",
    "\n",
    "ymax = ydf.max().max()\n",
    "dosemodel = SymptomPredictor(xdf.shape[1],ydf.shape[1],\n",
    "                             hidden_layers=[1000,100],\n",
    "                             max_rating=ymax,dropout=.1)\n",
    "train_ids = xdf.sample(frac=.7,replace=False).index\n",
    "test_ids = xdf.drop(train_ids).index\n",
    "\n",
    "xtrain = df_to_torch(xdf.loc[train_ids])\n",
    "ytrain = df_to_torch(ydf.loc[train_ids])\n",
    "xtest = df_to_torch(xdf.loc[test_ids])\n",
    "ytest = df_to_torch(ydf.loc[test_ids])\n",
    "\n",
    "dosemodel.fit_normalizer(xtrain)\n",
    "optimizer = torch.optim.Adam(dosemodel.parameters(),lr=lr)\n",
    "best_loss = 1000000000000000000000000\n",
    "steps_since_improvement=0\n",
    "\n",
    "dosemodel.train()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    ypred = dosemodel(xtrain)\n",
    "    loss = dose_mse_loss(ypred,ytrain)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    ypred_test = dosemodel(xtest)\n",
    "    val_loss = dose_mse_loss(ypred_test,ytest)\n",
    "    print(epoch,loss.item(),val_loss.item())\n",
    "    steps_since_improvement+=1\n",
    "    if val_loss.item() < best_loss:\n",
    "        best_loss = val_loss.item()\n",
    "        steps_since_improvement=0\n",
    "        torch.save(dosemodel.state_dict(),dose_save_file)\n",
    "    if steps_since_improvement > patience:\n",
    "        break\n",
    "dosemodel.load_state_dict(torch.load(dose_save_file))\n",
    "dosemodel.eval()\n",
    "print('best loss',best_loss,epoch-patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c681ad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymptomPredictor(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=50, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final_layer): Linear(in_features=100, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(dosemodel,Const.dosemodel_file )\n",
    "torch.load(Const.dosemodel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0067f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [10164, 10147, 10092, 218, 10135, 10044, 262, 10129, 179, 10138],\n",
       " 'distances': [1.84, 2.03, 2.77, 3.06, 3.18, 3.7, 3.78, 3.81, 3.87, 3.91],\n",
       " 'doses': {'Esophagus': {'mean': 34.071,\n",
       "   'max': 37.95,\n",
       "   'min': 25.29,\n",
       "   'values': [34.98,\n",
       "    35.31,\n",
       "    33.97,\n",
       "    34.9,\n",
       "    33.36,\n",
       "    32.64,\n",
       "    25.29,\n",
       "    35.05,\n",
       "    37.95,\n",
       "    37.26]},\n",
       "  'Spinal_Cord': {'mean': 28.15,\n",
       "   'max': 35.52,\n",
       "   'min': 24.31,\n",
       "   'values': [35.52,\n",
       "    27.42,\n",
       "    24.31,\n",
       "    25.99,\n",
       "    27.49,\n",
       "    27.44,\n",
       "    27.84,\n",
       "    31.63,\n",
       "    28.65,\n",
       "    25.21]},\n",
       "  'Lt_Brachial_Plexus': {'mean': 49.853,\n",
       "   'max': 57.92,\n",
       "   'min': 38.66,\n",
       "   'values': [49.16,\n",
       "    53.97,\n",
       "    46.64,\n",
       "    38.66,\n",
       "    48.94,\n",
       "    48.41,\n",
       "    49.7,\n",
       "    54.08,\n",
       "    57.92,\n",
       "    51.05]},\n",
       "  'Rt_Brachial_Plexus': {'mean': 54.21,\n",
       "   'max': 60.86,\n",
       "   'min': 45.71,\n",
       "   'values': [58.78,\n",
       "    57.47,\n",
       "    54.9,\n",
       "    55.49,\n",
       "    58.28,\n",
       "    57.11,\n",
       "    60.86,\n",
       "    46.31,\n",
       "    47.19,\n",
       "    45.71]},\n",
       "  'Cricopharyngeal_Muscle': {'mean': 18.646,\n",
       "   'max': 35.96,\n",
       "   'min': 6.61,\n",
       "   'values': [35.96,\n",
       "    14.28,\n",
       "    10.53,\n",
       "    18.21,\n",
       "    14.7,\n",
       "    17.06,\n",
       "    6.61,\n",
       "    19.89,\n",
       "    22.56,\n",
       "    26.66]},\n",
       "  'Lt_thyroid_lobe': {'mean': 50.343,\n",
       "   'max': 58.39,\n",
       "   'min': 41.75,\n",
       "   'values': [49.3,\n",
       "    58.39,\n",
       "    41.75,\n",
       "    44.27,\n",
       "    51.77,\n",
       "    46.85,\n",
       "    44.16,\n",
       "    54.84,\n",
       "    56.18,\n",
       "    55.92]},\n",
       "  'Rt_thyroid_lobe': {'mean': 54.15,\n",
       "   'max': 60.19,\n",
       "   'min': 49.08,\n",
       "   'values': [55.84,\n",
       "    56.71,\n",
       "    55.01,\n",
       "    57.59,\n",
       "    51.25,\n",
       "    60.19,\n",
       "    55.82,\n",
       "    50.9,\n",
       "    49.08,\n",
       "    49.11]},\n",
       "  'Cricoid_cartilage': {'mean': 24.348000000000003,\n",
       "   'max': 36.09,\n",
       "   'min': 13.58,\n",
       "   'values': [35.84,\n",
       "    18.32,\n",
       "    14.09,\n",
       "    26.18,\n",
       "    19.73,\n",
       "    23.67,\n",
       "    13.58,\n",
       "    28.2,\n",
       "    27.78,\n",
       "    36.09]},\n",
       "  'IPC': {'mean': 32.476,\n",
       "   'max': 50.01,\n",
       "   'min': 12.51,\n",
       "   'values': [12.51,\n",
       "    40.55,\n",
       "    50.01,\n",
       "    33.45,\n",
       "    40.51,\n",
       "    38.08,\n",
       "    37.71,\n",
       "    25.69,\n",
       "    22.35,\n",
       "    23.9]},\n",
       "  'MPC': {'mean': 60.77700000000001,\n",
       "   'max': 70.15,\n",
       "   'min': 39.13,\n",
       "   'values': [49.35,\n",
       "    60.49,\n",
       "    70.15,\n",
       "    68.9,\n",
       "    65.33,\n",
       "    67.02,\n",
       "    65.37,\n",
       "    39.13,\n",
       "    67.94,\n",
       "    54.09]},\n",
       "  'Brainstem': {'mean': 15.838,\n",
       "   'max': 20.19,\n",
       "   'min': 9.69,\n",
       "   'values': [16.71,\n",
       "    15.1,\n",
       "    14.62,\n",
       "    9.69,\n",
       "    16.65,\n",
       "    14.68,\n",
       "    15.74,\n",
       "    16.8,\n",
       "    18.2,\n",
       "    20.19]},\n",
       "  'Larynx': {'mean': 25.725,\n",
       "   'max': 37.17,\n",
       "   'min': 20.42,\n",
       "   'values': [23.79,\n",
       "    25.79,\n",
       "    37.17,\n",
       "    22.87,\n",
       "    25.72,\n",
       "    25.33,\n",
       "    25.55,\n",
       "    21.53,\n",
       "    20.42,\n",
       "    29.08]},\n",
       "  'Thyroid_cartilage': {'mean': 37.968999999999994,\n",
       "   'max': 49.58,\n",
       "   'min': 32.6,\n",
       "   'values': [32.6,\n",
       "    39.46,\n",
       "    49.58,\n",
       "    34.44,\n",
       "    42.2,\n",
       "    36.55,\n",
       "    35.31,\n",
       "    35.16,\n",
       "    33.63,\n",
       "    40.76]},\n",
       "  'Rt_Sternocleidomastoid_M': {'mean': 60.614,\n",
       "   'max': 64.87,\n",
       "   'min': 53.36,\n",
       "   'values': [64.87,\n",
       "    61.56,\n",
       "    63.01,\n",
       "    63.04,\n",
       "    64.36,\n",
       "    63.53,\n",
       "    64.54,\n",
       "    53.87,\n",
       "    54.0,\n",
       "    53.36]},\n",
       "  'Rt_Mastoid': {'mean': 44.733000000000004,\n",
       "   'max': 63.28,\n",
       "   'min': 21.11,\n",
       "   'values': [63.28,\n",
       "    29.69,\n",
       "    39.71,\n",
       "    61.68,\n",
       "    21.11,\n",
       "    60.83,\n",
       "    61.68,\n",
       "    47.99,\n",
       "    34.38,\n",
       "    26.98]},\n",
       "  'Rt_Parotid_Gland': {'mean': 34.863,\n",
       "   'max': 58.17,\n",
       "   'min': 18.45,\n",
       "   'values': [55.52,\n",
       "    26.52,\n",
       "    35.16,\n",
       "    44.43,\n",
       "    25.12,\n",
       "    58.17,\n",
       "    45.16,\n",
       "    20.0,\n",
       "    18.45,\n",
       "    20.1]},\n",
       "  'Rt_Medial_Pterygoid_M': {'mean': 62.561000000000014,\n",
       "   'max': 72.19,\n",
       "   'min': 49.5,\n",
       "   'values': [68.96,\n",
       "    65.79,\n",
       "    71.95,\n",
       "    71.53,\n",
       "    53.47,\n",
       "    72.19,\n",
       "    71.62,\n",
       "    50.64,\n",
       "    49.5,\n",
       "    49.96]},\n",
       "  'Rt_Lateral_Pterygoid_M': {'mean': 49.523999999999994,\n",
       "   'max': 69.87,\n",
       "   'min': 26.82,\n",
       "   'values': [57.54,\n",
       "    52.48,\n",
       "    63.23,\n",
       "    60.16,\n",
       "    26.82,\n",
       "    69.87,\n",
       "    64.0,\n",
       "    37.14,\n",
       "    36.37,\n",
       "    27.63]},\n",
       "  'Rt_Masseter_M': {'mean': 38.141000000000005,\n",
       "   'max': 62.9,\n",
       "   'min': 23.62,\n",
       "   'values': [48.45,\n",
       "    35.29,\n",
       "    42.03,\n",
       "    43.51,\n",
       "    25.72,\n",
       "    62.9,\n",
       "    43.85,\n",
       "    27.72,\n",
       "    28.32,\n",
       "    23.62]},\n",
       "  'Lt_Sternocleidomastoid_M': {'mean': 57.597,\n",
       "   'max': 69.24,\n",
       "   'min': 52.03,\n",
       "   'values': [52.27,\n",
       "    58.48,\n",
       "    55.07,\n",
       "    52.03,\n",
       "    54.06,\n",
       "    53.14,\n",
       "    52.88,\n",
       "    65.84,\n",
       "    69.24,\n",
       "    62.96]},\n",
       "  'Lt_Mastoid': {'mean': 41.906000000000006,\n",
       "   'max': 61.63,\n",
       "   'min': 27.48,\n",
       "   'values': [33.33,\n",
       "    29.12,\n",
       "    31.68,\n",
       "    40.61,\n",
       "    27.48,\n",
       "    35.45,\n",
       "    46.52,\n",
       "    61.63,\n",
       "    52.8,\n",
       "    60.44]},\n",
       "  'Lt_Parotid_Gland': {'mean': 28.878999999999998,\n",
       "   'max': 52.1,\n",
       "   'min': 18.08,\n",
       "   'values': [22.24,\n",
       "    25.37,\n",
       "    27.46,\n",
       "    23.5,\n",
       "    25.76,\n",
       "    18.08,\n",
       "    19.69,\n",
       "    32.81,\n",
       "    52.1,\n",
       "    41.78]},\n",
       "  'Lt_Submandibular_Gland': {'mean': 64.926,\n",
       "   'max': 73.55,\n",
       "   'min': 59.3,\n",
       "   'values': [59.3,\n",
       "    68.21,\n",
       "    64.34,\n",
       "    59.47,\n",
       "    69.45,\n",
       "    60.57,\n",
       "    59.34,\n",
       "    62.79,\n",
       "    72.24,\n",
       "    73.55]},\n",
       "  'Lt_Medial_Pterygoid_M': {'mean': 59.124,\n",
       "   'max': 72.95,\n",
       "   'min': 45.83,\n",
       "   'values': [45.83,\n",
       "    60.29,\n",
       "    55.25,\n",
       "    50.53,\n",
       "    52.05,\n",
       "    57.51,\n",
       "    56.38,\n",
       "    68.32,\n",
       "    72.13,\n",
       "    72.95]},\n",
       "  'Lt_Lateral_Pterygoid_M': {'mean': 43.272000000000006,\n",
       "   'max': 64.42,\n",
       "   'min': 21.08,\n",
       "   'values': [29.36,\n",
       "    34.82,\n",
       "    30.52,\n",
       "    41.93,\n",
       "    21.08,\n",
       "    37.59,\n",
       "    47.42,\n",
       "    61.47,\n",
       "    64.11,\n",
       "    64.42]},\n",
       "  'Lt_Masseter_M': {'mean': 33.905,\n",
       "   'max': 56.15,\n",
       "   'min': 21.85,\n",
       "   'values': [21.85,\n",
       "    30.96,\n",
       "    29.85,\n",
       "    33.02,\n",
       "    23.11,\n",
       "    32.92,\n",
       "    25.32,\n",
       "    38.24,\n",
       "    56.15,\n",
       "    47.63]},\n",
       "  'Supraglottic_Larynx': {'mean': 55.56700000000001,\n",
       "   'max': 68.01,\n",
       "   'min': 33.47,\n",
       "   'values': [46.95,\n",
       "    63.23,\n",
       "    66.68,\n",
       "    58.14,\n",
       "    61.88,\n",
       "    61.48,\n",
       "    68.01,\n",
       "    33.47,\n",
       "    51.42,\n",
       "    44.41]},\n",
       "  'SPC': {'mean': 67.332,\n",
       "   'max': 71.03,\n",
       "   'min': 62.82,\n",
       "   'values': [63.64,\n",
       "    67.58,\n",
       "    71.03,\n",
       "    68.41,\n",
       "    66.02,\n",
       "    70.23,\n",
       "    68.88,\n",
       "    62.82,\n",
       "    69.08,\n",
       "    65.63]},\n",
       "  'Rt_Submandibular_Gland': {'mean': 64.312,\n",
       "   'max': 71.94,\n",
       "   'min': 31.63,\n",
       "   'values': [71.71,\n",
       "    71.75,\n",
       "    71.39,\n",
       "    71.79,\n",
       "    71.94,\n",
       "    71.62,\n",
       "    71.94,\n",
       "    31.63,\n",
       "    51.97,\n",
       "    57.38]},\n",
       "  'Hyoid_bone': {'mean': 65.354,\n",
       "   'max': 72.36,\n",
       "   'min': 40.88,\n",
       "   'values': [65.91,\n",
       "    72.09,\n",
       "    72.3,\n",
       "    71.18,\n",
       "    72.36,\n",
       "    70.27,\n",
       "    71.71,\n",
       "    40.88,\n",
       "    65.65,\n",
       "    51.19]},\n",
       "  'Soft_Palate': {'mean': 66.768,\n",
       "   'max': 71.98,\n",
       "   'min': 50.19,\n",
       "   'values': [65.0,\n",
       "    66.34,\n",
       "    71.98,\n",
       "    69.87,\n",
       "    50.19,\n",
       "    70.75,\n",
       "    70.76,\n",
       "    62.12,\n",
       "    70.93,\n",
       "    69.74]},\n",
       "  'Genioglossus_M': {'mean': 64.66799999999999,\n",
       "   'max': 71.64,\n",
       "   'min': 49.14,\n",
       "   'values': [70.56,\n",
       "    71.64,\n",
       "    71.51,\n",
       "    65.96,\n",
       "    69.64,\n",
       "    66.46,\n",
       "    64.33,\n",
       "    49.14,\n",
       "    63.4,\n",
       "    54.04]},\n",
       "  'Tongue': {'mean': 61.373000000000005,\n",
       "   'max': 71.6,\n",
       "   'min': 52.79,\n",
       "   'values': [67.44,\n",
       "    63.54,\n",
       "    71.6,\n",
       "    61.03,\n",
       "    52.79,\n",
       "    63.9,\n",
       "    61.36,\n",
       "    54.61,\n",
       "    59.15,\n",
       "    58.31]},\n",
       "  'Rt_Ant_Digastric_M': {'mean': 56.947,\n",
       "   'max': 66.36,\n",
       "   'min': 37.2,\n",
       "   'values': [63.73,\n",
       "    63.84,\n",
       "    64.98,\n",
       "    65.86,\n",
       "    66.36,\n",
       "    64.04,\n",
       "    65.95,\n",
       "    37.42,\n",
       "    40.09,\n",
       "    37.2]},\n",
       "  'Lt_Ant_Digastric_M': {'mean': 59.741,\n",
       "   'max': 70.11,\n",
       "   'min': 49.58,\n",
       "   'values': [62.45,\n",
       "    64.9,\n",
       "    64.82,\n",
       "    50.16,\n",
       "    70.11,\n",
       "    49.58,\n",
       "    57.88,\n",
       "    55.58,\n",
       "    67.39,\n",
       "    54.54]},\n",
       "  'Mylogeniohyoid_M': {'mean': 59.737,\n",
       "   'max': 69.71,\n",
       "   'min': 45.2,\n",
       "   'values': [65.34,\n",
       "    69.71,\n",
       "    67.8,\n",
       "    58.82,\n",
       "    66.65,\n",
       "    58.98,\n",
       "    61.18,\n",
       "    45.2,\n",
       "    56.78,\n",
       "    46.91]},\n",
       "  'Extended_Oral_Cavity': {'mean': 58.291999999999994,\n",
       "   'max': 67.0,\n",
       "   'min': 46.08,\n",
       "   'values': [65.01,\n",
       "    58.85,\n",
       "    67.0,\n",
       "    59.24,\n",
       "    50.76,\n",
       "    62.0,\n",
       "    59.79,\n",
       "    46.08,\n",
       "    58.55,\n",
       "    55.64]},\n",
       "  'Mandible': {'mean': 45.98799999999999,\n",
       "   'max': 51.02,\n",
       "   'min': 39.51,\n",
       "   'values': [48.94,\n",
       "    48.16,\n",
       "    47.84,\n",
       "    43.07,\n",
       "    39.51,\n",
       "    51.02,\n",
       "    47.44,\n",
       "    40.91,\n",
       "    48.03,\n",
       "    44.96]},\n",
       "  'Hard_Palate': {'mean': 35.714999999999996,\n",
       "   'max': 48.27,\n",
       "   'min': 13.12,\n",
       "   'values': [34.17,\n",
       "    30.19,\n",
       "    44.28,\n",
       "    37.86,\n",
       "    13.12,\n",
       "    37.64,\n",
       "    48.27,\n",
       "    34.14,\n",
       "    48.12,\n",
       "    29.36]},\n",
       "  'Lt_Posterior_Seg_Eyeball': {'mean': 1.2710000000000001,\n",
       "   'max': 1.88,\n",
       "   'min': 0.68,\n",
       "   'values': [1.03, 1.11, 1.12, 1.13, 0.68, 1.41, 1.6, 1.64, 1.88, 1.11]},\n",
       "  'Rt_Posterior_Seg_Eyeball': {'mean': 1.3610000000000002,\n",
       "   'max': 1.87,\n",
       "   'min': 0.64,\n",
       "   'values': [1.18, 1.33, 1.46, 1.37, 0.64, 1.57, 1.87, 1.54, 1.62, 1.03]},\n",
       "  'Lt_Anterior_Seg_Eyeball': {'mean': 1.0740000000000003,\n",
       "   'max': 1.47,\n",
       "   'min': 0.67,\n",
       "   'values': [0.99, 1.03, 0.96, 0.93, 0.67, 1.16, 1.31, 1.3, 1.47, 0.92]},\n",
       "  'Rt_Anterior_Seg_Eyeball': {'mean': 1.152,\n",
       "   'max': 1.54,\n",
       "   'min': 0.61,\n",
       "   'values': [1.1, 1.17, 1.08, 1.1, 0.61, 1.17, 1.54, 1.43, 1.4, 0.92]},\n",
       "  'Lower_Lip': {'mean': 28.317,\n",
       "   'max': 34.9,\n",
       "   'min': 17.81,\n",
       "   'values': [34.9,\n",
       "    28.57,\n",
       "    33.2,\n",
       "    19.88,\n",
       "    17.81,\n",
       "    29.2,\n",
       "    32.78,\n",
       "    22.2,\n",
       "    30.01,\n",
       "    34.62]},\n",
       "  'Upper_Lip': {'mean': 20.947000000000003,\n",
       "   'max': 30.11,\n",
       "   'min': 9.69,\n",
       "   'values': [19.05,\n",
       "    20.57,\n",
       "    30.11,\n",
       "    18.26,\n",
       "    9.69,\n",
       "    22.61,\n",
       "    29.66,\n",
       "    18.41,\n",
       "    21.15,\n",
       "    19.96]},\n",
       "  'GTVp': {'mean': 72.451,\n",
       "   'max': 73.46,\n",
       "   'min': 71.97,\n",
       "   'values': [72.98,\n",
       "    72.05,\n",
       "    72.25,\n",
       "    72.14,\n",
       "    72.15,\n",
       "    71.97,\n",
       "    72.31,\n",
       "    72.56,\n",
       "    72.64,\n",
       "    73.46]},\n",
       "  'GTVn': {'mean': 71.68299999999999,\n",
       "   'max': 74.19,\n",
       "   'min': 69.56,\n",
       "   'values': [72.24,\n",
       "    69.67,\n",
       "    72.13,\n",
       "    71.54,\n",
       "    71.61,\n",
       "    71.08,\n",
       "    72.15,\n",
       "    69.56,\n",
       "    72.66,\n",
       "    74.19]}}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dose_knn(fdict,dmodel,camprt_df, organ_order=None,k=10):\n",
    "    if organ_order is None:\n",
    "        organ_order = Const.organ_order[:]\n",
    "    \n",
    "    camprt_input = camprt_df.drop(organ_order,axis=1)\n",
    "    order = camprt_input.columns\n",
    "    xin = torch.tensor([fdict[k] for k in order]).type(torch.FloatTensor).view(1,-1) \n",
    "    embeddings = dmodel.get_embedding(xin).cpu().detach().numpy()\n",
    "    \n",
    "    xalt = df_to_torch(camprt_input.fillna(0))\n",
    "    alt_embeddings = dmodel.get_embedding(xalt).cpu().detach().numpy()\n",
    "    \n",
    "    dists = cdist(embeddings,alt_embeddings)[0]\n",
    "    dorder = np.argsort(dists)[:k]\n",
    "    dists = dists[dorder]\n",
    "    \n",
    "    camprt_doses = camprt_df[organ_order]\n",
    "    sim_doses = camprt_doses.iloc[dorder]\n",
    "    mean_dose = sim_doses.mean().to_dict()\n",
    "    result = {}\n",
    "    for organ,meanval in mean_dose.items():\n",
    "        entry = {'mean': meanval}\n",
    "        other = sim_doses[organ].values.tolist()\n",
    "        entry['max'] = np.max(other)\n",
    "        entry['min'] = np.min(other)\n",
    "        entry['values'] = other\n",
    "        result[organ] = entry\n",
    "    dists = [np.round(d,2) for d in dists]\n",
    "    return {'ids': camprt_df.index[dorder].tolist(), 'distances':dists, 'doses': result}\n",
    "\n",
    "get_dose_knn(test_patient,dosemodel,merged_camprt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63631166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Esophagus': 15.907598,\n",
       " 'Spinal_Cord': 31.586063,\n",
       " 'Lt_Brachial_Plexus': 23.10606,\n",
       " 'Rt_Brachial_Plexus': 31.531345,\n",
       " 'Cricopharyngeal_Muscle': 53.54892,\n",
       " 'Lt_thyroid_lobe': 86.25,\n",
       " 'Rt_thyroid_lobe': 55.870605,\n",
       " 'Cricoid_cartilage': 64.25154,\n",
       " 'IPC': 36.65653,\n",
       " 'MPC': 66.13756,\n",
       " 'Brainstem': 35.4671,\n",
       " 'Larynx': 27.172567,\n",
       " 'Thyroid_cartilage': 26.4124,\n",
       " 'Rt_Sternocleidomastoid_M': 56.649967,\n",
       " 'Rt_Mastoid': 0.0,\n",
       " 'Rt_Parotid_Gland': 46.541172,\n",
       " 'Rt_Medial_Pterygoid_M': 39.9338,\n",
       " 'Rt_Lateral_Pterygoid_M': 30.849422,\n",
       " 'Rt_Masseter_M': 40.807407,\n",
       " 'Lt_Sternocleidomastoid_M': 55.16181,\n",
       " 'Lt_Mastoid': 31.036226,\n",
       " 'Lt_Parotid_Gland': 0.0,\n",
       " 'Lt_Submandibular_Gland': 56.86295,\n",
       " 'Lt_Medial_Pterygoid_M': 59.881886,\n",
       " 'Lt_Lateral_Pterygoid_M': 45.63928,\n",
       " 'Lt_Masseter_M': 62.5084,\n",
       " 'Supraglottic_Larynx': 42.579956,\n",
       " 'SPC': 60.710022,\n",
       " 'Rt_Submandibular_Gland': 58.45572,\n",
       " 'Hyoid_bone': 0.0,\n",
       " 'Soft_Palate': 53.09308,\n",
       " 'Genioglossus_M': 46.11689,\n",
       " 'Tongue': 37.72832,\n",
       " 'Rt_Ant_Digastric_M': 48.81045,\n",
       " 'Lt_Ant_Digastric_M': 66.61932,\n",
       " 'Mylogeniohyoid_M': 38.8513,\n",
       " 'Extended_Oral_Cavity': 0.0,\n",
       " 'Mandible': 63.5421,\n",
       " 'Hard_Palate': 68.977325,\n",
       " 'Lt_Posterior_Seg_Eyeball': 56.79498,\n",
       " 'Rt_Posterior_Seg_Eyeball': 66.46055,\n",
       " 'Lt_Anterior_Seg_Eyeball': 61.986965,\n",
       " 'Rt_Anterior_Seg_Eyeball': 28.284018,\n",
       " 'Lower_Lip': 54.48388,\n",
       " 'Upper_Lip': 35.74045,\n",
       " 'GTVp': 60.756195,\n",
       " 'GTVn': 19.153336}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dose_prediction(fdict,dmodel,camprt_df, organ_order=None):\n",
    "    if organ_order is None:\n",
    "        organ_order = Const.organ_order[:]\n",
    "    \n",
    "    camprt_input = camprt_df.drop(organ_order,axis=1)\n",
    "    order = camprt_input.columns\n",
    "    xin = torch.tensor([fdict[k] for k in order]).type(torch.FloatTensor).view(1,-1) \n",
    "    ypred = dmodel(xin).cpu().detach().numpy()[0]\n",
    "    \n",
    "    return {o:np.round(y,2 for o,y in zip(organ_order, ypred)}\n",
    "get_dose_prediction(test_patient,dosemodel,merged_camprt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdasi_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b4b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
