{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score,precision_recall_fscore_support\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "import copy\n",
    "from Utils import *\n",
    "from DeepSurvivalModels import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False)\n",
    "data.processed_df.T\n",
    "data.get_input_state(1).shape\n",
    "# data.processed_df#.shape, len(data.processed_df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055e18c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpv</th>\n",
       "      <th>age</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <th>FDM (months)</th>\n",
       "      <th>...</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>6_contra</th>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <th>RPLN_contra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55.969444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>143.200000</td>\n",
       "      <td>143.200000</td>\n",
       "      <td>143.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>136.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>45.950000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>152.600000</td>\n",
       "      <td>152.600000</td>\n",
       "      <td>152.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>49.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>155.533333</td>\n",
       "      <td>155.533333</td>\n",
       "      <td>155.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpv        age  packs_per_year  gender  Aspiration rate Pre-therapy  \\\n",
       "id                                                                           \n",
       "3        1  55.969444             0.0       1                            0   \n",
       "5        0  20.950000            38.0       1                            0   \n",
       "6        1  69.930556            35.0       0                            1   \n",
       "7        1  72.319444             0.0       1                            0   \n",
       "8        1  59.730556             0.0       1                            0   \n",
       "...    ...        ...             ...     ...                          ...   \n",
       "10201    1  49.566667            30.0       1                            0   \n",
       "10202    0  48.705556            30.0       1                            0   \n",
       "10203    1  77.116667             0.0       1                            0   \n",
       "10204    0  45.950000             5.0       1                            0   \n",
       "10205    1  49.733333             0.0       1                            0   \n",
       "\n",
       "       total_dose  dose_fraction  OS (Calculated)  \\\n",
       "id                                                  \n",
       "3           66.00       2.200000         6.033333   \n",
       "5           72.00       1.800000         7.333333   \n",
       "6           70.00       2.121212         7.466667   \n",
       "7           70.00       2.121212         7.800000   \n",
       "8           66.00       2.200000         8.066667   \n",
       "...           ...            ...              ...   \n",
       "10201       70.00       2.121212       143.200000   \n",
       "10202       72.00       1.714286       144.366667   \n",
       "10203       70.00       2.333333       148.366667   \n",
       "10204       69.96       2.120000       152.600000   \n",
       "10205       69.96       2.120000       155.533333   \n",
       "\n",
       "       Locoregional control (Time)  FDM (months)  ...  4_ipsi  4_contra  \\\n",
       "id                                                ...                     \n",
       "3                         4.700000      6.033333  ...     0.0       0.0   \n",
       "5                         7.333333      7.333333  ...     0.0       0.0   \n",
       "6                         7.466667      7.466667  ...     0.0       0.0   \n",
       "7                         7.800000      7.800000  ...     0.0       0.0   \n",
       "8                         8.066667      8.066667  ...     0.0       0.0   \n",
       "...                            ...           ...  ...     ...       ...   \n",
       "10201                   143.200000    143.200000  ...     0.0       0.0   \n",
       "10202                   144.366667    144.366667  ...     0.0       0.0   \n",
       "10203                   148.366667    136.033333  ...     0.0       0.0   \n",
       "10204                   152.600000    152.600000  ...     0.0       0.0   \n",
       "10205                   155.533333    155.533333  ...     0.0       0.0   \n",
       "\n",
       "       5A_ipsi  5A_contra  5B_ipsi  5B_contra  6_ipsi  6_contra  RPLN_ipsi  \\\n",
       "id                                                                           \n",
       "3          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "5          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "6          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "7          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "8          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "...        ...        ...      ...        ...     ...       ...        ...   \n",
       "10201      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10202      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10203      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10204      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10205      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "\n",
       "       RPLN_contra  \n",
       "id                  \n",
       "3              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "...            ...  \n",
       "10201          0.0  \n",
       "10202          0.0  \n",
       "10203          0.0  \n",
       "10204          0.0  \n",
       "10205          0.0  \n",
       "\n",
       "[536 rows x 109 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2937b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSM(\n",
       "  (act): Tanh()\n",
       "  (shape): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 6]\n",
       "      (1): Parameter containing: [torch.float32 of size 6]\n",
       "      (2): Parameter containing: [torch.float32 of size 6]\n",
       "      (3): Parameter containing: [torch.float32 of size 6]\n",
       "  )\n",
       "  (scale): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 6]\n",
       "      (1): Parameter containing: [torch.float32 of size 6]\n",
       "      (2): Parameter containing: [torch.float32 of size 6]\n",
       "      (3): Parameter containing: [torch.float32 of size 6]\n",
       "  )\n",
       "  (gate): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (scaleg): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (shapeg): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Sequential(\n",
       "    (0): Linear(in_features=78, out_features=100, bias=False)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (squish): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Utils import *\n",
    "model1,model2,model3,smodel3 = load_transition_models()\n",
    "smodel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29d259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([115.,   1., 137.]) 147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " {'pd1': tensor([[2.0924e-01, 7.9076e-01, 1.5778e-22],\n",
       "          [9.6747e-01, 3.2288e-02, 2.4502e-04],\n",
       "          [1.3833e-02, 9.8411e-01, 2.0531e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.7540e-01, 5.0797e-01, 1.6636e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.2756e-01, 1.6092e-01, 1.1516e-02],\n",
       "          [5.2761e-01, 4.5284e-01, 1.9554e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.6993e-01, 2.1634e-01, 1.3737e-02],\n",
       "          [6.9413e-01, 2.9794e-01, 7.9282e-03],\n",
       "          [4.4932e-01, 5.2751e-01, 2.3169e-02],\n",
       "          [7.2501e-01, 2.6165e-01, 1.3339e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.2162e-01, 3.5363e-01, 2.4759e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.0773e-01, 4.7543e-01, 1.6838e-02],\n",
       "          [8.3213e-01, 1.5390e-01, 1.3973e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.3580e-01, 7.5268e-01, 1.1527e-02],\n",
       "          [7.5501e-01, 2.2418e-01, 2.0812e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.8014e-01, 1.1986e-01, 5.6567e-22],\n",
       "          [4.0385e-01, 5.7868e-01, 1.7465e-02],\n",
       "          [9.4176e-01, 5.8245e-02, 3.6821e-22],\n",
       "          [7.5958e-01, 2.3356e-01, 6.8564e-03],\n",
       "          [6.7933e-01, 3.0655e-01, 1.4119e-02],\n",
       "          [4.8912e-01, 4.9384e-01, 1.7042e-02],\n",
       "          [8.8674e-01, 1.0067e-01, 1.2587e-02],\n",
       "          [7.6059e-01, 2.2149e-01, 1.7919e-02],\n",
       "          [8.1435e-01, 1.6960e-01, 1.6054e-02],\n",
       "          [9.2053e-01, 7.1608e-02, 7.8604e-03],\n",
       "          [7.1261e-01, 2.7092e-01, 1.6469e-02],\n",
       "          [1.8779e-02, 9.8122e-01, 4.6740e-23],\n",
       "          [5.6754e-01, 4.1812e-01, 1.4345e-02],\n",
       "          [8.3620e-01, 1.5111e-01, 1.2693e-02],\n",
       "          [7.4944e-01, 2.4440e-01, 6.1631e-03],\n",
       "          [5.4051e-01, 4.4400e-01, 1.5488e-02],\n",
       "          [7.4166e-01, 2.4133e-01, 1.7005e-02],\n",
       "          [1.3647e-01, 8.6247e-01, 1.0648e-03],\n",
       "          [1.7628e-01, 8.1391e-01, 9.8069e-03],\n",
       "          [2.3775e-01, 7.5617e-01, 6.0754e-03],\n",
       "          [6.3307e-01, 3.4741e-01, 1.9521e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.7960e-01, 1.1291e-01, 7.4926e-03],\n",
       "          [8.7422e-01, 1.1344e-01, 1.2334e-02],\n",
       "          [3.3553e-01, 6.5019e-01, 1.4280e-02],\n",
       "          [3.1154e-01, 6.8431e-01, 4.1533e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.2839e-01, 7.5219e-01, 1.9423e-02],\n",
       "          [6.3762e-01, 3.3962e-01, 2.2761e-02],\n",
       "          [4.8071e-01, 5.0211e-01, 1.7184e-02],\n",
       "          [9.7875e-02, 8.9396e-01, 8.1613e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.4193e-01, 6.3715e-01, 2.0920e-02],\n",
       "          [4.5843e-01, 5.4091e-01, 6.6228e-04],\n",
       "          [7.9055e-01, 1.9434e-01, 1.5102e-02],\n",
       "          [8.9960e-01, 8.8408e-02, 1.1989e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.5611e-01, 1.3306e-01, 1.0835e-02],\n",
       "          [8.6473e-01, 1.2377e-01, 1.1497e-02],\n",
       "          [8.2564e-01, 1.7436e-01, 3.8708e-22],\n",
       "          [7.9839e-01, 1.8647e-01, 1.5138e-02],\n",
       "          [7.7723e-01, 2.0445e-01, 1.8328e-02],\n",
       "          [2.2395e-01, 7.6226e-01, 1.3786e-02],\n",
       "          [9.1250e-01, 7.8433e-02, 9.0689e-03],\n",
       "          [8.0906e-01, 1.7823e-01, 1.2702e-02],\n",
       "          [1.3869e-01, 8.5251e-01, 8.8032e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.9230e-01, 1.9083e-01, 1.6868e-02],\n",
       "          [8.6252e-01, 1.2543e-01, 1.2045e-02],\n",
       "          [4.3284e-01, 5.5938e-01, 7.7763e-03],\n",
       "          [5.7393e-01, 4.1822e-01, 7.8540e-03],\n",
       "          [5.3008e-03, 9.9351e-01, 1.1924e-03],\n",
       "          [9.3820e-02, 8.9806e-01, 8.1226e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.4076e-01, 4.4211e-01, 1.7131e-02],\n",
       "          [6.2028e-01, 3.5956e-01, 2.0166e-02],\n",
       "          [2.5762e-01, 7.2602e-01, 1.6357e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.4231e-01, 1.4851e-01, 9.1807e-03],\n",
       "          [7.6312e-01, 2.2372e-01, 1.3165e-02],\n",
       "          [4.9383e-01, 4.8944e-01, 1.6728e-02],\n",
       "          [5.0024e-01, 4.9279e-01, 6.9713e-03],\n",
       "          [7.7167e-01, 2.1252e-01, 1.5807e-02],\n",
       "          [5.2694e-02, 9.4731e-01, 9.2817e-23],\n",
       "          [6.7730e-01, 3.0333e-01, 1.9367e-02],\n",
       "          [7.8206e-01, 2.0545e-01, 1.2488e-02],\n",
       "          [2.0938e-01, 7.7698e-01, 1.3640e-02],\n",
       "          [6.9277e-01, 2.9013e-01, 1.7098e-02],\n",
       "          [2.7415e-01, 7.2500e-01, 8.5402e-04],\n",
       "          [1.2617e-01, 8.6914e-01, 4.6946e-03],\n",
       "          [7.7878e-01, 2.1004e-01, 1.1189e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.2540e-01, 1.5945e-01, 1.5152e-02],\n",
       "          [2.0765e-02, 9.7696e-01, 2.2759e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [9.1597e-01, 7.5263e-02, 8.7636e-03],\n",
       "          [7.7147e-01, 2.1120e-01, 1.7332e-02],\n",
       "          [1.5720e-01, 8.3794e-01, 4.8637e-03],\n",
       "          [7.7217e-01, 2.1356e-01, 1.4272e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.9946e-01, 1.8515e-01, 1.5393e-02],\n",
       "          [4.4869e-01, 5.3269e-01, 1.8620e-02],\n",
       "          [7.8812e-01, 2.0020e-01, 1.1678e-02],\n",
       "          [6.5835e-01, 3.2470e-01, 1.6947e-02],\n",
       "          [3.0284e-01, 6.8470e-01, 1.2469e-02],\n",
       "          [8.4225e-01, 1.4382e-01, 1.3928e-02],\n",
       "          [6.5390e-01, 3.2371e-01, 2.2390e-02],\n",
       "          [2.6681e-01, 7.1431e-01, 1.8878e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.0520e-01, 3.7331e-01, 2.1485e-02],\n",
       "          [6.3474e-01, 3.4652e-01, 1.8740e-02],\n",
       "          [4.2296e-01, 5.5539e-01, 2.1645e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.6982e-01, 7.1840e-01, 1.1787e-02],\n",
       "          [6.7638e-01, 3.0921e-01, 1.4411e-02],\n",
       "          [1.2924e-01, 8.5861e-01, 1.2152e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.4087e-01, 4.3564e-01, 2.3485e-02],\n",
       "          [7.9781e-01, 1.8902e-01, 1.3166e-02],\n",
       "          [9.0081e-01, 8.7357e-02, 1.1837e-02],\n",
       "          [9.0182e-02, 9.0393e-01, 5.8860e-03],\n",
       "          [2.3781e-01, 7.5606e-01, 6.1234e-03],\n",
       "          [7.0272e-01, 2.9284e-01, 4.4428e-03],\n",
       "          [7.9357e-01, 1.9126e-01, 1.5165e-02],\n",
       "          [5.4260e-01, 4.4631e-01, 1.1093e-02],\n",
       "          [4.8694e-01, 4.9601e-01, 1.7045e-02],\n",
       "          [2.9372e-01, 6.8539e-01, 2.0886e-02],\n",
       "          [7.2824e-01, 2.5766e-01, 1.4101e-02],\n",
       "          [7.2282e-01, 2.5830e-01, 1.8885e-02],\n",
       "          [8.3273e-01, 1.5327e-01, 1.4002e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [9.0608e-01, 9.3350e-02, 5.6693e-04],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.3325e-01, 4.5324e-01, 1.3502e-02],\n",
       "          [4.2085e-01, 5.5723e-01, 2.1912e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01]], grad_fn=<CopySlices>),\n",
       "  'nd1': tensor([[2.2124e-34, 1.0000e+00, 2.2124e-34],\n",
       "          [4.6167e-05, 9.9991e-01, 4.5898e-05],\n",
       "          [2.1214e-03, 9.9576e-01, 2.1161e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.0973e-03, 9.9179e-01, 4.1104e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.6644e-03, 9.9065e-01, 4.6825e-03],\n",
       "          [5.5287e-03, 9.8898e-01, 5.4912e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.3592e-03, 9.8532e-01, 7.3197e-03],\n",
       "          [1.7947e-03, 9.9642e-01, 1.7883e-03],\n",
       "          [8.8949e-03, 9.8236e-01, 8.7480e-03],\n",
       "          [3.9735e-03, 9.9204e-01, 3.9848e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.0458e-02, 9.7923e-01, 1.0315e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.3402e-03, 9.9141e-01, 4.2492e-03],\n",
       "          [8.0328e-03, 9.8404e-01, 7.9269e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.9928e-03, 9.9204e-01, 3.9623e-03],\n",
       "          [8.9904e-03, 9.8212e-01, 8.8941e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.4630e-31, 1.0000e+00, 1.4630e-31],\n",
       "          [5.8860e-03, 9.8832e-01, 5.7946e-03],\n",
       "          [1.2170e-31, 1.0000e+00, 1.2170e-31],\n",
       "          [1.5123e-03, 9.9700e-01, 1.4900e-03],\n",
       "          [4.7974e-03, 9.9043e-01, 4.7696e-03],\n",
       "          [4.4441e-03, 9.9111e-01, 4.4507e-03],\n",
       "          [6.8379e-03, 9.8634e-01, 6.8251e-03],\n",
       "          [8.1959e-03, 9.8378e-01, 8.0216e-03],\n",
       "          [8.6242e-03, 9.8283e-01, 8.5410e-03],\n",
       "          [6.5535e-03, 9.8693e-01, 6.5164e-03],\n",
       "          [4.6789e-03, 9.9066e-01, 4.6567e-03],\n",
       "          [2.2424e-34, 1.0000e+00, 2.2424e-34],\n",
       "          [4.9114e-03, 9.9026e-01, 4.8314e-03],\n",
       "          [6.3983e-03, 9.8723e-01, 6.3719e-03],\n",
       "          [1.8317e-03, 9.9633e-01, 1.8361e-03],\n",
       "          [4.0439e-03, 9.9192e-01, 4.0394e-03],\n",
       "          [5.7265e-03, 9.8858e-01, 5.6975e-03],\n",
       "          [1.2475e-04, 9.9975e-01, 1.2466e-04],\n",
       "          [2.9387e-03, 9.9414e-01, 2.9196e-03],\n",
       "          [1.2702e-03, 9.9746e-01, 1.2706e-03],\n",
       "          [5.5958e-03, 9.8881e-01, 5.5908e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.3402e-03, 9.9532e-01, 2.3377e-03],\n",
       "          [7.9336e-03, 9.8431e-01, 7.7577e-03],\n",
       "          [5.1509e-03, 9.8978e-01, 5.0671e-03],\n",
       "          [7.0059e-04, 9.9860e-01, 6.9850e-04],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.3397e-03, 9.8352e-01, 8.1428e-03],\n",
       "          [9.3784e-03, 9.8136e-01, 9.2570e-03],\n",
       "          [4.4516e-03, 9.9109e-01, 4.4607e-03],\n",
       "          [4.2970e-03, 9.9141e-01, 4.2972e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.8168e-03, 9.8442e-01, 7.7637e-03],\n",
       "          [3.6341e-05, 9.9993e-01, 3.6228e-05],\n",
       "          [5.5178e-03, 9.8906e-01, 5.4210e-03],\n",
       "          [7.6071e-03, 9.8484e-01, 7.5511e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.3490e-03, 9.8540e-01, 7.2499e-03],\n",
       "          [7.1315e-03, 9.8586e-01, 7.0035e-03],\n",
       "          [8.9138e-32, 1.0000e+00, 8.9138e-32],\n",
       "          [5.3866e-03, 9.8921e-01, 5.4025e-03],\n",
       "          [8.4673e-03, 9.8316e-01, 8.3756e-03],\n",
       "          [6.2568e-03, 9.8757e-01, 6.1763e-03],\n",
       "          [5.7188e-03, 9.8865e-01, 5.6347e-03],\n",
       "          [6.7161e-03, 9.8672e-01, 6.5658e-03],\n",
       "          [4.3343e-03, 9.9136e-01, 4.3009e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.1926e-03, 9.8369e-01, 8.1222e-03],\n",
       "          [6.8866e-03, 9.8627e-01, 6.8448e-03],\n",
       "          [1.9611e-03, 9.9611e-01, 1.9300e-03],\n",
       "          [2.4347e-03, 9.9514e-01, 2.4247e-03],\n",
       "          [2.2680e-03, 9.9548e-01, 2.2562e-03],\n",
       "          [3.8439e-03, 9.9234e-01, 3.8196e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.1017e-03, 9.8977e-01, 5.1238e-03],\n",
       "          [7.9501e-03, 9.8409e-01, 7.9570e-03],\n",
       "          [5.6330e-03, 9.8874e-01, 5.6279e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.7088e-03, 9.9265e-01, 3.6394e-03],\n",
       "          [5.0341e-03, 9.8992e-01, 5.0490e-03],\n",
       "          [5.2589e-03, 9.8955e-01, 5.1914e-03],\n",
       "          [9.9882e-04, 9.9800e-01, 1.0048e-03],\n",
       "          [5.1365e-03, 9.8970e-01, 5.1601e-03],\n",
       "          [3.4766e-34, 1.0000e+00, 3.4766e-34],\n",
       "          [7.6824e-03, 9.8476e-01, 7.5535e-03],\n",
       "          [4.9960e-03, 9.9000e-01, 5.0065e-03],\n",
       "          [5.5926e-03, 9.8885e-01, 5.5544e-03],\n",
       "          [5.3990e-03, 9.8924e-01, 5.3616e-03],\n",
       "          [7.0718e-05, 9.9986e-01, 7.0557e-05],\n",
       "          [1.0871e-03, 9.9783e-01, 1.0798e-03],\n",
       "          [4.8529e-03, 9.9041e-01, 4.7383e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.5323e-03, 9.8303e-01, 8.4378e-03],\n",
       "          [1.8789e-03, 9.9625e-01, 1.8730e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.0437e-03, 9.8995e-01, 5.0033e-03],\n",
       "          [8.1959e-03, 9.8378e-01, 8.0217e-03],\n",
       "          [1.7599e-03, 9.9649e-01, 1.7541e-03],\n",
       "          [5.2006e-03, 9.8960e-01, 5.2018e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.7253e-03, 9.8866e-01, 5.6101e-03],\n",
       "          [5.6814e-03, 9.8868e-01, 5.6376e-03],\n",
       "          [4.8607e-03, 9.9032e-01, 4.8198e-03],\n",
       "          [4.7803e-03, 9.9047e-01, 4.7515e-03],\n",
       "          [3.8401e-03, 9.9230e-01, 3.8581e-03],\n",
       "          [6.1678e-03, 9.8768e-01, 6.1526e-03],\n",
       "          [7.9100e-03, 9.8426e-01, 7.8343e-03],\n",
       "          [6.9594e-03, 9.8607e-01, 6.9716e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.7566e-03, 9.8254e-01, 8.6986e-03],\n",
       "          [6.1931e-03, 9.8762e-01, 6.1914e-03],\n",
       "          [7.6278e-03, 9.8484e-01, 7.5331e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.8733e-03, 9.9227e-01, 3.8586e-03],\n",
       "          [6.4389e-03, 9.8732e-01, 6.2365e-03],\n",
       "          [6.1957e-03, 9.8783e-01, 5.9744e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.2988e-03, 9.8346e-01, 8.2399e-03],\n",
       "          [5.7031e-03, 9.8864e-01, 5.6594e-03],\n",
       "          [7.5607e-03, 9.8494e-01, 7.5037e-03],\n",
       "          [3.1342e-03, 9.9375e-01, 3.1114e-03],\n",
       "          [1.2159e-03, 9.9758e-01, 1.2046e-03],\n",
       "          [9.4322e-04, 9.9813e-01, 9.3113e-04],\n",
       "          [6.6422e-03, 9.8682e-01, 6.5397e-03],\n",
       "          [2.6470e-03, 9.9470e-01, 2.6482e-03],\n",
       "          [4.4433e-03, 9.9111e-01, 4.4501e-03],\n",
       "          [6.7831e-03, 9.8658e-01, 6.6373e-03],\n",
       "          [6.1602e-03, 9.8774e-01, 6.0970e-03],\n",
       "          [8.9374e-03, 9.8226e-01, 8.7985e-03],\n",
       "          [7.8374e-03, 9.8443e-01, 7.7330e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.1535e-05, 9.9988e-01, 6.1463e-05],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.7100e-03, 9.9058e-01, 4.7103e-03],\n",
       "          [8.3949e-03, 9.8344e-01, 8.1607e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01]], grad_fn=<CopySlices>),\n",
       "  'nd2': tensor([[8.8885e-01, 1.0284e-01, 8.3092e-03],\n",
       "          [8.3659e-01, 1.6291e-01, 5.0229e-04],\n",
       "          [6.5342e-01, 3.3993e-01, 6.6457e-03],\n",
       "          [6.2856e-01, 3.4393e-01, 2.7503e-02],\n",
       "          [6.1731e-01, 3.4138e-01, 4.1309e-02],\n",
       "          [5.4812e-01, 4.1321e-01, 3.8666e-02],\n",
       "          [6.0715e-01, 3.8119e-01, 1.1660e-02],\n",
       "          [5.1573e-01, 4.4956e-01, 3.4704e-02],\n",
       "          [6.3362e-01, 3.4249e-01, 2.3897e-02],\n",
       "          [4.8666e-01, 4.7735e-01, 3.5990e-02],\n",
       "          [5.1294e-01, 4.4661e-01, 4.0449e-02],\n",
       "          [7.6550e-01, 2.2556e-01, 8.9338e-03],\n",
       "          [5.1441e-01, 4.3650e-01, 4.9093e-02],\n",
       "          [5.0398e-01, 4.6226e-01, 3.3754e-02],\n",
       "          [5.9858e-01, 3.7369e-01, 2.7736e-02],\n",
       "          [5.9109e-01, 3.6760e-01, 4.1311e-02],\n",
       "          [7.5542e-01, 2.4206e-01, 2.5175e-03],\n",
       "          [6.1634e-01, 3.3700e-01, 4.6654e-02],\n",
       "          [4.9594e-01, 4.6354e-01, 4.0525e-02],\n",
       "          [5.4794e-01, 4.3385e-01, 1.8206e-02],\n",
       "          [6.6389e-01, 2.9873e-01, 3.7377e-02],\n",
       "          [6.2100e-01, 3.4076e-01, 3.8239e-02],\n",
       "          [5.3534e-01, 4.2475e-01, 3.9917e-02],\n",
       "          [6.1673e-01, 3.7549e-01, 7.7786e-03],\n",
       "          [6.9805e-01, 3.0164e-01, 3.0567e-04],\n",
       "          [6.6528e-01, 3.1097e-01, 2.3748e-02],\n",
       "          [7.6608e-01, 2.3368e-01, 2.3774e-04],\n",
       "          [7.1830e-01, 2.7561e-01, 6.0909e-03],\n",
       "          [5.5261e-01, 4.0249e-01, 4.4903e-02],\n",
       "          [5.3721e-01, 4.2627e-01, 3.6528e-02],\n",
       "          [5.4561e-01, 4.1491e-01, 3.9480e-02],\n",
       "          [6.3048e-01, 3.2762e-01, 4.1904e-02],\n",
       "          [5.3043e-01, 4.2551e-01, 4.4061e-02],\n",
       "          [6.2107e-01, 3.4394e-01, 3.4993e-02],\n",
       "          [6.5878e-01, 3.2073e-01, 2.0494e-02],\n",
       "          [8.3152e-01, 1.6029e-01, 8.1950e-03],\n",
       "          [5.8997e-01, 3.7127e-01, 3.8759e-02],\n",
       "          [6.6035e-01, 3.1394e-01, 2.5708e-02],\n",
       "          [5.3098e-01, 4.5048e-01, 1.8536e-02],\n",
       "          [5.1952e-01, 4.4844e-01, 3.2037e-02],\n",
       "          [6.4870e-01, 3.1248e-01, 3.8820e-02],\n",
       "          [8.0113e-01, 1.9802e-01, 8.5158e-04],\n",
       "          [6.7738e-01, 2.9789e-01, 2.4735e-02],\n",
       "          [8.5776e-01, 1.3850e-01, 3.7386e-03],\n",
       "          [5.5230e-01, 4.0814e-01, 3.9556e-02],\n",
       "          [6.9384e-01, 2.9796e-01, 8.1973e-03],\n",
       "          [7.2217e-01, 2.5699e-01, 2.0835e-02],\n",
       "          [5.9899e-01, 3.8009e-01, 2.0916e-02],\n",
       "          [6.2388e-01, 3.2894e-01, 4.7179e-02],\n",
       "          [5.3037e-01, 4.3576e-01, 3.3876e-02],\n",
       "          [6.3793e-01, 3.5463e-01, 7.4341e-03],\n",
       "          [5.7269e-01, 3.7984e-01, 4.7466e-02],\n",
       "          [7.2952e-01, 2.5005e-01, 2.0430e-02],\n",
       "          [5.3767e-01, 4.1596e-01, 4.6373e-02],\n",
       "          [5.4116e-01, 4.2137e-01, 3.7470e-02],\n",
       "          [5.2027e-01, 4.4952e-01, 3.0202e-02],\n",
       "          [6.3485e-01, 3.3615e-01, 2.9001e-02],\n",
       "          [5.2153e-01, 4.3398e-01, 4.4490e-02],\n",
       "          [8.8079e-01, 1.1884e-01, 3.6931e-04],\n",
       "          [5.9794e-01, 3.6117e-01, 4.0890e-02],\n",
       "          [5.4015e-01, 4.1616e-01, 4.3689e-02],\n",
       "          [5.3988e-01, 4.2424e-01, 3.5885e-02],\n",
       "          [5.3152e-01, 4.4021e-01, 2.8266e-02],\n",
       "          [5.3972e-01, 4.3108e-01, 2.9197e-02],\n",
       "          [6.5123e-01, 3.4847e-01, 2.9654e-04],\n",
       "          [5.3765e-01, 4.2318e-01, 3.9172e-02],\n",
       "          [5.6400e-01, 3.9954e-01, 3.6466e-02],\n",
       "          [5.0011e-01, 4.6781e-01, 3.2080e-02],\n",
       "          [6.2877e-01, 3.2473e-01, 4.6504e-02],\n",
       "          [6.0981e-01, 3.6551e-01, 2.4680e-02],\n",
       "          [4.5728e-01, 5.1403e-01, 2.8695e-02],\n",
       "          [6.0280e-01, 3.5381e-01, 4.3392e-02],\n",
       "          [5.5454e-01, 4.0146e-01, 4.3999e-02],\n",
       "          [5.9056e-01, 3.7283e-01, 3.6604e-02],\n",
       "          [7.0982e-01, 2.7457e-01, 1.5616e-02],\n",
       "          [5.9311e-01, 3.8644e-01, 2.0451e-02],\n",
       "          [5.3412e-01, 4.5721e-01, 8.6697e-03],\n",
       "          [5.5754e-01, 4.1065e-01, 3.1811e-02],\n",
       "          [5.7367e-01, 4.1277e-01, 1.3557e-02],\n",
       "          [5.6575e-01, 4.1105e-01, 2.3197e-02],\n",
       "          [5.3401e-01, 4.2825e-01, 3.7743e-02],\n",
       "          [6.4913e-01, 3.2482e-01, 2.6049e-02],\n",
       "          [6.5523e-01, 3.1787e-01, 2.6904e-02],\n",
       "          [5.2556e-01, 4.5859e-01, 1.5847e-02],\n",
       "          [7.9957e-01, 1.9543e-01, 5.0069e-03],\n",
       "          [4.9025e-01, 4.7161e-01, 3.8133e-02],\n",
       "          [6.0908e-01, 3.6239e-01, 2.8526e-02],\n",
       "          [5.3059e-01, 4.5222e-01, 1.7189e-02],\n",
       "          [5.5415e-01, 4.0566e-01, 4.0189e-02],\n",
       "          [8.2364e-01, 1.6518e-01, 1.1182e-02],\n",
       "          [5.5228e-01, 4.1015e-01, 3.7563e-02],\n",
       "          [4.8372e-01, 4.7931e-01, 3.6971e-02],\n",
       "          [5.6360e-01, 4.0836e-01, 2.8044e-02],\n",
       "          [5.2617e-01, 4.4089e-01, 3.2940e-02],\n",
       "          [7.2391e-01, 2.6862e-01, 7.4706e-03],\n",
       "          [7.6769e-01, 2.2243e-01, 9.8788e-03],\n",
       "          [5.9307e-01, 3.7464e-01, 3.2287e-02],\n",
       "          [7.3579e-01, 2.5931e-01, 4.8915e-03],\n",
       "          [5.1329e-01, 4.4377e-01, 4.2941e-02],\n",
       "          [5.8436e-01, 4.0059e-01, 1.5054e-02],\n",
       "          [6.0794e-01, 3.6818e-01, 2.3889e-02],\n",
       "          [6.1984e-01, 3.3767e-01, 4.2496e-02],\n",
       "          [6.2079e-01, 3.3724e-01, 4.1969e-02],\n",
       "          [6.6222e-01, 3.3124e-01, 6.5429e-03],\n",
       "          [5.7503e-01, 3.7906e-01, 4.5910e-02],\n",
       "          [5.8204e-01, 3.7839e-01, 3.9573e-02],\n",
       "          [6.1000e-01, 3.4546e-01, 4.4549e-02],\n",
       "          [6.2568e-01, 3.4374e-01, 3.0578e-02],\n",
       "          [5.0824e-01, 4.5851e-01, 3.3252e-02],\n",
       "          [6.1919e-01, 3.3849e-01, 4.2313e-02],\n",
       "          [6.2191e-01, 3.5490e-01, 2.3186e-02],\n",
       "          [6.1212e-01, 3.4312e-01, 4.4758e-02],\n",
       "          [5.3807e-01, 4.1442e-01, 4.7510e-02],\n",
       "          [7.5782e-01, 2.2807e-01, 1.4112e-02],\n",
       "          [5.5850e-01, 4.0012e-01, 4.1382e-02],\n",
       "          [5.8743e-01, 3.7948e-01, 3.3090e-02],\n",
       "          [5.0968e-01, 4.5004e-01, 4.0282e-02],\n",
       "          [5.3591e-01, 4.1566e-01, 4.8427e-02],\n",
       "          [5.6515e-01, 4.1937e-01, 1.5473e-02],\n",
       "          [5.4521e-01, 4.2145e-01, 3.3341e-02],\n",
       "          [6.6117e-01, 3.1946e-01, 1.9371e-02],\n",
       "          [6.6914e-01, 3.0097e-01, 2.9892e-02],\n",
       "          [5.2923e-01, 4.3019e-01, 4.0580e-02],\n",
       "          [5.8291e-01, 3.6798e-01, 4.9116e-02],\n",
       "          [6.3858e-01, 3.2961e-01, 3.1805e-02],\n",
       "          [5.3734e-01, 4.1926e-01, 4.3401e-02],\n",
       "          [5.0784e-01, 4.7700e-01, 1.5160e-02],\n",
       "          [6.7579e-01, 3.1425e-01, 9.9584e-03],\n",
       "          [6.7224e-01, 3.1289e-01, 1.4875e-02],\n",
       "          [4.9884e-01, 4.6158e-01, 3.9578e-02],\n",
       "          [6.5514e-01, 3.2121e-01, 2.3650e-02],\n",
       "          [5.3729e-01, 4.2629e-01, 3.6418e-02],\n",
       "          [6.7460e-01, 2.9912e-01, 2.6284e-02],\n",
       "          [5.7867e-01, 3.8554e-01, 3.5788e-02],\n",
       "          [5.3807e-01, 4.2404e-01, 3.7885e-02],\n",
       "          [6.6251e-01, 2.9913e-01, 3.8365e-02],\n",
       "          [6.0371e-01, 3.6178e-01, 3.4508e-02],\n",
       "          [5.1485e-01, 4.5078e-01, 3.4379e-02],\n",
       "          [4.8483e-01, 4.8326e-01, 3.1902e-02],\n",
       "          [6.3231e-01, 3.2760e-01, 4.0097e-02],\n",
       "          [4.8912e-01, 4.8127e-01, 2.9615e-02],\n",
       "          [5.6806e-01, 4.0264e-01, 2.9298e-02],\n",
       "          [5.5777e-01, 4.4185e-01, 3.7835e-04],\n",
       "          [6.6481e-01, 3.2557e-01, 9.6153e-03],\n",
       "          [5.6388e-01, 4.0474e-01, 3.1382e-02],\n",
       "          [6.8849e-01, 2.8587e-01, 2.5641e-02],\n",
       "          [5.1193e-01, 4.5494e-01, 3.3126e-02]], grad_fn=<CopySlices>),\n",
       "  'pd2': tensor([[9.9729e-01, 1.3501e-03, 1.3634e-03],\n",
       "          [9.9999e-01, 4.4617e-06, 4.4690e-06],\n",
       "          [9.9902e-01, 4.8847e-04, 4.9487e-04],\n",
       "          [9.8918e-01, 5.3673e-03, 5.4504e-03],\n",
       "          [9.7862e-01, 1.0575e-02, 1.0802e-02],\n",
       "          [9.8261e-01, 8.5956e-03, 8.7904e-03],\n",
       "          [9.9757e-01, 1.2120e-03, 1.2187e-03],\n",
       "          [9.8662e-01, 6.6187e-03, 6.7585e-03],\n",
       "          [9.9136e-01, 4.2651e-03, 4.3745e-03],\n",
       "          [9.8310e-01, 8.3984e-03, 8.4970e-03],\n",
       "          [9.8097e-01, 9.3978e-03, 9.6317e-03],\n",
       "          [9.9815e-01, 9.1859e-04, 9.2816e-04],\n",
       "          [9.6793e-01, 1.5815e-02, 1.6257e-02],\n",
       "          [9.8788e-01, 5.9905e-03, 6.1291e-03],\n",
       "          [9.8964e-01, 5.1392e-03, 5.2174e-03],\n",
       "          [9.7730e-01, 1.1205e-02, 1.1496e-02],\n",
       "          [9.9982e-01, 8.8601e-05, 8.8907e-05],\n",
       "          [9.7058e-01, 1.4593e-02, 1.4830e-02],\n",
       "          [9.7979e-01, 9.9884e-03, 1.0221e-02],\n",
       "          [9.9518e-01, 2.3949e-03, 2.4232e-03],\n",
       "          [9.8203e-01, 8.9401e-03, 9.0317e-03],\n",
       "          [9.8114e-01, 9.3360e-03, 9.5246e-03],\n",
       "          [9.8186e-01, 8.9963e-03, 9.1423e-03],\n",
       "          [9.9882e-01, 5.8918e-04, 5.9262e-04],\n",
       "          [1.0000e+00, 1.6977e-06, 1.6988e-06],\n",
       "          [9.9304e-01, 3.4411e-03, 3.5237e-03],\n",
       "          [1.0000e+00, 1.0666e-06, 1.0672e-06],\n",
       "          [9.9930e-01, 3.5000e-04, 3.5359e-04],\n",
       "          [9.7441e-01, 1.2668e-02, 1.2922e-02],\n",
       "          [9.8439e-01, 7.7157e-03, 7.8972e-03],\n",
       "          [9.8180e-01, 9.0082e-03, 9.1891e-03],\n",
       "          [9.7604e-01, 1.1857e-02, 1.2100e-02],\n",
       "          [9.7683e-01, 1.1445e-02, 1.1726e-02],\n",
       "          [9.8173e-01, 9.0097e-03, 9.2560e-03],\n",
       "          [9.9465e-01, 2.6461e-03, 2.7066e-03],\n",
       "          [9.9800e-01, 9.9822e-04, 1.0063e-03],\n",
       "          [9.8190e-01, 8.9702e-03, 9.1342e-03],\n",
       "          [9.9084e-01, 4.5367e-03, 4.6258e-03],\n",
       "          [9.9399e-01, 2.9791e-03, 3.0354e-03],\n",
       "          [9.8800e-01, 5.9265e-03, 6.0719e-03],\n",
       "          [9.7893e-01, 1.0448e-02, 1.0620e-02],\n",
       "          [9.9997e-01, 1.5094e-05, 1.5121e-05],\n",
       "          [9.9038e-01, 4.7679e-03, 4.8519e-03],\n",
       "          [9.9950e-01, 2.4827e-04, 2.4980e-04],\n",
       "          [9.8040e-01, 9.6854e-03, 9.9101e-03],\n",
       "          [9.9893e-01, 5.3143e-04, 5.3604e-04],\n",
       "          [9.9439e-01, 2.7937e-03, 2.8190e-03],\n",
       "          [9.9327e-01, 3.3316e-03, 3.3976e-03],\n",
       "          [9.7019e-01, 1.4753e-02, 1.5055e-02],\n",
       "          [9.8642e-01, 6.6838e-03, 6.8921e-03],\n",
       "          [9.9909e-01, 4.5328e-04, 4.5825e-04],\n",
       "          [9.7150e-01, 1.4122e-02, 1.4378e-02],\n",
       "          [9.9133e-01, 4.3020e-03, 4.3729e-03],\n",
       "          [9.7215e-01, 1.3719e-02, 1.4127e-02],\n",
       "          [9.8358e-01, 8.1172e-03, 8.3051e-03],\n",
       "          [9.8695e-01, 6.4621e-03, 6.5866e-03],\n",
       "          [9.8929e-01, 5.3075e-03, 5.3984e-03],\n",
       "          [9.7297e-01, 1.3327e-02, 1.3703e-02],\n",
       "          [9.9999e-01, 2.5008e-06, 2.5032e-06],\n",
       "          [9.7866e-01, 1.0569e-02, 1.0771e-02],\n",
       "          [9.7780e-01, 1.0988e-02, 1.1214e-02],\n",
       "          [9.8441e-01, 7.7342e-03, 7.8582e-03],\n",
       "          [9.8922e-01, 5.3389e-03, 5.4429e-03],\n",
       "          [9.8790e-01, 5.9834e-03, 6.1118e-03],\n",
       "          [1.0000e+00, 1.4324e-06, 1.4333e-06],\n",
       "          [9.8224e-01, 8.7883e-03, 8.9715e-03],\n",
       "          [9.8389e-01, 7.9801e-03, 8.1316e-03],\n",
       "          [9.8553e-01, 7.1962e-03, 7.2753e-03],\n",
       "          [9.7362e-01, 1.3055e-02, 1.3325e-02],\n",
       "          [9.9111e-01, 4.4023e-03, 4.4853e-03],\n",
       "          [9.8782e-01, 6.0418e-03, 6.1378e-03],\n",
       "          [9.7683e-01, 1.1490e-02, 1.1682e-02],\n",
       "          [9.7713e-01, 1.1291e-02, 1.1576e-02],\n",
       "          [9.8398e-01, 7.9433e-03, 8.0735e-03],\n",
       "          [9.9642e-01, 1.7801e-03, 1.7955e-03],\n",
       "          [9.9457e-01, 2.6960e-03, 2.7323e-03],\n",
       "          [9.9843e-01, 7.8259e-04, 7.8310e-04],\n",
       "          [9.8447e-01, 7.7056e-03, 7.8287e-03],\n",
       "          [9.9719e-01, 1.3994e-03, 1.4131e-03],\n",
       "          [9.9309e-01, 3.4437e-03, 3.4646e-03],\n",
       "          [9.8281e-01, 8.4936e-03, 8.6979e-03],\n",
       "          [9.8911e-01, 5.3733e-03, 5.5216e-03],\n",
       "          [9.9021e-01, 4.8601e-03, 4.9293e-03],\n",
       "          [9.9620e-01, 1.8916e-03, 1.9126e-03],\n",
       "          [9.9930e-01, 3.5023e-04, 3.5370e-04],\n",
       "          [9.8423e-01, 7.7974e-03, 7.9701e-03],\n",
       "          [9.8862e-01, 5.6258e-03, 5.7543e-03],\n",
       "          [9.9574e-01, 2.1110e-03, 2.1498e-03],\n",
       "          [9.8136e-01, 9.2292e-03, 9.4134e-03],\n",
       "          [9.9617e-01, 1.9053e-03, 1.9222e-03],\n",
       "          [9.8252e-01, 8.6805e-03, 8.7992e-03],\n",
       "          [9.8509e-01, 7.3733e-03, 7.5383e-03],\n",
       "          [9.8821e-01, 5.8458e-03, 5.9412e-03],\n",
       "          [9.8604e-01, 6.8947e-03, 7.0630e-03],\n",
       "          [9.9909e-01, 4.5503e-04, 4.5690e-04],\n",
       "          [9.9824e-01, 8.7504e-04, 8.8243e-04],\n",
       "          [9.8827e-01, 5.8159e-03, 5.9152e-03],\n",
       "          [9.9966e-01, 1.6881e-04, 1.6910e-04],\n",
       "          [9.7769e-01, 1.1025e-02, 1.1288e-02],\n",
       "          [9.9702e-01, 1.4848e-03, 1.4945e-03],\n",
       "          [9.9233e-01, 3.8021e-03, 3.8685e-03],\n",
       "          [9.7749e-01, 1.1166e-02, 1.1343e-02],\n",
       "          [9.7593e-01, 1.1911e-02, 1.2155e-02],\n",
       "          [9.9935e-01, 3.2332e-04, 3.2465e-04],\n",
       "          [9.7709e-01, 1.1306e-02, 1.1600e-02],\n",
       "          [9.8231e-01, 8.7672e-03, 8.9256e-03],\n",
       "          [9.7512e-01, 1.2327e-02, 1.2548e-02],\n",
       "          [9.8737e-01, 6.2460e-03, 6.3793e-03],\n",
       "          [9.8602e-01, 6.9178e-03, 7.0630e-03],\n",
       "          [9.7979e-01, 1.0040e-02, 1.0166e-02],\n",
       "          [9.9267e-01, 3.6314e-03, 3.6988e-03],\n",
       "          [9.7528e-01, 1.2233e-02, 1.2490e-02],\n",
       "          [9.6939e-01, 1.5122e-02, 1.5493e-02],\n",
       "          [9.9664e-01, 1.6679e-03, 1.6936e-03],\n",
       "          [9.7832e-01, 1.0765e-02, 1.0915e-02],\n",
       "          [9.8704e-01, 6.4184e-03, 6.5460e-03],\n",
       "          [9.8088e-01, 9.4400e-03, 9.6784e-03],\n",
       "          [9.6994e-01, 1.4824e-02, 1.5234e-02],\n",
       "          [9.9652e-01, 1.7291e-03, 1.7473e-03],\n",
       "          [9.8527e-01, 7.3064e-03, 7.4271e-03],\n",
       "          [9.9480e-01, 2.5765e-03, 2.6202e-03],\n",
       "          [9.8423e-01, 7.8125e-03, 7.9616e-03],\n",
       "          [9.7913e-01, 1.0345e-02, 1.0523e-02],\n",
       "          [9.6929e-01, 1.5139e-02, 1.5567e-02],\n",
       "          [9.8512e-01, 7.3694e-03, 7.5132e-03],\n",
       "          [9.7801e-01, 1.0882e-02, 1.1105e-02],\n",
       "          [9.9565e-01, 2.1766e-03, 2.1770e-03],\n",
       "          [9.9843e-01, 7.7914e-04, 7.8589e-04],\n",
       "          [9.9701e-01, 1.4937e-03, 1.4996e-03],\n",
       "          [9.8021e-01, 9.7936e-03, 9.9964e-03],\n",
       "          [9.9244e-01, 3.7428e-03, 3.8187e-03],\n",
       "          [9.8446e-01, 7.6802e-03, 7.8605e-03],\n",
       "          [9.9045e-01, 4.7405e-03, 4.8115e-03],\n",
       "          [9.8283e-01, 8.4853e-03, 8.6877e-03],\n",
       "          [9.8104e-01, 9.3600e-03, 9.5983e-03],\n",
       "          [9.8210e-01, 8.8605e-03, 9.0358e-03],\n",
       "          [9.8570e-01, 7.0989e-03, 7.2020e-03],\n",
       "          [9.8660e-01, 6.6325e-03, 6.7630e-03],\n",
       "          [9.8711e-01, 6.4150e-03, 6.4791e-03],\n",
       "          [9.8017e-01, 9.8303e-03, 9.9996e-03],\n",
       "          [9.8721e-01, 6.3478e-03, 6.4464e-03],\n",
       "          [9.8778e-01, 6.0684e-03, 6.1514e-03],\n",
       "          [9.9999e-01, 3.3423e-06, 3.3439e-06],\n",
       "          [9.9850e-01, 7.4727e-04, 7.5473e-04],\n",
       "          [9.8649e-01, 6.6807e-03, 6.8303e-03],\n",
       "          [9.8905e-01, 5.4225e-03, 5.5244e-03],\n",
       "          [9.8625e-01, 6.8200e-03, 6.9339e-03]], grad_fn=<CopySlices>),\n",
       "  'mod': tensor([[1.0000e+00, 3.7489e-27, 3.7489e-27, 3.7489e-27, 3.7489e-27, 3.7489e-27],\n",
       "          [9.9836e-01, 3.2424e-04, 3.2809e-04, 3.2845e-04, 3.2513e-04, 3.3682e-04],\n",
       "          [9.7040e-01, 5.6904e-03, 6.0574e-03, 5.8744e-03, 5.8157e-03, 6.1662e-03],\n",
       "          [1.0000e+00, 1.9325e-18, 1.9325e-18, 1.9325e-18, 1.9325e-18, 1.9325e-18],\n",
       "          [1.0000e+00, 2.0861e-18, 2.0861e-18, 2.0861e-18, 2.0861e-18, 2.0861e-18],\n",
       "          [9.3868e-01, 1.1681e-02, 1.2403e-02, 1.2153e-02, 1.1889e-02, 1.3199e-02],\n",
       "          [1.0000e+00, 1.3803e-18, 1.3803e-18, 1.3803e-18, 1.3803e-18, 1.3803e-18],\n",
       "          [9.4517e-01, 1.0488e-02, 1.1084e-02, 1.0943e-02, 1.0637e-02, 1.1675e-02],\n",
       "          [9.2458e-01, 1.4273e-02, 1.5321e-02, 1.4931e-02, 1.4599e-02, 1.6291e-02],\n",
       "          [1.0000e+00, 2.2080e-18, 2.2080e-18, 2.2080e-18, 2.2080e-18, 2.2080e-18],\n",
       "          [9.3579e-01, 1.2278e-02, 1.3082e-02, 1.2677e-02, 1.2565e-02, 1.3604e-02],\n",
       "          [9.6807e-01, 6.1401e-03, 6.4372e-03, 6.3982e-03, 6.2380e-03, 6.7203e-03],\n",
       "          [9.1253e-01, 1.6581e-02, 1.7749e-02, 1.7262e-02, 1.7039e-02, 1.8842e-02],\n",
       "          [9.4504e-01, 1.0464e-02, 1.1083e-02, 1.0919e-02, 1.0667e-02, 1.1828e-02],\n",
       "          [1.0000e+00, 1.8438e-18, 1.8438e-18, 1.8438e-18, 1.8438e-18, 1.8438e-18],\n",
       "          [8.9157e-01, 2.0527e-02, 2.1940e-02, 2.1335e-02, 2.1138e-02, 2.3486e-02],\n",
       "          [1.0000e+00, 2.2662e-18, 2.2662e-18, 2.2662e-18, 2.2662e-18, 2.2662e-18],\n",
       "          [9.4033e-01, 1.1416e-02, 1.2127e-02, 1.1856e-02, 1.1613e-02, 1.2658e-02],\n",
       "          [9.2414e-01, 1.4424e-02, 1.5351e-02, 1.4958e-02, 1.4820e-02, 1.6311e-02],\n",
       "          [1.0000e+00, 1.6471e-18, 1.6471e-18, 1.6471e-18, 1.6471e-18, 1.6471e-18],\n",
       "          [9.4591e-01, 1.0396e-02, 1.1059e-02, 1.0682e-02, 1.0594e-02, 1.1359e-02],\n",
       "          [9.0194e-01, 1.8494e-02, 1.9878e-02, 1.9285e-02, 1.9092e-02, 2.1306e-02],\n",
       "          [1.0000e+00, 1.8146e-18, 1.8146e-18, 1.8146e-18, 1.8146e-18, 1.8146e-18],\n",
       "          [1.0000e+00, 2.2365e-18, 2.2365e-18, 2.2365e-18, 2.2365e-18, 2.2365e-18],\n",
       "          [1.0000e+00, 3.4305e-27, 3.4305e-27, 3.4305e-27, 3.4305e-27, 3.4305e-27],\n",
       "          [9.2753e-01, 1.3786e-02, 1.4741e-02, 1.4351e-02, 1.4009e-02, 1.5579e-02],\n",
       "          [1.0000e+00, 3.2483e-27, 3.2483e-27, 3.2483e-27, 3.2483e-27, 3.2483e-27],\n",
       "          [9.7444e-01, 4.9311e-03, 5.0967e-03, 5.1193e-03, 5.0078e-03, 5.4033e-03],\n",
       "          [9.4496e-01, 1.0556e-02, 1.1217e-02, 1.0994e-02, 1.0740e-02, 1.1530e-02],\n",
       "          [9.3673e-01, 1.2019e-02, 1.2755e-02, 1.2535e-02, 1.2263e-02, 1.3700e-02],\n",
       "          [9.2529e-01, 1.4214e-02, 1.5151e-02, 1.4764e-02, 1.4369e-02, 1.6208e-02],\n",
       "          [9.1940e-01, 1.5434e-02, 1.6382e-02, 1.5750e-02, 1.5789e-02, 1.7243e-02],\n",
       "          [9.1707e-01, 1.5772e-02, 1.6809e-02, 1.6361e-02, 1.6198e-02, 1.7790e-02],\n",
       "          [9.4289e-01, 1.1039e-02, 1.1482e-02, 1.1380e-02, 1.1204e-02, 1.2002e-02],\n",
       "          [9.3462e-01, 1.2352e-02, 1.3282e-02, 1.3022e-02, 1.2559e-02, 1.4164e-02],\n",
       "          [1.0000e+00, 3.1663e-27, 3.1663e-27, 3.1663e-27, 3.1663e-27, 3.1663e-27],\n",
       "          [9.4921e-01, 9.7892e-03, 1.0340e-02, 9.9807e-03, 9.9369e-03, 1.0746e-02],\n",
       "          [9.3002e-01, 1.3451e-02, 1.4259e-02, 1.3920e-02, 1.3634e-02, 1.4719e-02],\n",
       "          [9.7975e-01, 3.9352e-03, 4.1347e-03, 3.9797e-03, 3.9587e-03, 4.2399e-03],\n",
       "          [9.4218e-01, 1.0982e-02, 1.1632e-02, 1.1420e-02, 1.1216e-02, 1.2566e-02],\n",
       "          [9.2929e-01, 1.3517e-02, 1.4295e-02, 1.4015e-02, 1.3681e-02, 1.5199e-02],\n",
       "          [9.9660e-01, 6.6855e-04, 6.8099e-04, 6.7709e-04, 6.7285e-04, 7.0026e-04],\n",
       "          [9.5304e-01, 8.9741e-03, 9.4833e-03, 9.3795e-03, 9.1955e-03, 9.9319e-03],\n",
       "          [9.7661e-01, 4.5144e-03, 4.7667e-03, 4.6746e-03, 4.5613e-03, 4.8774e-03],\n",
       "          [9.2868e-01, 1.3542e-02, 1.4407e-02, 1.4080e-02, 1.3846e-02, 1.5439e-02],\n",
       "          [1.0000e+00, 2.6410e-18, 2.6410e-18, 2.6410e-18, 2.6410e-18, 2.6410e-18],\n",
       "          [1.0000e+00, 2.0581e-18, 2.0581e-18, 2.0581e-18, 2.0581e-18, 2.0581e-18],\n",
       "          [9.6337e-01, 7.0221e-03, 7.5133e-03, 7.1604e-03, 7.1557e-03, 7.7760e-03],\n",
       "          [9.2026e-01, 1.5335e-02, 1.6158e-02, 1.5751e-02, 1.5615e-02, 1.6885e-02],\n",
       "          [9.4254e-01, 1.0997e-02, 1.1706e-02, 1.1447e-02, 1.1207e-02, 1.2104e-02],\n",
       "          [9.8516e-01, 2.8682e-03, 2.9914e-03, 2.9379e-03, 2.9294e-03, 3.1175e-03],\n",
       "          [1.0000e+00, 2.2218e-18, 2.2218e-18, 2.2218e-18, 2.2218e-18, 2.2218e-18],\n",
       "          [8.9196e-01, 2.0465e-02, 2.2188e-02, 2.1556e-02, 2.1102e-02, 2.2725e-02],\n",
       "          [9.0697e-01, 1.7631e-02, 1.8865e-02, 1.8255e-02, 1.8169e-02, 2.0109e-02],\n",
       "          [9.3625e-01, 1.2113e-02, 1.2859e-02, 1.2635e-02, 1.2353e-02, 1.3785e-02],\n",
       "          [9.5108e-01, 9.3390e-03, 9.9902e-03, 9.5939e-03, 9.6068e-03, 1.0387e-02],\n",
       "          [1.0000e+00, 2.1753e-18, 2.1753e-18, 2.1753e-18, 2.1753e-18, 2.1753e-18],\n",
       "          [9.1475e-01, 1.6154e-02, 1.7142e-02, 1.6770e-02, 1.6678e-02, 1.8505e-02],\n",
       "          [9.9868e-01, 2.6100e-04, 2.6395e-04, 2.6385e-04, 2.6183e-04, 2.6937e-04],\n",
       "          [9.3374e-01, 1.2659e-02, 1.3317e-02, 1.3157e-02, 1.2908e-02, 1.4220e-02],\n",
       "          [9.1807e-01, 1.5547e-02, 1.6602e-02, 1.6214e-02, 1.5952e-02, 1.7616e-02],\n",
       "          [1.0000e+00, 2.2512e-18, 2.2512e-18, 2.2512e-18, 2.2512e-18, 2.2512e-18],\n",
       "          [9.4100e-01, 1.1321e-02, 1.1980e-02, 1.1662e-02, 1.1525e-02, 1.2517e-02],\n",
       "          [9.3156e-01, 1.3004e-02, 1.3646e-02, 1.3636e-02, 1.3455e-02, 1.4698e-02],\n",
       "          [1.0000e+00, 1.9732e-27, 1.9732e-27, 1.9732e-27, 1.9732e-27, 1.9732e-27],\n",
       "          [9.3097e-01, 1.3121e-02, 1.3935e-02, 1.3703e-02, 1.3378e-02, 1.4896e-02],\n",
       "          [9.1281e-01, 1.6652e-02, 1.7837e-02, 1.7402e-02, 1.6921e-02, 1.8380e-02],\n",
       "          [9.4720e-01, 1.0133e-02, 1.0699e-02, 1.0332e-02, 1.0340e-02, 1.1292e-02],\n",
       "          [9.3354e-01, 1.2782e-02, 1.3472e-02, 1.3283e-02, 1.2994e-02, 1.3931e-02],\n",
       "          [9.3640e-01, 1.2134e-02, 1.2872e-02, 1.2633e-02, 1.2344e-02, 1.3617e-02],\n",
       "          [9.5948e-01, 7.7837e-03, 8.2181e-03, 7.9438e-03, 7.9647e-03, 8.6100e-03],\n",
       "          [1.0000e+00, 2.6746e-18, 2.6746e-18, 2.6746e-18, 2.6746e-18, 2.6746e-18],\n",
       "          [9.1799e-01, 1.5617e-02, 1.6652e-02, 1.6195e-02, 1.6012e-02, 1.7534e-02],\n",
       "          [9.2786e-01, 1.3756e-02, 1.4677e-02, 1.4331e-02, 1.4038e-02, 1.5339e-02],\n",
       "          [9.7709e-01, 4.4338e-03, 4.6366e-03, 4.5181e-03, 4.5177e-03, 4.8060e-03],\n",
       "          [9.7622e-01, 4.6129e-03, 4.8083e-03, 4.7387e-03, 4.6588e-03, 4.9586e-03],\n",
       "          [9.7268e-01, 5.2240e-03, 5.5571e-03, 5.3423e-03, 5.3038e-03, 5.8886e-03],\n",
       "          [9.5134e-01, 9.2951e-03, 9.8928e-03, 9.5617e-03, 9.5579e-03, 1.0352e-02],\n",
       "          [1.0000e+00, 3.8601e-18, 3.8601e-18, 3.8601e-18, 3.8601e-18, 3.8601e-18],\n",
       "          [1.0000e+00, 2.6951e-18, 2.6951e-18, 2.6951e-18, 2.6951e-18, 2.6951e-18],\n",
       "          [9.3646e-01, 1.2126e-02, 1.2912e-02, 1.2548e-02, 1.2350e-02, 1.3608e-02],\n",
       "          [9.1670e-01, 1.5769e-02, 1.6922e-02, 1.6486e-02, 1.6200e-02, 1.7918e-02],\n",
       "          [9.3793e-01, 1.1877e-02, 1.2635e-02, 1.2213e-02, 1.2105e-02, 1.3237e-02],\n",
       "          [1.0000e+00, 1.7446e-18, 1.7446e-18, 1.7446e-18, 1.7446e-18, 1.7446e-18],\n",
       "          [9.5028e-01, 9.5387e-03, 9.9283e-03, 1.0086e-02, 9.6699e-03, 1.0494e-02],\n",
       "          [9.4252e-01, 1.0983e-02, 1.1615e-02, 1.1392e-02, 1.1173e-02, 1.2314e-02],\n",
       "          [9.3944e-01, 1.1498e-02, 1.2304e-02, 1.1940e-02, 1.1878e-02, 1.2942e-02],\n",
       "          [9.8189e-01, 3.4985e-03, 3.6612e-03, 3.5705e-03, 3.5457e-03, 3.8296e-03],\n",
       "          [9.3224e-01, 1.2896e-02, 1.3690e-02, 1.3463e-02, 1.3136e-02, 1.4573e-02],\n",
       "          [1.0000e+00, 4.0285e-27, 4.0285e-27, 4.0285e-27, 4.0285e-27, 4.0285e-27],\n",
       "          [9.1462e-01, 1.6257e-02, 1.7256e-02, 1.7068e-02, 1.6641e-02, 1.8156e-02],\n",
       "          [9.4363e-01, 1.0771e-02, 1.1385e-02, 1.1165e-02, 1.0957e-02, 1.2087e-02],\n",
       "          [9.4513e-01, 1.0496e-02, 1.1197e-02, 1.0737e-02, 1.0727e-02, 1.1711e-02],\n",
       "          [9.3229e-01, 1.2845e-02, 1.3608e-02, 1.3339e-02, 1.3169e-02, 1.4746e-02],\n",
       "          [9.9777e-01, 4.3906e-04, 4.4672e-04, 4.4103e-04, 4.3977e-04, 4.5956e-04],\n",
       "          [9.8112e-01, 3.6481e-03, 3.7897e-03, 3.7410e-03, 3.7180e-03, 3.9837e-03],\n",
       "          [9.5081e-01, 9.5300e-03, 9.9007e-03, 9.7665e-03, 9.6648e-03, 1.0326e-02],\n",
       "          [1.0000e+00, 2.1407e-18, 2.1407e-18, 2.1407e-18, 2.1407e-18, 2.1407e-18],\n",
       "          [9.1925e-01, 1.5349e-02, 1.6355e-02, 1.5922e-02, 1.5773e-02, 1.7349e-02],\n",
       "          [9.7814e-01, 4.2333e-03, 4.4547e-03, 4.3301e-03, 4.2896e-03, 4.5514e-03],\n",
       "          [1.0000e+00, 2.1494e-18, 2.1494e-18, 2.1494e-18, 2.1494e-18, 2.1494e-18],\n",
       "          [9.4058e-01, 1.1417e-02, 1.1957e-02, 1.1859e-02, 1.1537e-02, 1.2649e-02],\n",
       "          [9.2149e-01, 1.5032e-02, 1.5937e-02, 1.5335e-02, 1.5385e-02, 1.6823e-02],\n",
       "          [9.7905e-01, 4.0567e-03, 4.2370e-03, 4.1578e-03, 4.1171e-03, 4.3766e-03],\n",
       "          [9.3485e-01, 1.2452e-02, 1.3230e-02, 1.2994e-02, 1.2688e-02, 1.3784e-02],\n",
       "          [1.0000e+00, 1.9359e-18, 1.9359e-18, 1.9359e-18, 1.9359e-18, 1.9359e-18],\n",
       "          [9.3076e-01, 1.3212e-02, 1.3972e-02, 1.3782e-02, 1.3480e-02, 1.4795e-02],\n",
       "          [9.1953e-01, 1.5188e-02, 1.6502e-02, 1.6069e-02, 1.5585e-02, 1.7123e-02],\n",
       "          [9.4741e-01, 1.0044e-02, 1.0500e-02, 1.0544e-02, 1.0296e-02, 1.1205e-02],\n",
       "          [9.3074e-01, 1.3207e-02, 1.4059e-02, 1.3913e-02, 1.3466e-02, 1.4616e-02],\n",
       "          [9.5614e-01, 8.4482e-03, 8.9443e-03, 8.6450e-03, 8.5689e-03, 9.2529e-03],\n",
       "          [9.2667e-01, 1.4011e-02, 1.4840e-02, 1.4581e-02, 1.4299e-02, 1.5603e-02],\n",
       "          [9.1052e-01, 1.6878e-02, 1.8083e-02, 1.7656e-02, 1.7427e-02, 1.9431e-02],\n",
       "          [9.1936e-01, 1.5266e-02, 1.6678e-02, 1.6036e-02, 1.5567e-02, 1.7089e-02],\n",
       "          [1.0000e+00, 2.1515e-18, 2.1515e-18, 2.1515e-18, 2.1515e-18, 2.1515e-18],\n",
       "          [9.0969e-01, 1.7159e-02, 1.8627e-02, 1.8142e-02, 1.7502e-02, 1.8878e-02],\n",
       "          [9.2704e-01, 1.3897e-02, 1.4738e-02, 1.4416e-02, 1.4182e-02, 1.5724e-02],\n",
       "          [9.1896e-01, 1.5397e-02, 1.6478e-02, 1.5993e-02, 1.5798e-02, 1.7372e-02],\n",
       "          [1.0000e+00, 1.2650e-18, 1.2650e-18, 1.2650e-18, 1.2650e-18, 1.2650e-18],\n",
       "          [9.5607e-01, 8.4520e-03, 8.9312e-03, 8.6696e-03, 8.6111e-03, 9.2626e-03],\n",
       "          [9.3843e-01, 1.1808e-02, 1.2568e-02, 1.2234e-02, 1.1984e-02, 1.2972e-02],\n",
       "          [9.2681e-01, 1.3905e-02, 1.4882e-02, 1.4361e-02, 1.4352e-02, 1.5687e-02],\n",
       "          [1.0000e+00, 2.2990e-18, 2.2990e-18, 2.2990e-18, 2.2990e-18, 2.2990e-18],\n",
       "          [9.1090e-01, 1.6965e-02, 1.8082e-02, 1.7567e-02, 1.7409e-02, 1.9080e-02],\n",
       "          [9.3589e-01, 1.2352e-02, 1.2995e-02, 1.2655e-02, 1.2572e-02, 1.3540e-02],\n",
       "          [9.1859e-01, 1.5449e-02, 1.6494e-02, 1.6110e-02, 1.5850e-02, 1.7506e-02],\n",
       "          [9.6837e-01, 6.0996e-03, 6.3804e-03, 6.2099e-03, 6.1720e-03, 6.7636e-03],\n",
       "          [9.7852e-01, 4.1592e-03, 4.3078e-03, 4.2876e-03, 4.2174e-03, 4.5070e-03],\n",
       "          [9.8614e-01, 2.6918e-03, 2.7940e-03, 2.7403e-03, 2.7225e-03, 2.9150e-03],\n",
       "          [9.2769e-01, 1.3760e-02, 1.4774e-02, 1.4169e-02, 1.4074e-02, 1.5538e-02],\n",
       "          [9.6764e-01, 6.2598e-03, 6.5295e-03, 6.4419e-03, 6.3112e-03, 6.8177e-03],\n",
       "          [9.3674e-01, 1.2017e-02, 1.2753e-02, 1.2535e-02, 1.2261e-02, 1.3698e-02],\n",
       "          [9.1993e-01, 1.5264e-02, 1.6221e-02, 1.5790e-02, 1.5578e-02, 1.7215e-02],\n",
       "          [9.3851e-01, 1.1827e-02, 1.2413e-02, 1.2197e-02, 1.2037e-02, 1.3018e-02],\n",
       "          [9.1845e-01, 1.5439e-02, 1.6444e-02, 1.6051e-02, 1.5961e-02, 1.7655e-02],\n",
       "          [9.2201e-01, 1.4957e-02, 1.5970e-02, 1.5470e-02, 1.5172e-02, 1.6423e-02],\n",
       "          [1.0000e+00, 1.7322e-18, 1.7322e-18, 1.7322e-18, 1.7322e-18, 1.7322e-18],\n",
       "          [1.0000e+00, 1.7116e-18, 1.7116e-18, 1.7116e-18, 1.7116e-18, 1.7116e-18],\n",
       "          [1.0000e+00, 1.9988e-18, 1.9988e-18, 1.9988e-18, 1.9988e-18, 1.9988e-18],\n",
       "          [1.0000e+00, 2.0943e-18, 2.0943e-18, 2.0943e-18, 2.0943e-18, 2.0943e-18],\n",
       "          [1.0000e+00, 1.9757e-18, 1.9757e-18, 1.9757e-18, 1.9757e-18, 1.9757e-18],\n",
       "          [1.0000e+00, 2.0479e-18, 2.0479e-18, 2.0479e-18, 2.0479e-18, 2.0479e-18],\n",
       "          [9.9828e-01, 3.3902e-04, 3.4420e-04, 3.4126e-04, 3.3985e-04, 3.5117e-04],\n",
       "          [1.0000e+00, 2.7990e-18, 2.7990e-18, 2.7990e-18, 2.7990e-18, 2.7990e-18],\n",
       "          [9.5361e-01, 8.9134e-03, 9.3488e-03, 9.1918e-03, 9.1172e-03, 9.8172e-03],\n",
       "          [9.0447e-01, 1.8070e-02, 1.9511e-02, 1.8954e-02, 1.8621e-02, 2.0378e-02],\n",
       "          [1.0000e+00, 2.0649e-18, 2.0649e-18, 2.0649e-18, 2.0649e-18, 2.0649e-18]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  'cc': tensor([[0.0919, 0.7785, 0.0679, 0.0617],\n",
       "          [0.0112, 0.9712, 0.0089, 0.0087],\n",
       "          [0.0659, 0.8336, 0.0521, 0.0484],\n",
       "          [0.1303, 0.6655, 0.1087, 0.0955],\n",
       "          [0.1562, 0.6055, 0.1248, 0.1136],\n",
       "          [0.1523, 0.6202, 0.1230, 0.1045],\n",
       "          [0.0880, 0.7757, 0.0720, 0.0643],\n",
       "          [0.1580, 0.6168, 0.1218, 0.1034],\n",
       "          [0.1375, 0.6702, 0.1018, 0.0906],\n",
       "          [0.1406, 0.6440, 0.1164, 0.0990],\n",
       "          [0.1631, 0.5921, 0.1317, 0.1132],\n",
       "          [0.0762, 0.8065, 0.0625, 0.0547],\n",
       "          [0.1631, 0.5835, 0.1356, 0.1178],\n",
       "          [0.1491, 0.6329, 0.1168, 0.1011],\n",
       "          [0.1209, 0.6865, 0.1012, 0.0915],\n",
       "          [0.1549, 0.6044, 0.1297, 0.1110],\n",
       "          [0.0341, 0.9115, 0.0279, 0.0265],\n",
       "          [0.1735, 0.5698, 0.1348, 0.1218],\n",
       "          [0.1596, 0.5995, 0.1287, 0.1122],\n",
       "          [0.1087, 0.7258, 0.0869, 0.0786],\n",
       "          [0.1403, 0.6360, 0.1176, 0.1060],\n",
       "          [0.1501, 0.6201, 0.1238, 0.1060],\n",
       "          [0.1539, 0.6081, 0.1258, 0.1122],\n",
       "          [0.0737, 0.8080, 0.0627, 0.0555],\n",
       "          [0.0080, 0.9788, 0.0067, 0.0065],\n",
       "          [0.1154, 0.7051, 0.0960, 0.0836],\n",
       "          [0.0070, 0.9813, 0.0060, 0.0058],\n",
       "          [0.0593, 0.8527, 0.0456, 0.0423],\n",
       "          [0.1586, 0.5939, 0.1326, 0.1149],\n",
       "          [0.1499, 0.6289, 0.1192, 0.1020],\n",
       "          [0.1700, 0.5874, 0.1280, 0.1147],\n",
       "          [0.1663, 0.5874, 0.1284, 0.1179],\n",
       "          [0.1653, 0.5856, 0.1332, 0.1159],\n",
       "          [0.1554, 0.6201, 0.1182, 0.1062],\n",
       "          [0.1330, 0.6875, 0.0958, 0.0837],\n",
       "          [0.0785, 0.8101, 0.0580, 0.0534],\n",
       "          [0.1601, 0.6019, 0.1259, 0.1122],\n",
       "          [0.1301, 0.6745, 0.1026, 0.0928],\n",
       "          [0.1167, 0.7093, 0.0917, 0.0823],\n",
       "          [0.1426, 0.6482, 0.1125, 0.0967],\n",
       "          [0.1651, 0.5987, 0.1238, 0.1125],\n",
       "          [0.0184, 0.9527, 0.0148, 0.0141],\n",
       "          [0.1244, 0.6881, 0.0992, 0.0884],\n",
       "          [0.0577, 0.8595, 0.0427, 0.0401],\n",
       "          [0.1614, 0.6025, 0.1269, 0.1093],\n",
       "          [0.0660, 0.8346, 0.0528, 0.0466],\n",
       "          [0.1055, 0.7217, 0.0911, 0.0818],\n",
       "          [0.1152, 0.7129, 0.0917, 0.0803],\n",
       "          [0.1731, 0.5707, 0.1336, 0.1226],\n",
       "          [0.1353, 0.6525, 0.1131, 0.0991],\n",
       "          [0.0599, 0.8456, 0.0492, 0.0453],\n",
       "          [0.1642, 0.5835, 0.1330, 0.1194],\n",
       "          [0.1205, 0.6925, 0.0981, 0.0890],\n",
       "          [0.1651, 0.5844, 0.1343, 0.1162],\n",
       "          [0.1512, 0.6250, 0.1207, 0.1030],\n",
       "          [0.1375, 0.6506, 0.1123, 0.0996],\n",
       "          [0.1437, 0.6476, 0.1093, 0.0994],\n",
       "          [0.1566, 0.6041, 0.1289, 0.1104],\n",
       "          [0.0096, 0.9752, 0.0077, 0.0074],\n",
       "          [0.1682, 0.5915, 0.1257, 0.1146],\n",
       "          [0.1645, 0.5892, 0.1320, 0.1144],\n",
       "          [0.1488, 0.6266, 0.1183, 0.1063],\n",
       "          [0.1340, 0.6654, 0.1055, 0.0951],\n",
       "          [0.1361, 0.6613, 0.1082, 0.0943],\n",
       "          [0.0082, 0.9781, 0.0069, 0.0068],\n",
       "          [0.1652, 0.5946, 0.1289, 0.1113],\n",
       "          [0.1517, 0.6177, 0.1212, 0.1094],\n",
       "          [0.1436, 0.6432, 0.1129, 0.1004],\n",
       "          [0.1660, 0.5869, 0.1292, 0.1179],\n",
       "          [0.1418, 0.6538, 0.1065, 0.0978],\n",
       "          [0.1373, 0.6576, 0.1094, 0.0957],\n",
       "          [0.1537, 0.6016, 0.1293, 0.1154],\n",
       "          [0.1653, 0.5863, 0.1330, 0.1155],\n",
       "          [0.1519, 0.6164, 0.1250, 0.1068],\n",
       "          [0.0868, 0.7818, 0.0685, 0.0629],\n",
       "          [0.1165, 0.7073, 0.0922, 0.0839],\n",
       "          [0.0680, 0.8201, 0.0593, 0.0527],\n",
       "          [0.1415, 0.6396, 0.1158, 0.1031],\n",
       "          [0.0992, 0.7527, 0.0779, 0.0702],\n",
       "          [0.1101, 0.7179, 0.0909, 0.0810],\n",
       "          [0.1577, 0.6140, 0.1235, 0.1048],\n",
       "          [0.1428, 0.6527, 0.1079, 0.0966],\n",
       "          [0.1316, 0.6738, 0.1020, 0.0926],\n",
       "          [0.1014, 0.7439, 0.0812, 0.0735],\n",
       "          [0.0625, 0.8484, 0.0463, 0.0428],\n",
       "          [0.1644, 0.5997, 0.1275, 0.1084],\n",
       "          [0.1347, 0.6655, 0.1054, 0.0943],\n",
       "          [0.1131, 0.7301, 0.0841, 0.0728],\n",
       "          [0.1662, 0.5919, 0.1301, 0.1119],\n",
       "          [0.0984, 0.7544, 0.0768, 0.0704],\n",
       "          [0.1447, 0.6258, 0.1222, 0.1074],\n",
       "          [0.1626, 0.6044, 0.1258, 0.1072],\n",
       "          [0.1324, 0.6648, 0.1057, 0.0971],\n",
       "          [0.1505, 0.6310, 0.1170, 0.1015],\n",
       "          [0.0696, 0.8309, 0.0518, 0.0478],\n",
       "          [0.0736, 0.8140, 0.0588, 0.0536],\n",
       "          [0.1496, 0.6372, 0.1124, 0.1009],\n",
       "          [0.0436, 0.8870, 0.0357, 0.0338],\n",
       "          [0.1636, 0.5898, 0.1318, 0.1149],\n",
       "          [0.0949, 0.7538, 0.0787, 0.0726],\n",
       "          [0.1221, 0.6928, 0.0971, 0.0880],\n",
       "          [0.1755, 0.5777, 0.1292, 0.1176],\n",
       "          [0.1662, 0.5881, 0.1281, 0.1176],\n",
       "          [0.0607, 0.8455, 0.0488, 0.0451],\n",
       "          [0.1634, 0.5918, 0.1313, 0.1135],\n",
       "          [0.1490, 0.6214, 0.1214, 0.1082],\n",
       "          [0.1725, 0.5800, 0.1294, 0.1181],\n",
       "          [0.1387, 0.6551, 0.1096, 0.0966],\n",
       "          [0.1471, 0.6426, 0.1141, 0.0961],\n",
       "          [0.1538, 0.6120, 0.1264, 0.1077],\n",
       "          [0.1243, 0.6937, 0.0960, 0.0860],\n",
       "          [0.1690, 0.5806, 0.1342, 0.1161],\n",
       "          [0.1637, 0.5889, 0.1326, 0.1148],\n",
       "          [0.1084, 0.7297, 0.0855, 0.0764],\n",
       "          [0.1515, 0.6135, 0.1240, 0.1110],\n",
       "          [0.1353, 0.6463, 0.1157, 0.1027],\n",
       "          [0.1665, 0.5894, 0.1308, 0.1132],\n",
       "          [0.1623, 0.5863, 0.1345, 0.1169],\n",
       "          [0.0979, 0.7539, 0.0774, 0.0708],\n",
       "          [0.1508, 0.6278, 0.1178, 0.1036],\n",
       "          [0.1342, 0.6769, 0.0988, 0.0901],\n",
       "          [0.1519, 0.6255, 0.1165, 0.1061],\n",
       "          [0.1525, 0.6131, 0.1239, 0.1106],\n",
       "          [0.1683, 0.5755, 0.1375, 0.1187],\n",
       "          [0.1456, 0.6360, 0.1143, 0.1042],\n",
       "          [0.1641, 0.5901, 0.1317, 0.1141],\n",
       "          [0.0865, 0.7761, 0.0722, 0.0652],\n",
       "          [0.0798, 0.8013, 0.0629, 0.0559],\n",
       "          [0.0961, 0.7624, 0.0746, 0.0669],\n",
       "          [0.1592, 0.6025, 0.1275, 0.1109],\n",
       "          [0.1325, 0.6768, 0.0993, 0.0914],\n",
       "          [0.1497, 0.6295, 0.1190, 0.1018],\n",
       "          [0.1289, 0.6768, 0.1021, 0.0922],\n",
       "          [0.1457, 0.6353, 0.1151, 0.1040],\n",
       "          [0.1550, 0.6134, 0.1232, 0.1084],\n",
       "          [0.1595, 0.5982, 0.1280, 0.1143],\n",
       "          [0.1354, 0.6485, 0.1146, 0.1015],\n",
       "          [0.1472, 0.6324, 0.1174, 0.1030],\n",
       "          [0.1363, 0.6511, 0.1124, 0.1002],\n",
       "          [0.1558, 0.6081, 0.1236, 0.1125],\n",
       "          [0.1395, 0.6448, 0.1155, 0.1002],\n",
       "          [0.1352, 0.6530, 0.1135, 0.0983],\n",
       "          [0.0085, 0.9768, 0.0074, 0.0072],\n",
       "          [0.0806, 0.8007, 0.0625, 0.0562],\n",
       "          [0.1494, 0.6380, 0.1121, 0.1005],\n",
       "          [0.1403, 0.6562, 0.1063, 0.0972],\n",
       "          [0.1499, 0.6237, 0.1206, 0.1058]], grad_fn=<CopySlices>),\n",
       "  'dlt1': tensor([[2.0894e-10, 1.0285e-13, 8.9041e-10, 3.5082e-13, 3.0970e-11],\n",
       "          [9.3115e-02, 5.9908e-02, 3.4212e-02, 1.4154e-02, 4.8939e-02],\n",
       "          [1.5403e-01, 7.5816e-02, 2.0141e-01, 7.7126e-02, 6.6691e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.6797e-01, 7.0020e-02, 2.1782e-01, 1.1213e-01, 1.3329e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3623e-01, 8.7620e-02, 1.8203e-01, 1.2506e-01, 1.3760e-01],\n",
       "          [1.4975e-01, 9.9382e-02, 3.3937e-01, 1.0690e-01, 1.6868e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3038e-01, 1.0302e-01, 1.4062e-01, 1.7155e-01, 1.0302e-01],\n",
       "          [1.2460e-01, 7.9167e-02, 1.4571e-01, 1.5441e-01, 9.2080e-02],\n",
       "          [1.9356e-01, 8.2686e-02, 1.8490e-01, 1.8778e-01, 9.6750e-02],\n",
       "          [1.4157e-01, 7.4109e-02, 2.1858e-01, 1.0539e-01, 1.3603e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8219e-01, 1.1045e-01, 2.4534e-01, 2.0619e-01, 1.5885e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.6078e-01, 7.5344e-02, 2.2865e-01, 9.5695e-02, 1.4740e-01],\n",
       "          [1.4543e-01, 1.0498e-01, 1.9252e-01, 1.6441e-01, 1.1527e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4298e-01, 1.0092e-01, 1.5074e-01, 1.3672e-01, 1.3209e-01],\n",
       "          [1.8965e-01, 1.1264e-01, 2.6435e-01, 1.9510e-01, 1.7769e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.1376e-10, 2.5244e-13, 5.6857e-10, 5.3323e-13, 1.1980e-12],\n",
       "          [2.0258e-01, 1.1031e-01, 1.5421e-01, 1.4221e-01, 9.5498e-02],\n",
       "          [2.4123e-10, 4.0932e-13, 2.7877e-10, 6.0485e-13, 7.1678e-13],\n",
       "          [2.6585e-01, 1.1133e-01, 1.1986e-01, 7.3539e-02, 6.5624e-02],\n",
       "          [1.7863e-01, 7.5638e-02, 1.5160e-01, 1.3836e-01, 1.0305e-01],\n",
       "          [1.5943e-01, 6.9640e-02, 2.3228e-01, 1.0733e-01, 1.3785e-01],\n",
       "          [1.4804e-01, 1.0599e-01, 2.4641e-01, 1.2678e-01, 1.8021e-01],\n",
       "          [1.7613e-01, 1.2202e-01, 1.9256e-01, 1.1352e-01, 1.5116e-01],\n",
       "          [1.5732e-01, 1.0944e-01, 1.8546e-01, 1.7889e-01, 1.1727e-01],\n",
       "          [1.2042e-01, 1.1511e-01, 1.6279e-01, 1.7831e-01, 1.5089e-01],\n",
       "          [1.6035e-01, 1.0602e-01, 2.6162e-01, 1.2601e-01, 1.5284e-01],\n",
       "          [1.2369e-10, 8.4478e-14, 7.6983e-10, 4.1209e-13, 1.9118e-11],\n",
       "          [1.7878e-01, 1.1887e-01, 1.1571e-01, 9.8645e-02, 8.7768e-02],\n",
       "          [1.9020e-01, 1.6129e-01, 1.5541e-01, 1.5549e-01, 1.1036e-01],\n",
       "          [9.4736e-02, 1.4653e-01, 5.6253e-02, 9.6834e-02, 7.2646e-02],\n",
       "          [1.4765e-01, 6.4042e-02, 2.4418e-01, 9.9097e-02, 1.3155e-01],\n",
       "          [1.3454e-01, 9.7143e-02, 2.8053e-01, 8.8995e-02, 2.1910e-01],\n",
       "          [5.4093e-02, 3.9588e-02, 3.3080e-02, 5.2710e-02, 7.6885e-02],\n",
       "          [1.6588e-01, 8.3108e-02, 1.7305e-01, 8.8733e-02, 1.6021e-01],\n",
       "          [1.3413e-01, 1.1682e-01, 1.2848e-01, 7.7702e-02, 6.2054e-02],\n",
       "          [1.5277e-01, 8.4182e-02, 2.4436e-01, 1.3030e-01, 1.4452e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.6393e-01, 1.0552e-01, 1.3253e-01, 1.0974e-01, 1.2291e-01],\n",
       "          [1.5800e-01, 1.1513e-01, 1.7710e-01, 1.4352e-01, 1.4521e-01],\n",
       "          [1.6672e-01, 7.3321e-02, 1.5398e-01, 1.4632e-01, 8.2358e-02],\n",
       "          [1.1769e-01, 4.6710e-02, 1.0611e-01, 4.4446e-02, 7.5060e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.5312e-01, 1.3815e-01, 3.5144e-01, 1.3303e-01, 1.7971e-01],\n",
       "          [1.7416e-01, 9.8810e-02, 2.1034e-01, 1.8101e-01, 1.1407e-01],\n",
       "          [1.6237e-01, 7.0395e-02, 2.2888e-01, 1.0892e-01, 1.3809e-01],\n",
       "          [1.4892e-01, 9.4043e-02, 1.1943e-01, 1.4216e-01, 6.5510e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8503e-01, 8.1092e-02, 1.8383e-01, 1.8896e-01, 1.0332e-01],\n",
       "          [5.2323e-02, 2.2896e-02, 5.4014e-02, 1.0357e-02, 8.3571e-02],\n",
       "          [1.3796e-01, 7.4942e-02, 3.0587e-01, 8.3106e-02, 1.9518e-01],\n",
       "          [1.6885e-01, 1.1900e-01, 2.1315e-01, 1.6937e-01, 1.3391e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8214e-01, 1.1707e-01, 1.6197e-01, 1.2491e-01, 9.2449e-02],\n",
       "          [1.3911e-01, 9.5556e-02, 1.9985e-01, 2.1761e-01, 1.2485e-01],\n",
       "          [1.6041e-10, 2.7861e-13, 1.8501e-10, 6.0138e-13, 4.5468e-13],\n",
       "          [1.4388e-01, 9.4122e-02, 2.2987e-01, 1.3582e-01, 1.4685e-01],\n",
       "          [2.1412e-01, 1.2809e-01, 1.8664e-01, 1.8158e-01, 1.2421e-01],\n",
       "          [1.4197e-01, 1.1644e-01, 1.2255e-01, 1.1366e-01, 7.8152e-02],\n",
       "          [1.8466e-01, 1.0344e-01, 1.8404e-01, 1.0800e-01, 1.5387e-01],\n",
       "          [1.8572e-01, 1.3971e-01, 1.8450e-01, 1.1591e-01, 1.0429e-01],\n",
       "          [1.2516e-01, 9.9216e-02, 9.6137e-02, 1.3289e-01, 5.4717e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.6255e-01, 1.0978e-01, 1.7761e-01, 1.8252e-01, 1.1475e-01],\n",
       "          [1.4961e-01, 1.1687e-01, 1.9556e-01, 1.8630e-01, 1.5161e-01],\n",
       "          [1.1125e-01, 5.6685e-02, 1.1368e-01, 8.0488e-02, 7.2413e-02],\n",
       "          [9.4834e-02, 5.6355e-02, 1.3050e-01, 7.4447e-02, 8.4358e-02],\n",
       "          [1.0982e-01, 7.4185e-02, 1.2071e-01, 1.2527e-01, 7.7137e-02],\n",
       "          [1.4728e-01, 8.5976e-02, 1.0086e-01, 1.5444e-01, 6.4886e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4090e-01, 7.8136e-02, 1.8196e-01, 1.2827e-01, 1.3371e-01],\n",
       "          [2.0303e-01, 1.4227e-01, 1.9892e-01, 1.3274e-01, 1.2532e-01],\n",
       "          [1.7118e-01, 1.3155e-01, 1.0905e-01, 1.2647e-01, 8.7901e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.0015e-01, 1.5699e-01, 2.1413e-01, 1.3204e-01, 1.1482e-01],\n",
       "          [1.2656e-01, 8.4615e-02, 1.7577e-01, 1.3160e-01, 1.2928e-01],\n",
       "          [1.5032e-01, 7.7813e-02, 2.0361e-01, 1.1510e-01, 1.4888e-01],\n",
       "          [1.0482e-01, 5.9759e-02, 9.2707e-02, 6.7900e-02, 1.1018e-01],\n",
       "          [1.4985e-01, 9.5197e-02, 2.1943e-01, 1.3857e-01, 1.4421e-01],\n",
       "          [1.9039e-10, 1.5434e-13, 7.3066e-10, 4.5503e-13, 2.2129e-11],\n",
       "          [2.0548e-01, 1.0713e-01, 2.1023e-01, 1.9520e-01, 1.3425e-01],\n",
       "          [1.2355e-01, 8.3479e-02, 1.7840e-01, 1.2938e-01, 1.2912e-01],\n",
       "          [1.3552e-01, 1.1324e-01, 1.5655e-01, 1.2135e-01, 1.0191e-01],\n",
       "          [1.3832e-01, 7.8291e-02, 2.6723e-01, 1.1625e-01, 1.4501e-01],\n",
       "          [4.2435e-02, 3.1799e-02, 5.3212e-02, 3.0324e-02, 3.1743e-02],\n",
       "          [1.2906e-01, 4.9539e-02, 6.0369e-02, 8.7043e-02, 5.0414e-02],\n",
       "          [1.7361e-01, 1.2975e-01, 1.0353e-01, 8.2986e-02, 9.0395e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.5263e-01, 1.0781e-01, 1.8971e-01, 1.7390e-01, 1.1687e-01],\n",
       "          [9.6307e-02, 9.0228e-02, 1.1308e-01, 8.1313e-02, 6.3379e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3060e-01, 9.2668e-02, 2.2353e-01, 9.6454e-02, 1.7843e-01],\n",
       "          [1.7180e-01, 1.2007e-01, 1.9365e-01, 1.1076e-01, 1.5010e-01],\n",
       "          [1.2376e-01, 7.5158e-02, 8.6240e-02, 7.1374e-02, 4.3967e-02],\n",
       "          [1.7750e-01, 9.7358e-02, 1.7153e-01, 1.4843e-01, 1.2070e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4996e-01, 7.6488e-02, 2.9423e-01, 8.9128e-02, 1.8905e-01],\n",
       "          [2.2291e-01, 1.0007e-01, 2.4949e-01, 1.3241e-01, 1.2226e-01],\n",
       "          [1.2565e-01, 6.6783e-02, 1.7998e-01, 1.6610e-01, 1.2861e-01],\n",
       "          [2.0862e-01, 1.1784e-01, 1.6516e-01, 1.5745e-01, 1.2924e-01],\n",
       "          [1.2682e-01, 1.4736e-01, 9.4279e-02, 1.2243e-01, 7.2400e-02],\n",
       "          [1.6897e-01, 1.2427e-01, 1.7761e-01, 1.7102e-01, 1.3614e-01],\n",
       "          [1.9762e-01, 8.6737e-02, 2.2383e-01, 1.7002e-01, 1.2055e-01],\n",
       "          [1.7886e-01, 1.2372e-01, 2.5698e-01, 1.7394e-01, 1.3857e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.3814e-01, 1.1766e-01, 1.9861e-01, 1.8665e-01, 1.3931e-01],\n",
       "          [1.3380e-01, 8.9440e-02, 2.1389e-01, 1.4073e-01, 1.3516e-01],\n",
       "          [1.9559e-01, 8.1363e-02, 1.6881e-01, 1.8656e-01, 9.3973e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4434e-01, 1.2325e-01, 8.2323e-02, 1.3338e-01, 5.9279e-02],\n",
       "          [1.5602e-01, 1.8446e-01, 1.6169e-01, 9.9182e-02, 1.1554e-01],\n",
       "          [1.7572e-01, 1.0379e-01, 2.8253e-01, 1.1023e-01, 1.2872e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8028e-01, 1.0551e-01, 1.8198e-01, 1.8571e-01, 1.1680e-01],\n",
       "          [2.0312e-01, 1.5098e-01, 1.4327e-01, 1.3409e-01, 9.2221e-02],\n",
       "          [1.6780e-01, 1.1881e-01, 2.1377e-01, 1.6791e-01, 1.3389e-01],\n",
       "          [1.1343e-01, 9.5494e-02, 8.4302e-02, 1.0182e-01, 9.3381e-02],\n",
       "          [9.4673e-02, 3.8702e-02, 1.7605e-01, 7.4818e-02, 9.4223e-02],\n",
       "          [1.4796e-01, 7.3391e-02, 8.2130e-02, 4.3479e-02, 6.5615e-02],\n",
       "          [1.6089e-01, 1.2138e-01, 1.6468e-01, 1.7241e-01, 1.2101e-01],\n",
       "          [8.6579e-02, 6.9206e-02, 1.6997e-01, 8.1088e-02, 1.1923e-01],\n",
       "          [1.5925e-01, 6.9806e-02, 2.3205e-01, 1.0706e-01, 1.3837e-01],\n",
       "          [2.3998e-01, 1.0722e-01, 1.7008e-01, 1.0720e-01, 1.1983e-01],\n",
       "          [2.0755e-01, 1.3563e-01, 1.5061e-01, 1.1183e-01, 9.6980e-02],\n",
       "          [1.7810e-01, 1.1118e-01, 1.6634e-01, 1.4704e-01, 1.0014e-01],\n",
       "          [1.5838e-01, 1.2539e-01, 2.0613e-01, 1.5216e-01, 1.9392e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.5725e-02, 2.7795e-02, 4.4543e-02, 2.0156e-02, 2.8874e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.2469e-01, 1.3286e-01, 1.0908e-01, 2.0415e-01, 1.0060e-01],\n",
       "          [1.9286e-01, 1.1709e-01, 3.4273e-01, 1.2667e-01, 1.7829e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  'dlt2': tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0025, 0.0011, 0.0003, 0.0013, 0.0012],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<CopySlices>)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temporal_loss(timestoevents,weights=None,maxtime=48,threshold=True):\n",
    "    #list of expected times to events, usualy in order of Const.temporal_outcomes\n",
    "    #basically longer = better, we count > maxtime (weeks) as no event\n",
    "    if weights is None: \n",
    "        weights = [1 for i in range(len(timestoevents))]\n",
    "    scores =  [(w*maxtime/t)for w,t in zip(weights,timestoevents)]\n",
    "    if threshold:\n",
    "        scores = [s*torch.lt(t,maxtime) for s,t in zip(scores,timestoevents)]\n",
    "    scores = torch.stack(scores).sum(axis=0)\n",
    "    return scores\n",
    "\n",
    "def outcome_loss(ypred,weights=None):\n",
    "    #default weights is bad\n",
    "    if weights is None: \n",
    "        print('using default outcome loss weights, which is probably wrong since bad stuff should be negative')\n",
    "        weights = [1 for i in range(ypred.shape[1])]\n",
    "    l = torch.mul(ypred[:,0],weights[0])\n",
    "    for i,weight in enumerate(weights[1:]):\n",
    "        #weights with negative values will invert the outcome so e.g. Regional control becomes no regional control\n",
    "        #so the penaly is correct\n",
    "        newloss = torch.mul(ypred[:,i+1],weight)\n",
    "        l = torch.add(l,newloss)\n",
    "    return l\n",
    "\n",
    "def calc_optimal_decisions(dataset,ids,m1,m2,m3,sm3,\n",
    "                           weights=[0,0.5,.5,0], #weight for OS, FT, AS, and LRC as binary probabilities\n",
    "                           tweights=[1,1,1,1], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "                           outcome_loss_func=None,\n",
    "                           threshold_temporal_loss = False,\n",
    "                           maxtime=48,\n",
    "                           get_transitions=True):\n",
    "    m1.eval()\n",
    "    m2.eval()\n",
    "    m3.eval()\n",
    "    sm3.eval()\n",
    "    device = m1.get_device()\n",
    "    data = dataset.processed_df.copy().loc[ids]\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        #this should have an ic condition but we don't use it anumore anywa\n",
    "        return res\n",
    "        \n",
    "    def formatdf(d):\n",
    "        d = df_to_torch(d).to(device)\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline').loc[ids]\n",
    "    baseline_input = formatdf(baseline)\n",
    "\n",
    "        \n",
    "    if outcome_loss_func is None:\n",
    "        outcome_loss_func = outcome_loss\n",
    "    \n",
    "    cat = lambda x: torch.cat([xx.to(device) for xx in x],axis=1).to(device)\n",
    "    format_transition = lambda x: x.to(device)\n",
    "    def get_outcome(d1,d2,d3):\n",
    "        d1 = torch.full((len(ids),1),d1).type(torch.FloatTensor)\n",
    "        d2 = torch.full((len(ids),1),d2).type(torch.FloatTensor)\n",
    "        d3 = torch.full((len(ids),1),d3).type(torch.FloatTensor)\n",
    "        \n",
    "        tinput1 = cat([baseline_input,d1])\n",
    "        ytransition = m1(tinput1)\n",
    "        [ypd1,ynd1,ymod,ydlt1] = [format_transition(xx) for xx in ytransition['predictions']]\n",
    "        d1_thresh = torch.gt(d1,.5).view(-1,1).to(device)\n",
    "        ypd1[:,0:2] = ypd1[:,0:2]*d1_thresh\n",
    "        ynd1[:,0:2] = ynd1[:,0:2]*d1_thresh\n",
    "        \n",
    "        tinput2 = cat([baseline_input,ypd1,ynd1,ymod,ydlt1,d1,d2])\n",
    "        ytransition2 = m2(tinput2)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = [format_transition(xx) for xx in ytransition2['predictions']]\n",
    "        \n",
    "        input3 = cat([baseline_input, ypd2, ynd2, ycc, ydlt2, d1, d2,d3])\n",
    "        outcome = m3(input3)['predictions']\n",
    "        temporal_outcomes = sm3.time_to_event(input3,n_samples=1)\n",
    "        \n",
    "        transitions = {\n",
    "            'pd1': ypd1,\n",
    "            'nd1': ynd1,\n",
    "            'nd2': ynd2,\n",
    "            'pd2': ypd2,\n",
    "            'mod': ymod,\n",
    "            'cc': ycc,\n",
    "            'dlt1': ydlt1,\n",
    "            'dlt2': ydlt2,\n",
    "        }\n",
    "        return outcome, temporal_outcomes, transitions\n",
    "\n",
    "    losses = []\n",
    "    loss_order = []\n",
    "    transitions = {}\n",
    "    for d1 in [0,1]:\n",
    "        for d2 in [0,1]:\n",
    "            for d3 in [0,1]:\n",
    "                outcomes, tte, transition_entry = get_outcome(d1,d2,d3)\n",
    "                loss = outcome_loss_func(outcomes,weights)\n",
    "                tloss = temporal_loss(tte,tweights,maxtime=maxtime,threshold=threshold_temporal_loss)\n",
    "                loss += tloss\n",
    "                losses.append(loss)\n",
    "                loss_order.append([d1,d2,d3])\n",
    "                transitions[str(d1)+str(d2)+str(d3)] = transition_entry\n",
    "    losses = torch.stack(losses,axis=1)\n",
    "    optimal_decisions = [loss_order[i] for i in torch.argmin(losses,axis=1)]\n",
    "    result = torch.tensor(optimal_decisions).type(torch.FloatTensor)\n",
    "    print(result.sum(axis=0),result.shape[0])\n",
    "    if get_transitions:\n",
    "        opt_transitions = {k: torch.zeros(v.shape).type(torch.FloatTensor) for k,v in transitions['000'].items()}\n",
    "        for i,od in enumerate(optimal_decisions):\n",
    "            key = ''.join([str(o) for o in od])\n",
    "            entry = transitions[key]\n",
    "            for kk,vv in entry.items():\n",
    "                opt_transitions[kk][i,:] = vv[i,:]\n",
    "        return result, opt_transitions\n",
    "    return result\n",
    "\n",
    "test, testtest = get_tt_split()\n",
    "calc_optimal_decisions(DTDataset(),\n",
    "                       testtest,model1,model2,model3,smodel3,\n",
    "                       threshold_temporal_loss=False,\n",
    "                       maxtime=48,\n",
    "                       weights=[0,0,0,0],\n",
    "                       tweights=[2,0.1,0,0],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "122ee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([223.,  23.,  68.]) 389\n",
      "tensor([78., 16., 28.]) 147\n",
      "torch.Size([3, 536, 86])\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 0 _____\n",
      "val reward 2.739492177963257\n",
      "imitation reward 2.10772705078125\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.8807123899459839, 0.001858161180280149, 0.0028599367942661047]\n",
      "[{'decision': 0, 'optimal_auc': 0.6501300631735415, 'imitation_auc': 0.6168893129770991, 'optimal_acc': 0.5306122448979592, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.7657442748091603, 'imitation_auc': 0.6695652173913044, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9054621848739496, 'imitation_auc': 0.7708200890019072, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 1 _____\n",
      "val reward 2.2080421447753906\n",
      "imitation reward 1.423767328262329\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.15189364552497864, 0.0016165042761713266, 0.03400934487581253]\n",
      "[{'decision': 0, 'optimal_auc': 0.657190635451505, 'imitation_auc': 0.5057251908396946, 'optimal_acc': 0.46938775510204084, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9732824427480916, 'imitation_auc': 0.7005434782608695, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.8970588235294118, 'imitation_auc': 0.7507946598855689, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 2 _____\n",
      "val reward 1.4662225246429443\n",
      "imitation reward 1.057037591934204\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.6257736086845398, 0.00516854552552104, 0.20397581160068512]\n",
      "[{'decision': 0, 'optimal_auc': 0.6365663322185061, 'imitation_auc': 0.5, 'optimal_acc': 0.5306122448979592, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9718511450381679, 'imitation_auc': 0.7220108695652174, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9069627851140456, 'imitation_auc': 0.7752701843610934, 'optimal_acc': 0.8639455782312925, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 3 _____\n",
      "val reward 1.398828387260437\n",
      "imitation reward 1.0737617015838623\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.7222489714622498, 0.020909350365400314, 0.31362393498420715]\n",
      "[{'decision': 0, 'optimal_auc': 0.666109253065775, 'imitation_auc': 0.5176526717557253, 'optimal_acc': 0.5238095238095238, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.969942748091603, 'imitation_auc': 0.7133152173913043, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9186674669867947, 'imitation_auc': 0.7975206611570248, 'optimal_acc': 0.8639455782312925, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 4 _____\n",
      "val reward 1.168137788772583\n",
      "imitation reward 1.0572234392166138\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.45594164729118347, 0.03152786195278168, 0.16769763827323914]\n",
      "[{'decision': 0, 'optimal_auc': 0.717391304347826, 'imitation_auc': 0.5868320610687023, 'optimal_acc': 0.6054421768707483, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9608778625954199, 'imitation_auc': 0.7057065217391304, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9276710684273709, 'imitation_auc': 0.8083280356007629, 'optimal_acc': 0.8775510204081632, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 5 _____\n",
      "val reward 1.0572381019592285\n",
      "imitation reward 1.2154626846313477\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5392187237739563, 0.10995962470769882, 0.21586816012859344]\n",
      "[{'decision': 0, 'optimal_auc': 0.7303976217019695, 'imitation_auc': 0.6006679389312977, 'optimal_acc': 0.6530612244897959, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9637404580152672, 'imitation_auc': 0.7013586956521739, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9309723889555822, 'imitation_auc': 0.8124602670057215, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 6 _____\n",
      "val reward 1.0766445398330688\n",
      "imitation reward 1.1954867839813232\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.6691791415214539, 0.10969983041286469, 0.132588729262352]\n",
      "[{'decision': 0, 'optimal_auc': 0.7772203641768859, 'imitation_auc': 0.5782442748091603, 'optimal_acc': 0.5918367346938775, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.961354961832061, 'imitation_auc': 0.7065217391304348, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9318727490996399, 'imitation_auc': 0.8073744437380801, 'optimal_acc': 0.8639455782312925, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 7 _____\n",
      "val reward 1.0340936183929443\n",
      "imitation reward 1.1426527500152588\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5180656313896179, 0.14487184584140778, 0.25508251786231995]\n",
      "[{'decision': 0, 'optimal_auc': 0.7629134150873282, 'imitation_auc': 0.6011450381679388, 'optimal_acc': 0.6462585034013606, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9604007633587786, 'imitation_auc': 0.7081521739130435, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.929171668667467, 'imitation_auc': 0.8223140495867768, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 8 _____\n",
      "val reward 1.0535931587219238\n",
      "imitation reward 1.1561235189437866\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.4290025234222412, 0.04326939582824707, 0.1856347918510437]\n",
      "[{'decision': 0, 'optimal_auc': 0.7861389817911557, 'imitation_auc': 0.6159351145038168, 'optimal_acc': 0.6666666666666666, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9465648854961832, 'imitation_auc': 0.7081521739130434, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9324729891956782, 'imitation_auc': 0.833121424030515, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 9 _____\n",
      "val reward 1.039119839668274\n",
      "imitation reward 1.107424259185791\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.6587597131729126, 0.0458507165312767, 0.191038578748703]\n",
      "[{'decision': 0, 'optimal_auc': 0.8132664437012262, 'imitation_auc': 0.5987595419847329, 'optimal_acc': 0.6802721088435374, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9527671755725191, 'imitation_auc': 0.7089673913043478, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9366746698679471, 'imitation_auc': 0.8328035600762873, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 10 _____\n",
      "val reward 1.0116602182388306\n",
      "imitation reward 1.1843092441558838\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.6343500018119812, 0.07664752006530762, 0.2515254318714142]\n",
      "[{'decision': 0, 'optimal_auc': 0.8125232255667039, 'imitation_auc': 0.5758587786259541, 'optimal_acc': 0.6938775510204082, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.963263358778626, 'imitation_auc': 0.7095108695652174, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9354741896758705, 'imitation_auc': 0.8280356007628735, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 11 _____\n",
      "val reward 0.978380560874939\n",
      "imitation reward 1.1548532247543335\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5122047662734985, 0.05782756209373474, 0.23589350283145905]\n",
      "[{'decision': 0, 'optimal_auc': 0.8153102935711631, 'imitation_auc': 0.5815839694656488, 'optimal_acc': 0.7210884353741497, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9584923664122137, 'imitation_auc': 0.7013586956521739, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.93937575030012, 'imitation_auc': 0.8369357914812461, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 12 _____\n",
      "val reward 0.9596152901649475\n",
      "imitation reward 1.1501882076263428\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5151830315589905, 0.04952097311615944, 0.1861485093832016]\n",
      "[{'decision': 0, 'optimal_auc': 0.8286882199925678, 'imitation_auc': 0.5744274809160306, 'optimal_acc': 0.7414965986394558, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9594465648854962, 'imitation_auc': 0.7005434782608696, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9459783913565426, 'imitation_auc': 0.8477431659249841, 'optimal_acc': 0.8775510204081632, 'imitation_acc': 0.8163265306122449}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 13 _____\n",
      "val reward 0.9419717788696289\n",
      "imitation reward 1.0961494445800781\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5899319648742676, 0.06736742705106735, 0.1716289073228836]\n",
      "[{'decision': 0, 'optimal_auc': 0.8381642512077295, 'imitation_auc': 0.5677480916030534, 'optimal_acc': 0.7278911564625851, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9646946564885496, 'imitation_auc': 0.7089673913043478, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.946578631452581, 'imitation_auc': 0.8502860775588048, 'optimal_acc': 0.8775510204081632, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 14 _____\n",
      "val reward 0.9309374094009399\n",
      "imitation reward 1.0761833190917969\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5568640232086182, 0.09840613603591919, 0.23050692677497864]\n",
      "[{'decision': 0, 'optimal_auc': 0.8407655146785581, 'imitation_auc': 0.5620229007633587, 'optimal_acc': 0.7551020408163265, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9642175572519084, 'imitation_auc': 0.7179347826086956, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9429771908763505, 'imitation_auc': 0.8458359821996186, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 15 _____\n",
      "val reward 0.9494763612747192\n",
      "imitation reward 1.137475609779358\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5052359104156494, 0.08397773653268814, 0.22476795315742493]\n",
      "[{'decision': 0, 'optimal_auc': 0.8450390189520625, 'imitation_auc': 0.5763358778625954, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9627862595419847, 'imitation_auc': 0.7152173913043478, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9423769507803121, 'imitation_auc': 0.8423394787031151, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 16 _____\n",
      "val reward 0.9828728437423706\n",
      "imitation reward 1.2102383375167847\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5139281749725342, 0.05512982979416847, 0.1727801412343979]\n",
      "[{'decision': 0, 'optimal_auc': 0.851170568561873, 'imitation_auc': 0.5844465648854962, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9632633587786259, 'imitation_auc': 0.7076086956521739, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9423769507803121, 'imitation_auc': 0.8417037507946599, 'optimal_acc': 0.8775510204081632, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 17 _____\n",
      "val reward 1.0005178451538086\n",
      "imitation reward 1.1663868427276611\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5610682964324951, 0.04800892993807793, 0.1772262305021286]\n",
      "[{'decision': 0, 'optimal_auc': 0.8530286138981791, 'imitation_auc': 0.5787213740458015, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9642175572519083, 'imitation_auc': 0.7201086956521738, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9429771908763506, 'imitation_auc': 0.840750158931977, 'optimal_acc': 0.8775510204081632, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 18 _____\n",
      "val reward 0.9998139142990112\n",
      "imitation reward 1.1376371383666992\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5562413930892944, 0.059120554476976395, 0.2377421110868454]\n",
      "[{'decision': 0, 'optimal_auc': 0.8582311408398364, 'imitation_auc': 0.569179389312977, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9618320610687023, 'imitation_auc': 0.7432065217391304, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9468787515006002, 'imitation_auc': 0.840114431023522, 'optimal_acc': 0.8843537414965986, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 19 _____\n",
      "val reward 0.984538197517395\n",
      "imitation reward 1.1314500570297241\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5326138138771057, 0.06365964561700821, 0.19428589940071106]\n",
      "[{'decision': 0, 'optimal_auc': 0.8582311408398365, 'imitation_auc': 0.5849236641221374, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9627862595419847, 'imitation_auc': 0.7472826086956521, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9471788715486195, 'imitation_auc': 0.8302606484424666, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 20 _____\n",
      "val reward 1.0223642587661743\n",
      "imitation reward 1.2372156381607056\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5316773653030396, 0.06245574355125427, 0.16333584487438202]\n",
      "[{'decision': 0, 'optimal_auc': 0.8587885544407282, 'imitation_auc': 0.607824427480916, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9646946564885497, 'imitation_auc': 0.7296195652173914, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9471788715486193, 'imitation_auc': 0.819135410044501, 'optimal_acc': 0.891156462585034, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 21 _____\n",
      "val reward 1.0183653831481934\n",
      "imitation reward 1.3289008140563965\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5190941691398621, 0.0624484159052372, 0.20139773190021515]\n",
      "[{'decision': 0, 'optimal_auc': 0.8582311408398364, 'imitation_auc': 0.6040076335877862, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9666030534351145, 'imitation_auc': 0.7230978260869565, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9513805522208884, 'imitation_auc': 0.8130959949141767, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 22 _____\n",
      "val reward 1.0502060651779175\n",
      "imitation reward 1.3087021112442017\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5147212743759155, 0.06367053091526031, 0.24391597509384155]\n",
      "[{'decision': 0, 'optimal_auc': 0.8541434410999628, 'imitation_auc': 0.5815839694656488, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9680343511450381, 'imitation_auc': 0.7266304347826087, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9531812725090036, 'imitation_auc': 0.810553083280356, 'optimal_acc': 0.8843537414965986, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 23 _____\n",
      "val reward 1.0149887800216675\n",
      "imitation reward 1.310874104499817\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5534908771514893, 0.06441156566143036, 0.21199458837509155]\n",
      "[{'decision': 0, 'optimal_auc': 0.8534002229654404, 'imitation_auc': 0.5591603053435115, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9718511450381679, 'imitation_auc': 0.7255434782608696, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9555822328931572, 'imitation_auc': 0.8083280356007629, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 24 _____\n",
      "val reward 1.0443768501281738\n",
      "imitation reward 1.3285250663757324\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5543729066848755, 0.05937213823199272, 0.15631386637687683]\n",
      "[{'decision': 0, 'optimal_auc': 0.8591601635079897, 'imitation_auc': 0.5515267175572519, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9742366412213741, 'imitation_auc': 0.7157608695652173, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9558823529411764, 'imitation_auc': 0.8118245390972664, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7959183673469388}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 25 _____\n",
      "val reward 1.0436654090881348\n",
      "imitation reward 1.337204933166504\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5212624669075012, 0.0703563466668129, 0.14958108961582184]\n",
      "[{'decision': 0, 'optimal_auc': 0.8652917131178001, 'imitation_auc': 0.5391221374045801, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9728053435114504, 'imitation_auc': 0.7165760869565216, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9570828331332533, 'imitation_auc': 0.8073744437380801, 'optimal_acc': 0.8843537414965986, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 26 _____\n",
      "val reward 0.9784489274024963\n",
      "imitation reward 1.410025715827942\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5351572632789612, 0.09958470612764359, 0.2003445029258728]\n",
      "[{'decision': 0, 'optimal_auc': 0.8701226309921962, 'imitation_auc': 0.5252862595419847, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9751908396946565, 'imitation_auc': 0.7114130434782608, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9585834333733493, 'imitation_auc': 0.8032422123331213, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 27 _____\n",
      "val reward 1.0034639835357666\n",
      "imitation reward 1.481576681137085\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.535631000995636, 0.10397039353847504, 0.24130886793136597]\n",
      "[{'decision': 0, 'optimal_auc': 0.8745819397993311, 'imitation_auc': 0.5066793893129772, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9742366412213741, 'imitation_auc': 0.7027173913043478, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9600840336134453, 'imitation_auc': 0.805149396058487, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 28 _____\n",
      "val reward 1.021561861038208\n",
      "imitation reward 1.4896349906921387\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5224039554595947, 0.0852518081665039, 0.24277831614017487]\n",
      "[{'decision': 0, 'optimal_auc': 0.8756967670011149, 'imitation_auc': 0.4942748091603053, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9742366412213741, 'imitation_auc': 0.6932065217391304, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9618847539015606, 'imitation_auc': 0.8038779402415765, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 29 _____\n",
      "val reward 1.0363909006118774\n",
      "imitation reward 1.530369520187378\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5169069170951843, 0.06077616661787033, 0.20690622925758362]\n",
      "[{'decision': 0, 'optimal_auc': 0.8764399851356374, 'imitation_auc': 0.49093511450381677, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9728053435114503, 'imitation_auc': 0.6747282608695652, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9600840336134454, 'imitation_auc': 0.8041958041958042, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 30 _____\n",
      "val reward 1.0435004234313965\n",
      "imitation reward 1.5528554916381836\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5486791729927063, 0.053947046399116516, 0.1710132658481598]\n",
      "[{'decision': 0, 'optimal_auc': 0.8768115942028986, 'imitation_auc': 0.4952290076335878, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9728053435114504, 'imitation_auc': 0.660054347826087, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.962484993997599, 'imitation_auc': 0.8038779402415765, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 31 _____\n",
      "val reward 1.0083277225494385\n",
      "imitation reward 1.5645954608917236\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5582427978515625, 0.0686868280172348, 0.18096454441547394]\n",
      "[{'decision': 0, 'optimal_auc': 0.8771832032701598, 'imitation_auc': 0.5019083969465649, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9742366412213741, 'imitation_auc': 0.6581521739130435, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.963985594237695, 'imitation_auc': 0.8032422123331213, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 32 _____\n",
      "val reward 0.9976294040679932\n",
      "imitation reward 1.5823116302490234\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5254679322242737, 0.08624756336212158, 0.21046221256256104]\n",
      "[{'decision': 0, 'optimal_auc': 0.8758825715347455, 'imitation_auc': 0.5076335877862596, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9766221374045801, 'imitation_auc': 0.6641304347826087, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9675870348139255, 'imitation_auc': 0.8089637635092182, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 33 _____\n",
      "val reward 0.9782555103302002\n",
      "imitation reward 1.725257158279419\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5446006655693054, 0.10438187420368195, 0.21884502470493317]\n",
      "[{'decision': 0, 'optimal_auc': 0.8820141211445559, 'imitation_auc': 0.5219465648854962, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9818702290076335, 'imitation_auc': 0.653804347826087, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9687875150060024, 'imitation_auc': 0.8143674507310871, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 34 _____\n",
      "val reward 0.9688568711280823\n",
      "imitation reward 1.8627269268035889\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5570253133773804, 0.10518494993448257, 0.2077764868736267]\n",
      "[{'decision': 0, 'optimal_auc': 0.8849869936826459, 'imitation_auc': 0.5281488549618321, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.6407608695652174, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9699879951980792, 'imitation_auc': 0.8121424030514939, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 35 _____\n",
      "val reward 0.9758204817771912\n",
      "imitation reward 1.7975659370422363\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5381339192390442, 0.08074778318405151, 0.2034795731306076]\n",
      "[{'decision': 0, 'optimal_auc': 0.8842437755481234, 'imitation_auc': 0.5119274809160306, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9842557251908397, 'imitation_auc': 0.6570652173913043, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9717887154861944, 'imitation_auc': 0.8022886204704387, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 36 _____\n",
      "val reward 1.00978422164917\n",
      "imitation reward 1.7971199750900269\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5141730904579163, 0.06043493002653122, 0.19646196067333221]\n",
      "[{'decision': 0, 'optimal_auc': 0.8808992939427722, 'imitation_auc': 0.5162213740458016, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9842557251908397, 'imitation_auc': 0.6641304347826087, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9720888355342137, 'imitation_auc': 0.7984742530197075, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7959183673469388}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 37 _____\n",
      "val reward 1.0110183954238892\n",
      "imitation reward 1.879839539527893\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5358799695968628, 0.057767581194639206, 0.20950046181678772]\n",
      "[{'decision': 0, 'optimal_auc': 0.8777406168710516, 'imitation_auc': 0.5219465648854962, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9852099236641221, 'imitation_auc': 0.6644021739130435, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9720888355342137, 'imitation_auc': 0.7956134774316592, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 38 _____\n",
      "val reward 1.017220377922058\n",
      "imitation reward 1.9850151538848877\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5368927121162415, 0.06613056361675262, 0.22531865537166595]\n",
      "[{'decision': 0, 'optimal_auc': 0.8755109624674842, 'imitation_auc': 0.5124045801526718, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9856870229007634, 'imitation_auc': 0.6603260869565217, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9735894357743097, 'imitation_auc': 0.7892561983471074, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 39 _____\n",
      "val reward 1.019885778427124\n",
      "imitation reward 2.1082727909088135\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5346072912216187, 0.07960055023431778, 0.226795956492424]\n",
      "[{'decision': 0, 'optimal_auc': 0.8762541806020067, 'imitation_auc': 0.5104961832061069, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9852099236641221, 'imitation_auc': 0.6432065217391305, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 0.973889555822329, 'imitation_auc': 0.7749523204068658, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 40 _____\n",
      "val reward 1.0382297039031982\n",
      "imitation reward 2.2211780548095703\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5236635208129883, 0.08698888123035431, 0.23018376529216766]\n",
      "[{'decision': 0, 'optimal_auc': 0.8755109624674842, 'imitation_auc': 0.5047709923664122, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9856870229007634, 'imitation_auc': 0.628804347826087, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 0.9729891956782712, 'imitation_auc': 0.7596948506039414, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 41 _____\n",
      "val reward 1.0382490158081055\n",
      "imitation reward 2.272505760192871\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5289404988288879, 0.09026705473661423, 0.22669285535812378]\n",
      "[{'decision': 0, 'optimal_auc': 0.8742103307320698, 'imitation_auc': 0.4933206106870229, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.9861641221374046, 'imitation_auc': 0.6307065217391303, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 0.9735894357743098, 'imitation_auc': 0.7546090273363001, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 42 _____\n",
      "val reward 1.0196623802185059\n",
      "imitation reward 2.295069456100464\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5410448908805847, 0.08451783657073975, 0.210286945104599]\n",
      "[{'decision': 0, 'optimal_auc': 0.873652917131178, 'imitation_auc': 0.4947519083969466, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9861641221374046, 'imitation_auc': 0.625, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9735894357743097, 'imitation_auc': 0.7612841703750794, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 43 _____\n",
      "val reward 1.0175937414169312\n",
      "imitation reward 2.241180181503296\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5536942481994629, 0.07605373859405518, 0.2008434683084488]\n",
      "[{'decision': 0, 'optimal_auc': 0.875139353400223, 'imitation_auc': 0.48759541984732824, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.987118320610687, 'imitation_auc': 0.6404891304347826, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9741896758703481, 'imitation_auc': 0.7590591226954864, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 44 _____\n",
      "val reward 1.0302667617797852\n",
      "imitation reward 2.23268461227417\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5483104586601257, 0.06622644513845444, 0.20806671679019928]\n",
      "[{'decision': 0, 'optimal_auc': 0.8743961352657005, 'imitation_auc': 0.48998091603053434, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9885496183206107, 'imitation_auc': 0.6448369565217391, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9735894357743098, 'imitation_auc': 0.7609663064208518, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 45 _____\n",
      "val reward 1.0374457836151123\n",
      "imitation reward 2.152930736541748\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5438679456710815, 0.06521399319171906, 0.22636350989341736]\n",
      "[{'decision': 0, 'optimal_auc': 0.8704942400594575, 'imitation_auc': 0.4937977099236641, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.9880725190839694, 'imitation_auc': 0.6589673913043479, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9732893157262905, 'imitation_auc': 0.7498410680228862, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 46 _____\n",
      "val reward 1.026024580001831\n",
      "imitation reward 2.158705234527588\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5371707081794739, 0.06715624779462814, 0.22706705331802368]\n",
      "[{'decision': 0, 'optimal_auc': 0.8730955035302862, 'imitation_auc': 0.5019083969465649, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9885496183206107, 'imitation_auc': 0.6535326086956523, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.7514303877940242, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 47 _____\n",
      "val reward 0.9984277486801147\n",
      "imitation reward 2.2507898807525635\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5423645377159119, 0.07492921501398087, 0.22450536489486694]\n",
      "[{'decision': 0, 'optimal_auc': 0.8758825715347454, 'imitation_auc': 0.5119274809160305, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.9895038167938931, 'imitation_auc': 0.6453804347826088, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.77177368086459, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 48 _____\n",
      "val reward 0.9820210337638855\n",
      "imitation reward 2.278104543685913\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5462443232536316, 0.08472079783678055, 0.21332335472106934]\n",
      "[{'decision': 0, 'optimal_auc': 0.8756967670011149, 'imitation_auc': 0.5147900763358778, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9904580152671756, 'imitation_auc': 0.6399456521739131, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.96968787515006, 'imitation_auc': 0.7828989192625556, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 49 _____\n",
      "val reward 0.9894413948059082\n",
      "imitation reward 2.2578165531158447\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5414515137672424, 0.08777158707380295, 0.20316731929779053]\n",
      "[{'decision': 0, 'optimal_auc': 0.8743961352657005, 'imitation_auc': 0.5081106870229007, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9904580152671756, 'imitation_auc': 0.6464673913043479, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9705882352941175, 'imitation_auc': 0.7911633820724729, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 50 _____\n",
      "val reward 1.0249848365783691\n",
      "imitation reward 2.2192282676696777\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5337875485420227, 0.08299502730369568, 0.18589016795158386]\n",
      "[{'decision': 0, 'optimal_auc': 0.8703084355258268, 'imitation_auc': 0.49570610687022904, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.8095238095238095}, {'decision': 1, 'optimal_auc': 0.9899809160305343, 'imitation_auc': 0.6557065217391305, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9720888355342137, 'imitation_auc': 0.796567069294342, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 51 _____\n",
      "val reward 1.0677003860473633\n",
      "imitation reward 2.2075064182281494\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5281473398208618, 0.07623038440942764, 0.18690967559814453]\n",
      "[{'decision': 0, 'optimal_auc': 0.8677071720549981, 'imitation_auc': 0.4878339694656489, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9880725190839695, 'imitation_auc': 0.6510869565217392, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.7972027972027972, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 52 _____\n",
      "val reward 1.0874463319778442\n",
      "imitation reward 2.2582454681396484\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5436656475067139, 0.07794301211833954, 0.2062675505876541]\n",
      "[{'decision': 0, 'optimal_auc': 0.8647342995169082, 'imitation_auc': 0.4830629770992366, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9866412213740459, 'imitation_auc': 0.6478260869565218, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9717887154861945, 'imitation_auc': 0.7940241576605214, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 53 _____\n",
      "val reward 1.1462743282318115\n",
      "imitation reward 2.349731206893921\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5930015444755554, 0.08018115907907486, 0.2131338119506836]\n",
      "[{'decision': 0, 'optimal_auc': 0.8602749907097733, 'imitation_auc': 0.4718511450381679, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8639455782312925}, {'decision': 1, 'optimal_auc': 0.9866412213740459, 'imitation_auc': 0.6339673913043478, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9705882352941178, 'imitation_auc': 0.7959313413858868, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 54 _____\n",
      "val reward 1.2097915410995483\n",
      "imitation reward 2.3393139839172363\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.6056888103485107, 0.07682808488607407, 0.22136302292346954]\n",
      "[{'decision': 0, 'optimal_auc': 0.8554440728353772, 'imitation_auc': 0.46803435114503816, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.9861641221374046, 'imitation_auc': 0.6372282608695652, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9714885954381752, 'imitation_auc': 0.7902097902097902, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 55 _____\n",
      "val reward 1.1863456964492798\n",
      "imitation reward 2.2945892810821533\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5567424297332764, 0.07114268839359283, 0.22142823040485382]\n",
      "[{'decision': 0, 'optimal_auc': 0.858974358974359, 'imitation_auc': 0.4651717557251908, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.9852099236641221, 'imitation_auc': 0.6461956521739131, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9696878751500599, 'imitation_auc': 0.7838525111252383, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 56 _____\n",
      "val reward 1.187688946723938\n",
      "imitation reward 2.287229061126709\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5207712650299072, 0.0688977763056755, 0.21462367475032806]\n",
      "[{'decision': 0, 'optimal_auc': 0.862876254180602, 'imitation_auc': 0.46803435114503816, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8095238095238095}, {'decision': 1, 'optimal_auc': 0.9847328244274809, 'imitation_auc': 0.6491847826086956, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9672869147659063, 'imitation_auc': 0.7908455181182454, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 57 _____\n",
      "val reward 1.1592789888381958\n",
      "imitation reward 2.366358757019043\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.524287760257721, 0.07771097868680954, 0.19290240108966827]\n",
      "[{'decision': 0, 'optimal_auc': 0.862876254180602, 'imitation_auc': 0.47781488549618323, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9875954198473282, 'imitation_auc': 0.65, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9645858343337335, 'imitation_auc': 0.8061029879211697, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 58 _____\n",
      "val reward 1.1320297718048096\n",
      "imitation reward 2.4255123138427734\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5393350720405579, 0.08687561750411987, 0.17800097167491913]\n",
      "[{'decision': 0, 'optimal_auc': 0.8634336677814939, 'imitation_auc': 0.4830629770992366, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9890267175572518, 'imitation_auc': 0.6480978260869565, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.965486194477791, 'imitation_auc': 0.8118245390972664, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 59 _____\n",
      "val reward 1.1248924732208252\n",
      "imitation reward 2.4354097843170166\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5416542887687683, 0.08802594244480133, 0.1871401071548462]\n",
      "[{'decision': 0, 'optimal_auc': 0.861389817911557, 'imitation_auc': 0.4825858778625954, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9890267175572519, 'imitation_auc': 0.6461956521739131, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9684873949579832, 'imitation_auc': 0.8153210425937699, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 60 _____\n",
      "val reward 1.148026943206787\n",
      "imitation reward 2.4472479820251465\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5558001399040222, 0.08648218214511871, 0.21478134393692017]\n",
      "[{'decision': 0, 'optimal_auc': 0.855072463768116, 'imitation_auc': 0.47089694656488545, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.987118320610687, 'imitation_auc': 0.6480978260869565, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9708883553421368, 'imitation_auc': 0.8111888111888111, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 61 _____\n",
      "val reward 1.2163044214248657\n",
      "imitation reward 2.4828832149505615\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5578861832618713, 0.07708095014095306, 0.23476192355155945]\n",
      "[{'decision': 0, 'optimal_auc': 0.8494983277591973, 'imitation_auc': 0.45658396946564883, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9861641221374046, 'imitation_auc': 0.6423913043478261, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9720888355342138, 'imitation_auc': 0.805149396058487, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 62 _____\n",
      "val reward 1.2521328926086426\n",
      "imitation reward 2.510287284851074\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5602875351905823, 0.06892110407352448, 0.2379961609840393]\n",
      "[{'decision': 0, 'optimal_auc': 0.8470828688219992, 'imitation_auc': 0.4501431297709924, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.9852099236641222, 'imitation_auc': 0.6266304347826086, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.79815638906548, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 63 _____\n",
      "val reward 1.2333595752716064\n",
      "imitation reward 2.57199764251709\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.562017023563385, 0.06732270866632462, 0.21830490231513977]\n",
      "[{'decision': 0, 'optimal_auc': 0.8467112597547379, 'imitation_auc': 0.45014312977099236, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.6092391304347826, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.7930705657978385, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 64 _____\n",
      "val reward 1.219728708267212\n",
      "imitation reward 2.6738321781158447\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5638012290000916, 0.07214424759149551, 0.20267094671726227]\n",
      "[{'decision': 0, 'optimal_auc': 0.8454106280193237, 'imitation_auc': 0.4494274809160305, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8503401360544217}, {'decision': 1, 'optimal_auc': 0.9818702290076335, 'imitation_auc': 0.59375, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9708883553421369, 'imitation_auc': 0.7794024157660522, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 65 _____\n",
      "val reward 1.2221122980117798\n",
      "imitation reward 2.696726083755493\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.552061140537262, 0.07581165432929993, 0.18868114054203033]\n",
      "[{'decision': 0, 'optimal_auc': 0.8494983277591973, 'imitation_auc': 0.4582538167938931, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9818702290076335, 'imitation_auc': 0.5883152173913043, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9672869147659063, 'imitation_auc': 0.77177368086459, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 66 _____\n",
      "val reward 1.2471613883972168\n",
      "imitation reward 2.707195281982422\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5421361327171326, 0.07478882372379303, 0.1815842241048813]\n",
      "[{'decision': 0, 'optimal_auc': 0.8485693050910442, 'imitation_auc': 0.481631679389313, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9799618320610688, 'imitation_auc': 0.5853260869565217, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9657863145258103, 'imitation_auc': 0.7660521296884932, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 67 _____\n",
      "val reward 1.2583248615264893\n",
      "imitation reward 2.7109742164611816\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5499436259269714, 0.07988496869802475, 0.20971544086933136]\n",
      "[{'decision': 0, 'optimal_auc': 0.8441099962839094, 'imitation_auc': 0.48568702290076327, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9775763358778626, 'imitation_auc': 0.595108695652174, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9627851140456183, 'imitation_auc': 0.7616020343293071, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 68 _____\n",
      "val reward 1.2874927520751953\n",
      "imitation reward 2.7414145469665527\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5505475997924805, 0.07883249223232269, 0.2264135181903839]\n",
      "[{'decision': 0, 'optimal_auc': 0.8435525826830174, 'imitation_auc': 0.5, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9761450381679388, 'imitation_auc': 0.6059782608695652, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9630852340936376, 'imitation_auc': 0.7622377622377622, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 69 _____\n",
      "val reward 1.323827862739563\n",
      "imitation reward 2.733341693878174\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5511098504066467, 0.0706234872341156, 0.2385566383600235]\n",
      "[{'decision': 0, 'optimal_auc': 0.8431809736157562, 'imitation_auc': 0.5107347328244274, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9751908396946565, 'imitation_auc': 0.6279891304347827, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9624849939975991, 'imitation_auc': 0.7628734901462174, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 70 _____\n",
      "val reward 1.306891918182373\n",
      "imitation reward 2.7577147483825684\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5632419586181641, 0.06402581185102463, 0.21823543310165405]\n",
      "[{'decision': 0, 'optimal_auc': 0.8461538461538461, 'imitation_auc': 0.5238549618320612, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9751908396946565, 'imitation_auc': 0.6320652173913044, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9615846338535413, 'imitation_auc': 0.7625556261919898, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 71 _____\n",
      "val reward 1.2859848737716675\n",
      "imitation reward 2.735246181488037\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5804409384727478, 0.06533514708280563, 0.18638861179351807]\n",
      "[{'decision': 0, 'optimal_auc': 0.8478260869565218, 'imitation_auc': 0.5300572519083969, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9770992366412214, 'imitation_auc': 0.6361413043478261, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9615846338535414, 'imitation_auc': 0.7622377622377623, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 72 _____\n",
      "val reward 1.2430877685546875\n",
      "imitation reward 2.7121806144714355\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5854169130325317, 0.07666122913360596, 0.18037039041519165]\n",
      "[{'decision': 0, 'optimal_auc': 0.8478260869565218, 'imitation_auc': 0.5295801526717557, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.98043893129771, 'imitation_auc': 0.6385869565217391, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.962484993997599, 'imitation_auc': 0.7631913541004449, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 73 _____\n",
      "val reward 1.2077126502990723\n",
      "imitation reward 2.715541362762451\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5836015343666077, 0.08694503456354141, 0.2021631896495819]\n",
      "[{'decision': 0, 'optimal_auc': 0.8500557413600891, 'imitation_auc': 0.5240935114503817, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9813931297709924, 'imitation_auc': 0.6399456521739131, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9663865546218487, 'imitation_auc': 0.7635092180546726, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 74 _____\n",
      "val reward 1.193095088005066\n",
      "imitation reward 2.732006072998047\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.562433660030365, 0.09051352739334106, 0.22332249581813812]\n",
      "[{'decision': 0, 'optimal_auc': 0.8474544778892605, 'imitation_auc': 0.5190839694656488, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.982824427480916, 'imitation_auc': 0.6279891304347825, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.7584233947870311, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 75 _____\n",
      "val reward 1.2021856307983398\n",
      "imitation reward 2.7935123443603516\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5423046946525574, 0.0839056670665741, 0.22781291604042053]\n",
      "[{'decision': 0, 'optimal_auc': 0.8493125232255667, 'imitation_auc': 0.5200381679389313, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.982824427480916, 'imitation_auc': 0.6081521739130434, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9708883553421368, 'imitation_auc': 0.7511125238397965, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 76 _____\n",
      "val reward 1.2163752317428589\n",
      "imitation reward 2.9077959060668945\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5380070209503174, 0.07262048870325089, 0.21902959048748016]\n",
      "[{'decision': 0, 'optimal_auc': 0.8507989594946116, 'imitation_auc': 0.5248091603053435, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9809160305343512, 'imitation_auc': 0.5907608695652176, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.968187274909964, 'imitation_auc': 0.7479338842975206, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 77 _____\n",
      "val reward 1.237233281135559\n",
      "imitation reward 3.0313897132873535\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5538957118988037, 0.06464564055204391, 0.20581741631031036]\n",
      "[{'decision': 0, 'optimal_auc': 0.8513563730955036, 'imitation_auc': 0.5286259541984732, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9809160305343512, 'imitation_auc': 0.5809782608695652, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9657863145258104, 'imitation_auc': 0.7431659249841068, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 78 _____\n",
      "val reward 1.2712070941925049\n",
      "imitation reward 3.1055126190185547\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5828811526298523, 0.06259140372276306, 0.19397640228271484]\n",
      "[{'decision': 0, 'optimal_auc': 0.8539576365663322, 'imitation_auc': 0.528148854961832, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.9818702290076337, 'imitation_auc': 0.5796195652173913, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9645858343337335, 'imitation_auc': 0.742212333121424, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 79 _____\n",
      "val reward 1.261335015296936\n",
      "imitation reward 3.1015820503234863\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5879543423652649, 0.07203014940023422, 0.20504820346832275]\n",
      "[{'decision': 0, 'optimal_auc': 0.8530286138981792, 'imitation_auc': 0.5283874045801528, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.982824427480916, 'imitation_auc': 0.5907608695652175, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9660864345738296, 'imitation_auc': 0.7472981563890655, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 80 _____\n",
      "val reward 1.2425222396850586\n",
      "imitation reward 3.070446014404297\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5740643739700317, 0.0828644335269928, 0.2205016016960144]\n",
      "[{'decision': 0, 'optimal_auc': 0.850613154960981, 'imitation_auc': 0.5245706106870229, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.5978260869565217, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9678871548619448, 'imitation_auc': 0.7527018436109345, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 81 _____\n",
      "val reward 1.2203067541122437\n",
      "imitation reward 3.04032039642334\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5636686086654663, 0.09265422075986862, 0.21746660768985748]\n",
      "[{'decision': 0, 'optimal_auc': 0.8498699368264586, 'imitation_auc': 0.5221851145038168, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9852099236641221, 'imitation_auc': 0.6070652173913044, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9714885954381753, 'imitation_auc': 0.7565162110616657, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 82 _____\n",
      "val reward 1.2221388816833496\n",
      "imitation reward 3.0360946655273438\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5575878024101257, 0.0949116051197052, 0.2145790308713913]\n",
      "[{'decision': 0, 'optimal_auc': 0.8481976960237829, 'imitation_auc': 0.5176526717557252, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9847328244274809, 'imitation_auc': 0.6097826086956522, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9717887154861944, 'imitation_auc': 0.7568340750158932, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 83 _____\n",
      "val reward 1.2559152841567993\n",
      "imitation reward 3.060258388519287\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5504136681556702, 0.07980471104383469, 0.20283560454845428]\n",
      "[{'decision': 0, 'optimal_auc': 0.8494983277591974, 'imitation_auc': 0.5062022900763359, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9847328244274809, 'imitation_auc': 0.6078804347826087, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9711884753901561, 'imitation_auc': 0.7596948506039415, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 84 _____\n",
      "val reward 1.3038427829742432\n",
      "imitation reward 3.0902624130249023\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5544348955154419, 0.06916399300098419, 0.1844790130853653]\n",
      "[{'decision': 0, 'optimal_auc': 0.8511705685618729, 'imitation_auc': 0.5021469465648855, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9828244274809159, 'imitation_auc': 0.6095108695652175, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9681872749099639, 'imitation_auc': 0.7596948506039416, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7551020408163265}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 85 _____\n",
      "val reward 1.3346316814422607\n",
      "imitation reward 3.4257473945617676\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5597478151321411, 0.06469225883483887, 0.18424008786678314]\n",
      "[{'decision': 0, 'optimal_auc': 0.853586027499071, 'imitation_auc': 0.4930820610687023, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.6081521739130434, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9693877551020408, 'imitation_auc': 0.7612841703750794, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 86 _____\n",
      "val reward 1.3455426692962646\n",
      "imitation reward 3.452864646911621\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5613715052604675, 0.06733614951372147, 0.19794994592666626]\n",
      "[{'decision': 0, 'optimal_auc': 0.8524712002972872, 'imitation_auc': 0.481631679389313, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.6059782608695653, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9702881152460984, 'imitation_auc': 0.7616020343293071, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 87 _____\n",
      "val reward 1.3339800834655762\n",
      "imitation reward 3.7278757095336914\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5558397173881531, 0.07911166548728943, 0.21006813645362854]\n",
      "[{'decision': 0, 'optimal_auc': 0.850613154960981, 'imitation_auc': 0.47686068702290074, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9833015267175572, 'imitation_auc': 0.6043478260869565, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9708883553421369, 'imitation_auc': 0.7552447552447553, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 88 _____\n",
      "val reward 1.3264833688735962\n",
      "imitation reward 3.679985284805298\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5536866784095764, 0.08675479143857956, 0.21641618013381958]\n",
      "[{'decision': 0, 'optimal_auc': 0.8489409141583054, 'imitation_auc': 0.481631679389313, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9847328244274809, 'imitation_auc': 0.6059782608695652, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9690876350540216, 'imitation_auc': 0.7527018436109346, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 89 _____\n",
      "val reward 1.3247010707855225\n",
      "imitation reward 3.3655014038085938\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5499271154403687, 0.08491789549589157, 0.21029230952262878]\n",
      "[{'decision': 0, 'optimal_auc': 0.8476402824228912, 'imitation_auc': 0.48998091603053434, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9837786259541985, 'imitation_auc': 0.6067934782608696, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9675870348139256, 'imitation_auc': 0.7457088366179276, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7414965986394558}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 90 _____\n",
      "val reward 1.3220539093017578\n",
      "imitation reward 3.380425453186035\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5497916340827942, 0.07972447574138641, 0.20342959463596344]\n",
      "[{'decision': 0, 'optimal_auc': 0.8468970642883688, 'imitation_auc': 0.495706106870229, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9809160305343512, 'imitation_auc': 0.6097826086956522, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.965486194477791, 'imitation_auc': 0.7374443738080102, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 91 _____\n",
      "val reward 1.322169303894043\n",
      "imitation reward 3.4663100242614746\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5606618523597717, 0.07640188187360764, 0.20833580195903778]\n",
      "[{'decision': 0, 'optimal_auc': 0.8450390189520625, 'imitation_auc': 0.5062022900763359, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9823473282442747, 'imitation_auc': 0.6114130434782609, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9639855942376951, 'imitation_auc': 0.7304513668150032, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 92 _____\n",
      "val reward 1.3145843744277954\n",
      "imitation reward 3.5853092670440674\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5553182363510132, 0.07190996408462524, 0.2124066799879074]\n",
      "[{'decision': 0, 'optimal_auc': 0.8480118914901523, 'imitation_auc': 0.5212309160305344, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9818702290076335, 'imitation_auc': 0.6038043478260869, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.963985594237695, 'imitation_auc': 0.7247298156389065, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 93 _____\n",
      "val reward 1.3004534244537354\n",
      "imitation reward 3.633387327194214\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5455998778343201, 0.0733695700764656, 0.2144075632095337]\n",
      "[{'decision': 0, 'optimal_auc': 0.8485693050910442, 'imitation_auc': 0.5267175572519084, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9823473282442747, 'imitation_auc': 0.5956521739130434, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9642857142857143, 'imitation_auc': 0.721233312142403, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 94 _____\n",
      "val reward 1.2889037132263184\n",
      "imitation reward 3.644596576690674\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5324843525886536, 0.08036351948976517, 0.20823173224925995]\n",
      "[{'decision': 0, 'optimal_auc': 0.8463396506874767, 'imitation_auc': 0.5343511450381679, 'optimal_acc': 0.7482993197278912, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.982824427480916, 'imitation_auc': 0.5945652173913043, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9630852340936374, 'imitation_auc': 0.7167832167832168, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 95 _____\n",
      "val reward 1.29313325881958\n",
      "imitation reward 3.5722734928131104\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5303378105163574, 0.08586595207452774, 0.19634439051151276]\n",
      "[{'decision': 0, 'optimal_auc': 0.8444816053511706, 'imitation_auc': 0.5362595419847329, 'optimal_acc': 0.7482993197278912, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9818702290076335, 'imitation_auc': 0.5926630434782609, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9630852340936373, 'imitation_auc': 0.7136045772409408, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 96 _____\n",
      "val reward 1.3034499883651733\n",
      "imitation reward 3.5446813106536865\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.53884357213974, 0.08077353239059448, 0.19263498485088348]\n",
      "[{'decision': 0, 'optimal_auc': 0.8470828688219992, 'imitation_auc': 0.538645038167939, 'optimal_acc': 0.7619047619047619, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9813931297709924, 'imitation_auc': 0.5907608695652173, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.962484993997599, 'imitation_auc': 0.7145581691036237, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7414965986394558}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 97 _____\n",
      "val reward 1.3224382400512695\n",
      "imitation reward 3.548539400100708\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5470466613769531, 0.0736616775393486, 0.19896817207336426]\n",
      "[{'decision': 0, 'optimal_auc': 0.8487551096246748, 'imitation_auc': 0.5343511450381679, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9809160305343512, 'imitation_auc': 0.5864130434782608, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9639855942376949, 'imitation_auc': 0.717418944691672, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7414965986394558}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 98 _____\n",
      "val reward 1.3496953248977661\n",
      "imitation reward 3.5587961673736572\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5536510944366455, 0.06588783115148544, 0.20336395502090454]\n",
      "[{'decision': 0, 'optimal_auc': 0.8491267186919361, 'imitation_auc': 0.5333969465648855, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9790076335877863, 'imitation_auc': 0.5828804347826086, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9663865546218487, 'imitation_auc': 0.7180546726001271, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 99 _____\n",
      "val reward 1.3748910427093506\n",
      "imitation reward 3.5251588821411133\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5603863596916199, 0.06371008604764938, 0.21101270616054535]\n",
      "[{'decision': 0, 'optimal_auc': 0.8476402824228911, 'imitation_auc': 0.5333969465648855, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.978530534351145, 'imitation_auc': 0.5883152173913043, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9693877551020409, 'imitation_auc': 0.7269548633184997, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 100 _____\n",
      "val reward 1.37416672706604\n",
      "imitation reward 3.4509105682373047\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5689273476600647, 0.0713958889245987, 0.21448425948619843]\n",
      "[{'decision': 0, 'optimal_auc': 0.845224823485693, 'imitation_auc': 0.5357824427480916, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.978530534351145, 'imitation_auc': 0.5956521739130435, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9705882352941176, 'imitation_auc': 0.7310870947234583, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7551020408163265}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 101 _____\n",
      "val reward 1.3529870510101318\n",
      "imitation reward 3.3823986053466797\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5645077228546143, 0.07930374145507812, 0.21337135136127472]\n",
      "[{'decision': 0, 'optimal_auc': 0.845224823485693, 'imitation_auc': 0.5322041984732824, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9775763358778626, 'imitation_auc': 0.6046195652173912, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9717887154861944, 'imitation_auc': 0.7406230133502861, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 102 _____\n",
      "val reward 1.345548152923584\n",
      "imitation reward 3.3746564388275146\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5622622966766357, 0.08203228563070297, 0.20177173614501953]\n",
      "[{'decision': 0, 'optimal_auc': 0.8435525826830175, 'imitation_auc': 0.53125, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8163265306122449}, {'decision': 1, 'optimal_auc': 0.9770992366412213, 'imitation_auc': 0.6092391304347825, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9714885954381752, 'imitation_auc': 0.7418944691671965, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 103 _____\n",
      "val reward 1.3649516105651855\n",
      "imitation reward 3.409292459487915\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5614768266677856, 0.0725250244140625, 0.1875167191028595]\n",
      "[{'decision': 0, 'optimal_auc': 0.8461538461538461, 'imitation_auc': 0.5350667938931297, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8095238095238095}, {'decision': 1, 'optimal_auc': 0.9775763358778626, 'imitation_auc': 0.6133152173913043, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9708883553421368, 'imitation_auc': 0.7428480610298792, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 104 _____\n",
      "val reward 1.3936336040496826\n",
      "imitation reward 3.4478392601013184\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5635994672775269, 0.06493262946605682, 0.18071982264518738]\n",
      "[{'decision': 0, 'optimal_auc': 0.8491267186919361, 'imitation_auc': 0.5353053435114503, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9756679389312977, 'imitation_auc': 0.6089673913043478, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9717887154861945, 'imitation_auc': 0.746980292434838, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 105 _____\n",
      "val reward 1.3871177434921265\n",
      "imitation reward 3.2085423469543457\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5653154253959656, 0.06921535730361938, 0.18212543427944183]\n",
      "[{'decision': 0, 'optimal_auc': 0.8491267186919361, 'imitation_auc': 0.539837786259542, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9766221374045801, 'imitation_auc': 0.6081521739130434, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9726890756302521, 'imitation_auc': 0.750794659885569, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 106 _____\n",
      "val reward 1.3631744384765625\n",
      "imitation reward 3.4812746047973633\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5686199069023132, 0.08094971626996994, 0.18986815214157104]\n",
      "[{'decision': 0, 'optimal_auc': 0.8478260869565216, 'imitation_auc': 0.5343511450381679, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9799618320610688, 'imitation_auc': 0.6092391304347826, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9723889555822329, 'imitation_auc': 0.7539732994278449, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 107 _____\n",
      "val reward 1.351145625114441\n",
      "imitation reward 3.403196334838867\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5539206862449646, 0.09036055207252502, 0.20280762016773224]\n",
      "[{'decision': 0, 'optimal_auc': 0.8448532144184318, 'imitation_auc': 0.5331583969465649, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.9799618320610687, 'imitation_auc': 0.6122282608695653, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9723889555822329, 'imitation_auc': 0.7546090273363001, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 108 _____\n",
      "val reward 1.3574436902999878\n",
      "imitation reward 3.3664779663085938\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5546528697013855, 0.08940212428569794, 0.21315698325634003]\n",
      "[{'decision': 0, 'optimal_auc': 0.8507989594946116, 'imitation_auc': 0.5231393129770991, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9799618320610688, 'imitation_auc': 0.6111413043478261, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9714885954381753, 'imitation_auc': 0.7542911633820725, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 109 _____\n",
      "val reward 1.3768863677978516\n",
      "imitation reward 3.3941965103149414\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5546929240226746, 0.0782427042722702, 0.21824881434440613]\n",
      "[{'decision': 0, 'optimal_auc': 0.8528428093645485, 'imitation_auc': 0.5186068702290075, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8367346938775511}, {'decision': 1, 'optimal_auc': 0.978530534351145, 'imitation_auc': 0.6070652173913043, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9693877551020409, 'imitation_auc': 0.7539732994278449, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 110 _____\n",
      "val reward 1.390576720237732\n",
      "imitation reward 3.483417510986328\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5619707107543945, 0.06704583764076233, 0.2198861539363861]\n",
      "[{'decision': 0, 'optimal_auc': 0.8580453363062058, 'imitation_auc': 0.512881679389313, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9775763358778626, 'imitation_auc': 0.6065217391304347, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9702881152460985, 'imitation_auc': 0.7501589319771137, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 111 _____\n",
      "val reward 1.3946871757507324\n",
      "imitation reward 3.5680713653564453\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5670691728591919, 0.06361755728721619, 0.2094837874174118]\n",
      "[{'decision': 0, 'optimal_auc': 0.8619472315124489, 'imitation_auc': 0.5104961832061068, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.9766221374045801, 'imitation_auc': 0.6089673913043478, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9684873949579832, 'imitation_auc': 0.7447552447552448, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7619047619047619}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 112 _____\n",
      "val reward 1.3517603874206543\n",
      "imitation reward 3.6079094409942627\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5581004023551941, 0.07040034979581833, 0.2046280950307846]\n",
      "[{'decision': 0, 'optimal_auc': 0.8619472315124489, 'imitation_auc': 0.509780534351145, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8571428571428571}, {'decision': 1, 'optimal_auc': 0.9790076335877862, 'imitation_auc': 0.6168478260869565, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.96968787515006, 'imitation_auc': 0.7374443738080102, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 113 _____\n",
      "val reward 1.3040626049041748\n",
      "imitation reward 3.5766396522521973\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.545378565788269, 0.07880967110395432, 0.19755282998085022]\n",
      "[{'decision': 0, 'optimal_auc': 0.862876254180602, 'imitation_auc': 0.5107347328244274, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.8435374149659864}, {'decision': 1, 'optimal_auc': 0.9794847328244275, 'imitation_auc': 0.6225543478260869, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9714885954381753, 'imitation_auc': 0.7399872854418309, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7414965986394558}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 114 _____\n",
      "val reward 1.2820338010787964\n",
      "imitation reward 3.527961492538452\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.5247674584388733, 0.08666027337312698, 0.19808238744735718]\n",
      "[{'decision': 0, 'optimal_auc': 0.8608324043106652, 'imitation_auc': 0.5100190839694656, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8299319727891157}, {'decision': 1, 'optimal_auc': 0.9790076335877862, 'imitation_auc': 0.6293478260869565, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9741896758703482, 'imitation_auc': 0.7409408773045136, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.5306, 0.1088, 0.1905], grad_fn=<MeanBackward1>)\n",
      "______epoch 115 _____\n",
      "val reward 1.3161898851394653\n",
      "imitation reward 3.5037856101989746\n",
      "distance losses 0.0 0.0\n",
      "distributions [0.4980371296405792, 0.0829252302646637, 0.19316887855529785]\n",
      "[{'decision': 0, 'optimal_auc': 0.8599033816425121, 'imitation_auc': 0.5145515267175572, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.8231292517006803}, {'decision': 1, 'optimal_auc': 0.9775763358778626, 'imitation_auc': 0.6353260869565218, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9732893157262905, 'imitation_auc': 0.7383979656706929, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7551020408163265}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(1.5197, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'optimal_auc': 0.8407655146785581, 'imitation_auc': 0.5620229007633587, 'optimal_acc': 0.7551020408163265, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9642175572519084, 'imitation_auc': 0.7179347826086956, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9429771908763505, 'imitation_auc': 0.8458359821996186, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.8163265306122449}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionAttentionModel(\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=1000, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (relu): Softplus(beta=1, threshold=20)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (final_opt_layer): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (final_imitation_layer): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (final_layer): Linear(in_features=1000, out_features=6, bias=True)\n",
       "  (resize_layer): Linear(in_features=90, out_features=100, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_sequence(array):\n",
    "    #converts a row of boolean values to a unique number e.g. [1,1,0] => 11, [0,0,1] => 100\n",
    "    uniqueify = lambda r: torch.sum(torch.stack([i*(10**ii) for ii,i in enumerate(r)]))\n",
    "    return torch_apply_along_axis(uniqueify,array)\n",
    "\n",
    "def train_decision_model_triplet(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    smodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    use_attention=True,\n",
    "    lr=.001,\n",
    "    epochs=10000,\n",
    "    patience=5,\n",
    "    weights=[0,.5,.5,0], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,1,0], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "    opt_weights=[1,1,1], #weights for policy model for optimal decisions\n",
    "    imitation_weights=[.5,1,1],#weights of imitation decisions, because ic overtrains too quickly\n",
    "    imitation_weight=1,\n",
    "    reward_weight=1,\n",
    "    imitation_triplet_weight=2,\n",
    "    reward_triplet_weight = 2,\n",
    "    shufflecol_chance = 0.2,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    verbose=True,\n",
    "    use_gpu=False,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "\n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    true_ids = train_ids + test_ids #for saving memory without upsampling\n",
    "\n",
    "    dataset = DTDataset()\n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        #this should have an ic condition but we don't use it anumore anywa\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids]).to(model.get_device())\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model_kwargs = {k:v for k,v in model_kwargs.items() if 'attention' not in k and 'embed' not in k}\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "        \n",
    "    device = 'cpu'\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        \n",
    "    model.set_device(device)\n",
    "\n",
    "    tmodel1.set_device(device)\n",
    "    tmodel2.set_device(device)\n",
    "    tmodel3.set_device(device)\n",
    "    smodel3.set_device(device)\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    \n",
    "    optimal_train,transitions_train = calc_optimal_decisions(dataset,train_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                           weights=weights,tweights=tweights,\n",
    "                                          )\n",
    "    optimal_test,transitions_test = calc_optimal_decisions(dataset,test_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                          weights=weights,tweights=tweights,\n",
    "                                         )\n",
    "    optimal_train = optimal_train.to(model.get_device())\n",
    "    optimal_test = optimal_test.to(model.get_device())\n",
    "    mse = torch.nn.MSELoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,torch.rand(x.shape[0])).type(torch.FloatTensor)\n",
    "\n",
    "    randchoice = lambda x: x[torch.randint(len(x),(1,))[0]]\n",
    "    tloss_func = torch.nn.TripletMarginLoss()\n",
    "    def get_tloss(row,step,yt,x,imitation=True):\n",
    "        if yt[:,step].std() < .001:\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive_idx= torch.nonzero(yt[:,step] == yt[row,step])\n",
    "        if len(positive_idx) <= 1:\n",
    "            print('no losses','n positive',len(positive_idx),'yt',yt[row,step],'row',row,'step',step,'imitation',imitation,end='\\r')\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive_idx = torch.stack([ii for ii in positive_idx if ii != row]).view(-1)\n",
    "        negative_idx = torch.tensor([ii for ii in range(x.shape[0]) if ii not in positive_idx and ii != row])\n",
    "        if len(positive_idx) < 1 or len(negative_idx) < 1:\n",
    "            print('no losses','n positive',len(positive_idx),'n negative',len(negative_idx),'yt',yt[row,step],'row',row,'step',step,'imitation',imitation,end='\\r')\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive = x[randchoice(positive_idx)]\n",
    "        negative = x[randchoice(negative_idx)]\n",
    "        anchor = x[row]\n",
    "        if use_attention:\n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,use_saved_memory=True) for xx in [anchor,positive,negative]]\n",
    "        else:    \n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,concatenate=False)[int(imitation)] for xx in [anchor,positive,negative]]\n",
    "        tloss = tloss_func(anchor_embedding,pos_embedding,neg_embedding)\n",
    "        return tloss\n",
    "    #save the inputs from the whole dataset for future reference\n",
    "    if use_attention:\n",
    "        full_data = []\n",
    "        for mstep in [0,1,2]:\n",
    "            full_data_step = [baseline, get_dlt(min(mstep,1)),\n",
    "                         get_dlt(mstep),get_pd(mstep),get_nd(mstep),get_cc(mstep),get_mod(mstep)]\n",
    "            full_data_step = torch.cat([formatdf(fd,true_ids) for fd in full_data_step],axis=1)\n",
    "            full_data.append(full_data_step)\n",
    "        full_data = torch.stack(full_data)\n",
    "        model.save_memory(full_data)\n",
    "        print(full_data.shape)\n",
    "        \n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            tmodel1.train(True)\n",
    "            tmodel2.train(True)\n",
    "            tmodel3.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "            y_opt = makegrad(optimal_train)\n",
    "            transition_dict = {k: torch.clone(v).detach() for k,v in transitions_train.items()}\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            tmodel1.eval()\n",
    "            tmodel2.eval()\n",
    "            tmodel3.eval()\n",
    "            y_opt = makegrad(optimal_test)\n",
    "            print(y_opt.mean(axis=0))\n",
    "            transition_dict = {k: torch.clone(v).detach() for k,v in transitions_test.items()}\n",
    "        model.set_device(device)\n",
    "        ytrain = df_to_torch(outcomedf.loc[ids]).to(device)\n",
    "        #imitation losses and decision 1\n",
    "        xxtrained = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrained]\n",
    "        xxtrain = torch.cat(xxtrain,axis=1).to(device)\n",
    "        o1 = model(xxtrain,position=0,use_saved_memory= (not train))\n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1_opt = o1[:,0]\n",
    "    \n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        imitation_loss1 = torch.mul(imitation_loss1,imitation_weights[0])\n",
    "        opt_loss1 = bce(decision1_opt,y_opt[:,0])\n",
    "        opt_loss1 = torch.mul(opt_loss1,opt_weights[0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        x1_imitation = torch.cat(x1_imitation,axis=1).to(device)\n",
    "        \n",
    "        o2 = model(x1_imitation,position=1,use_saved_memory= (not train))\n",
    "            \n",
    "        decision2_imitation = o2[:,4]\n",
    "            \n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        imitation_loss2 = torch.mul(imitation_loss2,imitation_weights[1])\n",
    "        \n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "        \n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        x2_imitation = torch.cat(x2_imitation,axis=1).to(device)\n",
    "        \n",
    "        \n",
    "        o3 = model(x2_imitation,position=2,use_saved_memory= (not train))\n",
    "        \n",
    "        decision3_imitation = o3[:,5]\n",
    "        \n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        imitation_loss3 = torch.mul(imitation_loss3,imitation_weights[2])\n",
    "        \n",
    "        opt_input2 = [\n",
    "            formatdf(baseline,ids), \n",
    "            transition_dict['dlt1'],\n",
    "            formatdf(get_dlt(0),ids),\n",
    "            transition_dict['pd1'],\n",
    "            transition_dict['nd1'], \n",
    "            formatdf(get_cc(0),ids),\n",
    "            transition_dict['mod']\n",
    "                 ]\n",
    "        opt_input2 = [o.to(device) for o in opt_input2]\n",
    "\n",
    "        opt_input2 = torch.cat(opt_input2,axis=1).to(device)\n",
    "        decision2_opt = model(opt_input2,position=1,use_saved_memory= (not train))[:,1]\n",
    "        \n",
    "        opt_loss2 = bce(decision2_opt,y_opt[:,1])\n",
    "        opt_loss2 = torch.mul(opt_loss2,opt_weights[1])\n",
    "        \n",
    "        opt_input3 = [\n",
    "            formatdf(baseline,ids),\n",
    "            transition_dict['dlt1'],\n",
    "            transition_dict['dlt2'],\n",
    "            transition_dict['pd2'],\n",
    "            transition_dict['nd2'],\n",
    "            transition_dict['cc'],\n",
    "            transition_dict['mod'],\n",
    "        ]\n",
    "        opt_input3 = [o.to(device) for o in opt_input3]\n",
    "        opt_input3 = torch.cat(opt_input3,axis=1).to(device)\n",
    "        decision3_opt = model(opt_input3,position=2,use_saved_memory= (not train))[:,2]\n",
    "        \n",
    "        opt_loss3 = bce(decision3_opt,y_opt[:,2])\n",
    "        opt_loss3 = torch.mul(opt_loss3,opt_weights[2])\n",
    "        \n",
    "        iloss = torch.add(torch.add(imitation_loss1,imitation_loss2),imitation_loss3)\n",
    "        iloss = torch.mul(iloss,imitation_weight)\n",
    "        \n",
    "        reward_loss = torch.add(torch.add(opt_loss1,opt_loss2),opt_loss3)\n",
    "        reward_loss =torch.mul(reward_loss,reward_weight)\n",
    "        \n",
    "        loss = torch.add(iloss,reward_loss)\n",
    "        \n",
    "        imitation_tloss = torch.FloatTensor([0]).to(device)\n",
    "        opt_tloss = torch.FloatTensor([0]).to(device)\n",
    "        n_rows = xxtrain.shape[0]\n",
    "        if reward_triplet_weight + imitation_triplet_weight > 0.0001:\n",
    "            for i in range(n_rows):\n",
    "                \n",
    "                if imitation_triplet_weight > .0001:\n",
    "                    imitation_tloss += get_tloss(i,0,ytrain,xxtrain,True)\n",
    "                    imitation_tloss += get_tloss(i,1,ytrain,x1_imitation,True)\n",
    "                    imitation_tloss += get_tloss(i,2,ytrain,x2_imitation,True)\n",
    "                if reward_triplet_weight > .0001:\n",
    "                    opt_tloss += get_tloss(i,0,y_opt,xxtrain,False)\n",
    "                    opt_tloss += get_tloss(i,1,y_opt,opt_input2,False)\n",
    "                    opt_tloss += get_tloss(i,2,y_opt,opt_input3,False)\n",
    "            loss += torch.mul(imitation_tloss[0],imitation_triplet_weight/n_rows)\n",
    "            loss += torch.mul(opt_tloss[0],reward_triplet_weight/n_rows)\n",
    "        losses = [iloss,reward_loss,imitation_tloss*imitation_triplet_weight/n_rows,opt_tloss*reward_triplet_weight/n_rows]\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            distributions = [decision1_opt.mean().item(),decision2_opt.mean().item(),decision3_opt.mean().item()]\n",
    "            imitation = [decision1_imitation,decision2_imitation,decision3_imitation]\n",
    "            optimal = [decision1_opt,decision2_opt,decision3_opt]\n",
    "            for i,decision_im in enumerate(imitation):\n",
    "                deci = decision_im.cpu().detach().numpy()\n",
    "                deci0 = (deci > .5).astype(int)\n",
    "                iout = ytrain[:,i].cpu().detach().numpy()\n",
    "                acci = accuracy_score(iout,deci0)\n",
    "                try:\n",
    "                    auci = roc_auc_score(iout,deci)\n",
    "                except:\n",
    "                    auci = -1\n",
    "                \n",
    "                deco = optimal[i].cpu().detach().numpy()\n",
    "                deci0 = (deco > .5).astype(int)\n",
    "                oout = y_opt[:,i].cpu().detach().numpy()\n",
    "                acco = accuracy_score(oout,deci0)\n",
    "                try:\n",
    "                    auco = roc_auc_score(oout,deco)\n",
    "                except:\n",
    "                    auco=-1\n",
    "                scores.append({'decision': i,'optimal_auc': auco,'imitation_auc': auci,'optimal_acc': acco,'imitation_acc': acci})\n",
    "            return losses, scores, distributions\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics,val_distributions = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        for vm in val_metrics:\n",
    "            vl += (-((vm['optimal_auc']*reward_weight) + (vm['imitation_auc']*imitation_weight)))/10\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('val reward',val_losses[1].item())\n",
    "            print('imitation reward', val_losses[0].item())\n",
    "            print('distance losses',val_losses[2].item(),val_losses[-1].item())\n",
    "            print('distributions',val_distributions)\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            best_val_distributions = val_distributions\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss, best_val_distributions\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [1000,1000], \n",
    "    'opt_layer_size': 20, \n",
    "    'imitation_layer_size': 20, \n",
    "    'dropout': 0.25, \n",
    "    'input_dropout': 0.1, \n",
    "    'shufflecol_chance': 0.5\n",
    "}\n",
    "\n",
    "#1.8424\n",
    "decision_model, decision_score, decision_loss, _ = train_decision_model_triplet(\n",
    "    model1,model2,model3,smodel3,\n",
    "    lr=.01,\n",
    "    imitation_weight=1,\n",
    "    reward_weight=1,\n",
    "    patience=100,\n",
    "    imitation_triplet_weight=0,\n",
    "    reward_triplet_weight =0,\n",
    "    verbose=True,\n",
    "    weights=[1,1,1,1], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,1,0], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "    use_attention=True,\n",
    "    **args)\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5687255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>optimal_auc</th>\n",
       "      <th>imitation_auc</th>\n",
       "      <th>optimal_acc</th>\n",
       "      <th>imitation_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.824972</td>\n",
       "      <td>0.601622</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.870748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.959924</td>\n",
       "      <td>0.739674</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.944478</td>\n",
       "      <td>0.844882</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision  optimal_auc  imitation_auc  optimal_acc  imitation_acc\n",
       "0         0     0.824972       0.601622     0.714286       0.870748\n",
       "1         1     0.959924       0.739674     0.911565       0.775510\n",
       "2         2     0.944478       0.844882     0.877551       0.809524"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(decision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f37f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>optimal_auc</th>\n",
       "      <th>imitation_auc</th>\n",
       "      <th>optimal_acc</th>\n",
       "      <th>imitation_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.841137</td>\n",
       "      <td>0.582061</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.972805</td>\n",
       "      <td>0.730978</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945078</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision  optimal_auc  imitation_auc  optimal_acc  imitation_acc\n",
       "0         0     0.841137       0.582061     0.789116       0.877551\n",
       "1         1     0.972805       0.730978     0.925170       0.775510\n",
       "2         2     0.945078       0.793388     0.897959       0.809524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model.set_device('cpu')\n",
    "torch.save(decision_model,'../resources/decision_model.pt')\n",
    "pd.DataFrame(decision_score).to_csv('../results/policy_model_score.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc3c8bac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(decision_score)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(decision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.8424\n",
    "decision_model2, decision_score2, decision_loss2, _ = train_decision_model_triplet(\n",
    "    model1,model2,model3,smodel3,\n",
    "    lr=.01,\n",
    "    imitation_weight=1,\n",
    "    reward_weight=1,\n",
    "    patience=10,\n",
    "    imitation_triplet_weight=0,\n",
    "    reward_triplet_weight =0,\n",
    "    verbose=True,\n",
    "    weights=[0,0,0,0], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,0,0], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "    use_attention=True,\n",
    "    **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a7faad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (468907433.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    imitation_weights=[.5,1,1],#weights of imitation decisions, because ic overtrains too quickly\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train_decision_model(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    smodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    lr=.0001,\n",
    "    epochs=10000,\n",
    "    patience=50,\n",
    "    weights=[0,.5,.5,0], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,1,0]\n",
    "    imitation_weights=[.5,1,1],#weights of imitation decisions, because ic overtrains too quickly\n",
    "    imitation_weight=0.1,\n",
    "    shufflecol_chance = 0.1,\n",
    "    reward_weight=1,\n",
    "    imitation_triplet_weight=0,\n",
    "    reward_triplet_weight = 0,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    use_gpu=True,\n",
    "    use_attention=True,\n",
    "    verbose=True,\n",
    "    threshold_decisions=True,#convert decisiosn to binary in simulation, usually breaks it\n",
    "    use_smote=False,\n",
    "    validate_with_memory=True,\n",
    "    **model_kwargs):\n",
    "    #outdated method of doing stuff, haven't updated with new loss functions idk\n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "    smodel3.eval()\n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    true_ids = train_ids + test_ids #for saving memory without upsampling\n",
    "    if use_smote:\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids)\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        #this should have an ic condition but we don't use it anumore anywa\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids]).to(model.get_device())\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model_kwargs = {k:v for k,v in model_kwargs.items() if 'attention' not in k and 'embed' not in k}\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "\n",
    "    device = 'cpu'\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        \n",
    "    model.set_device(device)\n",
    "\n",
    "    tmodel1.set_device(device)\n",
    "    tmodel2.set_device(device)\n",
    "    tmodel3.set_device(device)\n",
    "    smodel3.set_device(device)\n",
    "    \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]).to(model.get_device()))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    device = model.get_device()\n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids))).to(device)\n",
    "    thresh = lambda x: torch.sigmoid(100000000*(x - .5))\n",
    "\n",
    "    optimal_train,transitions_train = calc_optimal_decisions(dataset,train_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                           weights=weights,tweights=tweights,\n",
    "                                          )\n",
    "    optimal_test,transitions_test = calc_optimal_decisions(dataset,test_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                          weights=weights,tweights=tweights,\n",
    "                                         )\n",
    "    optimal_train = optimal_train.to(model.get_device())\n",
    "    optimal_test = optimal_test.to(model.get_device())\n",
    "    \n",
    "    #save the inputs from the whole dataset for future reference\n",
    "    if use_attention:\n",
    "        full_data = []\n",
    "        for mstep in [0,1,2]:\n",
    "            full_data_step = [baseline, get_dlt(min(mstep,1)),\n",
    "                         get_dlt(mstep),get_pd(mstep),get_nd(mstep),get_cc(mstep),get_mod(mstep)]\n",
    "            full_data_step = torch.cat([formatdf(fd,true_ids) for fd in full_data_step],axis=1)\n",
    "            full_data.append(full_data_step)\n",
    "        full_data = torch.stack(full_data)\n",
    "        model.save_memory(full_data.to(device))\n",
    "        print(full_data.shape)\n",
    "        \n",
    "    randchoice = lambda x: x[torch.randint(len(x),(1,))[0]]\n",
    "    tloss_func = torch.nn.TripletMarginLoss()\n",
    "    def get_tloss(row,step,yt,x,imitation=True):\n",
    "        if yt[:,step].std() < .001:\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive_idx= torch.nonzero(yt[:,step] == yt[row,step])\n",
    "        positive_idx = torch.stack([ii for ii in positive_idx if ii != row]).view(-1)\n",
    "        negative_idx = torch.tensor([ii for ii in range(x.shape[0]) if ii not in positive_idx and ii != row])\n",
    "        if len(positive_idx) < 1 or len(negative_idx) < 1:\n",
    "            print('no losses','n positive',len(positive_idx),'n negative',len(negative_idx),'yt',yt[row,step],'row',row,'step',step,'imitation',imitation,end='\\r')\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive = x[randchoice(positive_idx)]\n",
    "        negative = x[randchoice(negative_idx)]\n",
    "        anchor = x[row]\n",
    "        if use_attention:\n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,use_saved_memory=True) for xx in [anchor,positive,negative]]\n",
    "        else:    \n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,concatenate=False)[int(imitation)] for xx in [anchor,positive,negative]]\n",
    "        tloss = tloss_func(anchor_embedding,pos_embedding,neg_embedding)\n",
    "        return tloss\n",
    "    \n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            tmodel1.train(True)\n",
    "            tmodel2.train(True)\n",
    "            tmodel3.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "            y_opt = makegrad(optimal_train)\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            tmodel1.eval()\n",
    "            tmodel2.eval()\n",
    "            tmodel3.eval()\n",
    "            y_opt = makegrad(optimal_test)\n",
    "            \n",
    "            \n",
    "        ytrain = df_to_torch(outcomedf.loc[ids]).to(device)\n",
    "        #imitation losses and decision 1\n",
    "        xxtrained = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = torch.cat([formatdf(xx,ids) for xx in xxtrained],axis=1).to(device)\n",
    "        \n",
    "        use_memory = (not train) and validate_with_memory\n",
    "\n",
    "        o1 = model(xxtrain,position=0,use_saved_memory = use_memory)\n",
    "\n",
    "        decision1_imitation = o1[:,3]\n",
    "        \n",
    "        decision1_opt = o1[:,0]\n",
    "        if threshold_decisions:\n",
    "            decision1_opt = thresh(decision1_opt)\n",
    "\n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        imitation_loss1 = torch.mul(imitation_loss1,imitation_weights[0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        x1_imitation = torch.cat(x1_imitation,axis=1).to(device)\n",
    "        decision2_imitation = model(x1_imitation,position=1,use_saved_memory = use_memory)[:,4]\n",
    "\n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        imitation_loss2 = torch.mul(imitation_loss2,imitation_weights[1])\n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "        \n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        x2_imitation = torch.cat(x2_imitation,axis=1)\n",
    "        decision3_imitation = model(x2_imitation,position=2,use_saved_memory = use_memory)[:,5]\n",
    "\n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        imitation_loss3 = torch.mul(imitation_loss3,imitation_weights[2])\n",
    "        \n",
    "        #reward decisions\n",
    "        xx1 = makeinput(1,ids)\n",
    "        xx2 = makeinput(2,ids)\n",
    "        xx3 = makeinput(3,ids)\n",
    "\n",
    "        xx1 = makegrad(xx1)\n",
    "        xx2 = makegrad(xx2)\n",
    "        xx3 = makegrad(xx3)\n",
    "        baseline_train_base = formatdf(baseline,ids)\n",
    "            \n",
    "        baseline_train = torch.clone(baseline_train_base)\n",
    "\n",
    "        \n",
    "        xi1 = torch.cat([xx1,decision1_opt.view(-1,1)],axis=1)\n",
    "        print(train,tmodel1.training,tmodel1.dropout.training)\n",
    "        [ypd1, ynd1, ymod, ydlt1] = tmodel1(xi1)['predictions']\n",
    "        print(train,tmodel1.training,tmodel1.dropout.training)\n",
    "        d1_thresh = torch.gt(decision1_opt.view(-1,1),.5).to(ypd1.device)\n",
    "        d1_scale = torch.cat([d1_thresh,d1_thresh,torch.ones(d1_thresh.view(-1,1).shape).to(ypd1.device)],dim=1)\n",
    "        ypd1= torch.mul(ypd1,d1_scale)\n",
    "        ynd1= torch.mul(ynd1,d1_scale)\n",
    "        \n",
    "        x1 = [baseline_train,ydlt1,formatdf(get_dlt(0),ids),ypd1,ynd1,formatdf(get_cc(1),ids),ymod]\n",
    "        x1= torch.cat([xx1.to(model.get_device()) for xx1 in x1],axis=1)\n",
    "        \n",
    "        decision2_opt = model(x1,position=1,use_saved_memory = use_memory)[:,1] \n",
    "        if threshold_decisions:\n",
    "            decision2_opt = thresh(decision2_opt)\n",
    "            \n",
    "        xi2 = torch.cat([xx2,decision1_opt.view(-1,1),decision2_opt.view(-1,1)],axis=1)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = tmodel2(xi2)['predictions']\n",
    "\n",
    "        x2 = [baseline_train,ydlt1,ydlt2,ypd2,ynd2,ycc,ymod]\n",
    "        x2 = torch.cat([xx2.to(model.get_device()) for xx2 in x2],axis=1)\n",
    "        decision3_opt = model(x2,position=2,use_saved_memory = use_memory)[:,2]\n",
    "        \n",
    "        if threshold_decisions:\n",
    "            decision3_opt = thresh(decision3_opt)\n",
    "            \n",
    "        xi3 = torch.cat([xx3,decision1_opt.view(-1,1),decision2_opt.view(-1,1),decision3_opt.view(-1,1)],axis=1)\n",
    "        \n",
    "        outcomes = tmodel3(xi3)['predictions']\n",
    "        survival = smodel3.time_to_event(xi3,n_samples=1)\n",
    "        if not train and verbose:\n",
    "            print(torch.mean(outcomes,dim=0))\n",
    "            \n",
    "        reward_loss = torch.mean(outcome_loss(outcomes,weights) + temporal_loss(survival,tweights))\n",
    "        loss = torch.add(imitation_loss1,imitation_loss2)\n",
    "        loss = torch.add(loss,imitation_loss3)\n",
    "        loss = torch.mul(loss,imitation_weight/3)\n",
    "        loss = torch.add(loss,torch.mul(reward_loss,reward_weight))\n",
    "        \n",
    "        imitation_tloss = torch.FloatTensor([0]).to(device)\n",
    "        opt_tloss = torch.FloatTensor([0]).to(device)\n",
    "        n_rows = x1.shape[0]\n",
    "        if reward_triplet_weight + imitation_triplet_weight > 0.0001:\n",
    "            for i in range(n_rows):\n",
    "                #skip if we're using an attention model idk\n",
    "                if not use_attention and imitation_triplet_weight > .0001:\n",
    "                    imitation_tloss += get_tloss(i,0,ytrain,xxtrain,True)\n",
    "                    imitation_tloss += get_tloss(i,1,ytrain,x1_imitation,True)\n",
    "                    imitation_tloss += get_tloss(i,2,ytrain,x2_imitation,True)\n",
    "                if reward_triplet_weight > .0001:\n",
    "                    opt_tloss += get_tloss(i,0,y_opt,xxtrain,False)\n",
    "                    opt_tloss += get_tloss(i,1,y_opt,x1,False)\n",
    "                    opt_tloss += get_tloss(i,2,y_opt,x2,False)\n",
    "            loss += torch.mul(imitation_tloss[0],imitation_triplet_weight/n_rows)\n",
    "            loss += torch.mul(opt_tloss[0],reward_triplet_weight/n_rows)\n",
    "        \n",
    "        losses = [imitation_loss1+imitation_loss2+imitation_loss3,reward_loss,imitation_tloss,opt_tloss]\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            distributions = [decision1_opt.mean().item(),decision2_opt.mean().item(),decision3_opt.mean().item()]\n",
    "            imitation = [decision1_imitation,decision2_imitation,decision3_imitation]\n",
    "            optimal = [decision1_opt,decision2_opt,decision3_opt]\n",
    "            for i,decision_im in enumerate(imitation):\n",
    "                deci = decision_im.cpu().detach().numpy()\n",
    "                deci0 = (deci > .5).astype(int)\n",
    "                iout = ytrain[:,i].cpu().detach().numpy()\n",
    "                acci = accuracy_score(iout,deci0)\n",
    "                try:\n",
    "                    auci = roc_auc_score(iout,deci)\n",
    "                except:\n",
    "                    auci = -1\n",
    "                \n",
    "                deco = optimal[i].cpu().detach().numpy()\n",
    "                deci0 = (deco > .5).astype(int)\n",
    "                oout = y_opt[:,i].cpu().detach().numpy()\n",
    "                acco = accuracy_score(oout,deci0)\n",
    "                try:\n",
    "                    auco = roc_auc_score(oout,deco)\n",
    "                except:\n",
    "                    auco=-1\n",
    "                scores.append({'decision': i,'optimal_auc': auco,'imitation_auc': auci,'optimal_acc': acco,'imitation_acc': acci})\n",
    "            return losses, scores, distributions\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics,val_distributions = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        for vm in val_metrics:\n",
    "            vl += (-((vm['optimal_auc']*reward_weight) + (vm['imitation_auc']*imitation_weight)))/10\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('val reward',val_losses[1].item())\n",
    "            print('imitation reward', val_losses[0].item())\n",
    "            if len(val_losses) > 2:\n",
    "                print('distance losses',val_losses[2].item(),val_losses[-1].item())\n",
    "            print('distributions',val_distributions)\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            best_val_distributions = val_distributions\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss, best_val_distributions\n",
    "\n",
    "from Models import *\n",
    "# args = {\n",
    "#     'hidden_layers': [50,50], \n",
    "#     'attention_heads': [2,2],\n",
    "#     'embed_size': 120, \n",
    "#     'dropout': 0.5, \n",
    "#     'input_dropout': 0.2, \n",
    "#     'shufflecol_chance':  0.2,\n",
    "# }\n",
    "args = {\n",
    "    'hidden_layers': [500], \n",
    "    'opt_layer_size': 20, \n",
    "    'imitation_layer_size': 20, \n",
    "    'dropout': 0.25, \n",
    "    'input_dropout': 0.25, \n",
    "    'shufflecol_chance': 0.5\n",
    "}\n",
    "from Models import *\n",
    "decision_model, _, _, _ = train_decision_model(\n",
    "    model1,model2,model3,smodel3,\n",
    "    lr=.001,\n",
    "    use_attention=True,\n",
    "    imitation_weight=1,\n",
    "    imitation_triplet_weight=0,\n",
    "    reward_triplet_weight=0,\n",
    "    reward_weight=2,\n",
    "    validate_with_memory=True,\n",
    "    use_smote=False,\n",
    "    **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc951c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
